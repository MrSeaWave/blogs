{"posts":[{"title":"GoodNotes软件","text":"今天安利一款软件：GoodNotes 想必手头上有 ipad 的人可能或多或少都听过他的大名，没错，他就是可以让你的 Ipad 不在是娱乐工具，从而转型为学术型工具的一款基于 Apple Pencil 的电子笔记的软件。 大家在看书，学习，玩游戏时或多或少都需要笔记功能，可以说笔记在两个环节起作用： 方便记录过后的查阅。书写过程怎么记的也许不重要，事后方便查找翻看才是王道； 追求笔记书写的过程。有些笔记记完了甚⾄不⼀定会回去看，但是⼀笔⼀画写下来的过程能加深记忆。 对于第一类笔记，我会使用键盘或者语音输入从而尽快完成记录； 对于第二类笔记，则使用手写形式的电子笔记。比如看书，计算公式，学习语言，需要花时间反复去记忆，那么手写这种看似很慢的方式，反而很高效。相比于噼里啪啦在屏幕上打字，一笔一画写字的过程也是记忆和思考的过程。即使后期不去回看，学习效果也比打字好得太多。在我们追求速度、准确、效率的过程中，纸笔的价值仍然不能被否定。 纸质的书籍厚重难找还不好修改，纯打字的笔记又没有手写的质感和灵感， iPad 搭配 Pencil 可以很好地结合电子产品和手写的优势，算是在其中找到了相对平衡的点。既能够保留⼿写的感官体验，⼜兼顾了电⼦笔记的轻便⾼效。 而除了硬件以外，适合自己的软件可以让笔记这件事事半功倍。 因此今天安利了这款软件：GoodNotes。 下面举个例子，来佐证下这款软件： 自由的书写体验对于 Notion 这样的非手写工具，有背后强大的 UI 做支撑，你每一个输入、每一次创建都不会破坏页面的严谨度和美感，似乎在使用的时候也会更加「郑重其事」，还有其独特的数据库功能。理性用户的选择， 但是相比之下 GoodNotes 则比较感性许多，手写的形式可以让人不必过分在意内容是否准确无误（GoodNotes 在 iPad 上拥有拥有完全媲美纸笔的流畅书写感受，尤其是在贴了类纸膜之后，书写体验更上一个台阶）。 GoodNotes 有四种笔可供选择。 钢笔有压感，但是压感变化不如画笔明显； 圆珠笔没有压感，无论多大力气写笔迹粗细都是一样的； 画笔也有压感，但笔迹粗细随下笔力度的变化更加明显。 荧光笔可以用来做标记，没有压感。 具体的笔迹效果如下图： （小 Tip: 插入 PDF 或 图片后，使用荧光笔时，它会自动置于文字下方。 ） 当然有了笔之后可是免不了一种就做橡皮擦的东西，毕竟不是每个人都能做到下过笔之后不作任何修改的。 优秀的文档管理方法做了笔记，接下来我们就要对它们进行收纳，保证之后能更方便地找到对应的内容。其中 GoodNotes 的文件管理逻辑与交互，和大家常用的电脑系统保持一致：拖拽实现移动、可随意切换视图和列表展示、文件夹支持层层嵌套…..，学习成本低，上手简单，文件情况一目了然。 文件夹管理 直接搜索如果没有进行收纳，GoodNotes 提供了一个简单的方法，就是「搜索」。 它能识别我们手写的文字——只要不是太潦草。 收藏重要的页面/笔记本笔记收藏在笔记页面，点击左上角的【收藏】按钮。 笔记本收藏在笔记本页面上，点击笔记本右上角的【⭐️】，即可。 制作目录有的时候，一个笔记本写多了，后期查找会比较困难。这时候，可以制作目录，快速定位。 （1）在某一页笔记上，点击右上角的【…】，然后选择【将此页面添加到大纲】。 （2）接下来，然后选择【大纲】，即可看到【索引】。点击其中某一个，可以快速到达对应的页面。 多平台同步GoodNotes 现在支持了源文件的迁移。比起只能保存为图片或者 PDF 的笔记工具，源文件的迁移让资料保存、共享都变得更简单了，结合 iCloud 的共享生态，再也不必担心后期的修改和整合，怎么变都能无缝衔接。 （在 ipad 上还可以设定其余的云存储。 分屏同时满足阅读和书写需求GoodNotes 可以支持同时显示两个笔记。以前一边用 PDF expert 看教材、PPT 或者试卷题型等，左边做标注，右边用 GoodNotes 记笔记。但这样做会导致左右两边的标注风格不一样，有的时候左右切换工具还反应不过来。但是现在同个 APP 可以支持同时显示两个笔记，分屏操作大大提高了统一性，文件管理也更方便了。 额外亮点操作制作模版虽然 GoodNotes 有提供非常多的模板，但是，根据自己的需要，有时候需要重新开发。这时候，我们可以制作属于自己的个性笔记本。 素材可以收藏你喜爱的图片、贴纸、文字等素材并随时取用。（表情包大户可用 有了素材可以制作漂亮的手账： 共享GoodNotes 目前还自带文件协作，共享笔墨的功能。 练字没错，这款软件还可提供练字功能。如下:","link":"/articles/2021/07/09/GoodNotes/"},{"title":"apiDoc 教程","text":"apiDoc - 超简单的文档生成器，本文将讲述如何使用它。 市面上常用的 API 文档管理方式有 apiDoc、Swagger2、DocClear。 Swagger2 有一个比较明显的缺点：代码侵入，开启注解时会影响原本的系统性能。 同样 DocClear 也有一个比较明显的缺点：DocClear 本身只是一个接口信息管理平台，所有的接口信息需要开发人员在平台内进行录入。 apiDoc 作为 API 文档工具是一款通过源代码中的 API 注释创建文档，支持 Java、JS、PHP、Tython 等语言，没有 Swagger2 那样代码侵入，而是通过 apiDoc 的程序对我们的源代码文件进行扫描，获取文件内的 apiDoc 注释信息来创建 API 文档，进而生成静态的 API 文档页面。接下来就从头到尾给大家讲解一下 apiDoc 如何使用。 快速开始 装环境 1npm install apidoc -g 新建一个项目 src/file.js，不用纠结这些注释含义, 后面会详解 12345678910111213141516171819202122// src/file.js/** * @api {Get} /user/get getUserInfo * @apiGroup User * * @apiParam {String} name 文章名 * @apiParamExample {json} Request-Example * { * &quot;userName&quot;: &quot;Eve&quot; * } * * @apiSuccessExample {json} Response-Example * { * &quot;userName&quot;: &quot;Eve&quot;, * &quot;createTime&quot;: &quot;1568901681&quot; * &quot;updateTime&quot;: &quot;1568901681&quot; * } */function getUserInfo(username) { // 假如这个函数是根据用户名返回用户信息的} apidoc.json 12345{ &quot;name&quot;: &quot;apidoc-demo&quot;, &quot;description&quot;: &quot;You write something here to describe your project&quot;, &quot;title&quot;: &quot;The title of this doc&quot;} 执行命令，-i是指注释文件存放的地方, -o是指文档输出的位置 1$ apidoc -i src/ -o apidoc/ 接下来我们会发现多了一个文件夹**apidoc**. 这是自动生成的一个文件夹目录 双击打开index.html 如 s 上简单三步即可生成一份 API 文档, 算是挺傻瓜式的，接下来将介绍具体字段含义。 配置(apidoc.json)详解每次导出接口文档都必须要让 apidoc 读取到 apidoc.json 文件(如果未添加配置文件，导出报错)，你可以在你项目的根目录下添加 apidoc.json 文件，这个文件主要包含一些项目的描述信息，比如标题、简短的描述、版本等，你也可以加入一些可选的配置项，比如页眉、页脚、模板等。 配置项： 参数 描述 name 工程名称如果 apidoc.json 文件中没有配置该参数，apidoc 会尝试从 pakcage.json 文件中读取 version 版本如果 apidoc.json 文件中没有配置该参数，apidoc 会尝试从 pakcage.json 文件中读取 description 工程描述如果 apidoc.json 文件中没有配置该参数，apidoc 会尝试从 pakcage.json 文件中读取 title 浏览器标题 url api 路径前缀例如:https://api.github.com/v1 sampleUrl 如果设置了该参数，那么在文档中便可以看到用于测试接口的一个表单(详情可以查看参数@apiSampleReques) header.title 页眉导航标题 header.filename 页眉文件名(markdown) (如：header.md) footer.title 页脚导航标题 footer.filename 页脚文件名(markdown) (如：footer.md) order 接口名称或接口组名称的排序列表如果未定义，那么所有名称会自动排序&quot;order&quot;: [ &quot;Error&quot;, &quot;Define&quot;, &quot;PostTitleAndError&quot;, PostError&quot;] 更多详情 apidoc 注释参数@api【必填字段】否则，apidoc 会忽略该条注释 1@api {method} path [title] 参数列表: 参数 必填 描述 method yes 请求类型:DELETE, GET, POST, PUT, ...更多 path yes 请求路径 title no 接口标题 例： 123/** * @api {get} /user/getUserById/:id 获取用户数据 - 根据id */ @apiDefine定义注释模块(类似于代码中定义一个常量)，对于一些通用可复用的注释模块(例如:接口错误响应模块)，只需要在源代码中定义一次，便可以在其他注释模块中随便引用，最后在文档导出时会自动替换所引用的注释模块，定义之后您可以通过@apiUse来引入所定义的注释模块。(注:可以同时使用@apiVersion来定义注释模块的版本) 12@apiDefine name [title] [description] 参数列表: 参数 必填 描述 name yes 注释模块名称(唯一)，不同@apiVersion 可以定义相同名称的注释模块 title no 注释模块标题 description no 注释模块详细描述(详细描述另起一行，可包含多行) 123456789/** * @apiDefine MyError * @apiError UserNotFound The &lt;code&gt;id&lt;/code&gt; of the User was not found. *//** * @api {get} /user/:id * @apiUse MyError */ 123456789/** * @apiDefine admin User access only * This optional description belong to to the group admin. *//** * @api {get} /user/:id * @apiPermission admin */ @apiDeprecated标注一个接口已经被弃用 1@apiDeprecated [text] 参数列表: 参数 必填 描述 text yes 多行文字描述 12345678910/** * @apiDeprecated *//** * @apiDeprecated use now (#Group:Name). * * Example: to set a link to the GetDetails method of your group User * write (#User:GetDetails) */ @apiDescriptionapi 接口的详细描述 1@apiDescription [text] 参数列表: 参数 必填 描述 text yes 多行文字描述 123456/** * @apiDescription This is the Description. * It is multiline capable. * * Last line of Description. */ @apiError错误返回参数 1@apiError [(group)] [{type}] field [description] 参数列表: 参数 必填 描述 (group) no 所有的参数都会通过这个参数进行分组，如果未设置，默认值为 Error 4xx {type} no 返回类型，例如{Boolean}， {Number}， {String}， {Object}，{String[]}（字符串数组），… field yes 返回 id description no 参数描述 12345678/** * @api {get} /user/getUserById/:id 获取用户数据 - 根据id * @apiError UserNotFound The &lt;code&gt;id&lt;/code&gt; of the User was not found. *//** * @apiError (错误分组) {Object} xxx xxxxxxxx */ @apiErrorExample接口错误返回示例(格式化输出) 12@apiErrorExample [{type}] [title] example 参数列表: 参数 必填 描述 type no 响应类型 title yes 示例标题 example yes 示例详情(兼容多行) 12345678/** *@api {get} /user/getUserById/:id 获取用户数据 - 根据id * @apiErrorExample {json} Error-Response: * HTTP/1.1 404 Not Found * { * &quot;error&quot;: &quot;UserNotFound&quot; * } */ @apiExample接口方式请求示例 12@apiExample [{type}] title example 参数列表: 参数 必填 描述 type no 请求内容格式 title yes 示例标题 example yes 示例详情(兼容多行) 12345/** * @api {get} /user/getUserById/:id * @apiExample {curl} Example usage: * curl -i http://127.0.0.1/user/getUserById/1 */ @apiGroup定义接口所属的接口组，虽然接口定义里不需要这个参数，但是您应该在每个接口注释里都添加这个参数，因为导出的接口文档会以接口组的形式导航展示。 1@apiGroup name 参数列表: 参数 必填 描述 name yes 接口组名称(用于导航,不支持中文) 1234/** * @api {get} /user/:id * @apiGroup User */ @apiHeader描述接口请求头部需要的参数(功能类似@apiParam) 1@apiHeader [(group)] [{type}] [field=defaultValue] [description] 参数列表: 参数 必填 描述 (group) no 所有的参数都会以该参数值进行分组(默认 Parameter) {type} no 返回类型(例如:{Boolean}, {Number}, {String}, {Object}, {String[]}) field yes 参数名称(定义该头部参数为必填) [field] yes 参数名称(定义该头部参数为可选) =defaultValue no 参数默认值 description no 参数描述 1234/** * @api {get} /user/:id * @apiHeader {String} access-key Users unique access-key. */ @apiHeaderExample请求头部参数示例 12@apiHeaderExample [{type}] [title] example 参数列表: 参数 必填 描述 type no 请求内容格式 title no 请求示例标题 example yes 请求示例详情(兼容多行) 1234567/** * @api {get} /user/getUserById/:id * @apiHeaderExample {json} Header-Example: * { * &quot;Accept-Encoding&quot;: &quot;Accept-Encoding: gzip, deflate&quot; * } */ @apiIgnore如果你需要使用该参数，请把它放到注释块的最前面。如果设置了该参数，那么该注释模块将不会被解析(当有些接口还未完成或未投入使用时，可以使用该字段) 1@apiIgnore [hint] 参数列表: 参数 必填 描述 hint no 描接口忽略原因描述 1234/** * @apiIgnore Not finished Method * @api {get} /user/:id */ @apiName接口名称，每一个接口注释里都应该添加该字段，在导出的接口文档里会已该字段值作为导航子标题，如果两个接口的@apiVersion和@apiName一样，那么有一个接口的注释将会被覆盖(接口文档里不会展示) 1@apiName name 参数列表: 参数 必填 描述 name yes 接口名称(相同接口版本下所有接口名称应该是唯一的) 1234/** * @api {get} /user/:id * @apiName GetUser */ @apiParam接口请求体参数 1@apiParam [(group)] [{type}] [field=defaultValue] [description] 参数列表: 参数 必填 描述 (group) no 所有的参数都会以该参数值进行分组(默认 Parameter) {type} no 返回类型(例如:{Boolean}, {Number}, {String}, {Object}, {String[]}) {type{size}} no 返回类型,同时定义参数的范围{string{…5}}意为字符串长度不超过 5{string{2…5}}意为字符串长度介于 25 之间 {number{100-999}}意为数值介于 100999 之间 {type=allowedValues} no 参数可选值{string=“small”}意为字符串仅允许值为”small”{string=“small”,“huge”}意为字符串允许值为”small”、“huge”{number=1,2,3,99}意为数值允许值为 1、2、3、99{string {…5}=“small”,”huge”意为字符串最大长度为 5 并且值允许为:“small”、“huge” field yes 参数名称(定义该请求体参数为必填) [field] yes 参数名称(定义该请求体参数为可选) =defaultValue no 参数默认值 description no 参数描述 1234567891011121314151617181920212223/** * @api {get} /user/:id * @apiParam {Number} id Users unique ID. *//** * @api {post} /user/ * @apiParam {String} [firstname] Optional Firstname of the User. * @apiParam {String} lastname Mandatory Lastname. * @apiParam {String} country=&quot;DE&quot; Mandatory with default value &quot;DE&quot;. * @apiParam {Number} [age=18] Optional Age with default 18. * * @apiParam (Login) {String} pass Only logged in users can post this. * In generated documentation a separate * &quot;Login&quot; Block will be generated. * * @apiParam {Object} [address] Optional nested address object. * @apiParam {String} [address[street]] Optional street and number. * @apiParam {String} [address[zip]] Optional zip code. * @apiParam {String} [address[city]] Optional city. * @apiParam {Object} [data] data * @apiParam {Object} [data.a] data.a */ @apiParamExample请求体参数示例 12@apiParamExample [{type}] [title] example 参数列表: 参数 必填 描述 type no 请求内容格式 title no 请求示例标题 example yes 请求示例详情(兼容多行) 1234567/** * @api {get} /user/:id * @apiParamExample {json} Request-Example: * { * &quot;id&quot;: 4711 * } */ @apiPermission允许访问该接口的角色名称 1@apiPermission name 参数列表: 参数 必填 描述 name yes 允许访问的角色名称(唯一) 1234/** * @api {get} /user/:id * @apiPermission admin */ @apiPrivate定义私有接口，对于定义为私有的接口，可以在生成接口文档的时候，通过在命令行中设置参数 --private false|true来决定导出的文档中是否包含私有接口 1@apiPrivate 1234/** * @api {get} /user/:id * @apiPrivate */ @apiSampleRequest设置了该参数后，导出的 html 接口文档中会包含模拟接口请求的 form 表单；如果在配置文件apidoc.json中设置了参数sampleUrl，那么导出的文档中每一个接口都会包含模拟接口请求的 form 表单，如果既设置了sampleUrl参数，同时不希望当前这个接口包含模拟接口请求的 form 表单，可以使用@apiSampleRequest off来关闭。 1@apiSampleRequest url 参数列表: 参数 必填 描述 url yes 模拟接口请求的 url@apiSampleRequest http://www.example.com意为覆盖apidoc.json中的sampleUrl参数，@apiSampleRequest off意为关闭接口测试功能 例：发送测试请求到:http://api.github.com/user/:id 1234Configuration parameter sampleUrl: &quot;http://api.github.com&quot;/** * @api {get} /user/:id */ 请求发送到http://test.github.com/some_path/user/:id。它将覆盖 sampleUrl。 12345Configuration parameter sampleUrl: &quot;http://api.github.com&quot;/** * @api {get} /user/:id * @apiSampleRequest http://test.github.com/some_path/ */ 请求发送到http://api.github.com/test/user/:id。它扩展了 sampleUrl。 12345Configuration parameter sampleUrl: &quot;http://api.github.com&quot;/** * @api {get} /user/:id * @apiSampleRequest /test */ 禁用此 api 方法的 api 请求。 12345Configuration parameter sampleUrl: &quot;http://api.github.com&quot;/** * @api {get} /user/:id * @apiSampleRequest off */ 请求发送到http://api.github.com/some_path/user/:id，因为未设置 sampleUrl，所以仅激活此方法的请求。 12345Configuration parameter sampleUrl is not set/** * @api {get} /user/:id * @apiSampleRequest http://api.github.com/some_path/ */ @apiSuccess接口成功返回参数 1@apiSuccess [(group)] [{type}] field [description] 参数列表: 参数 必填 描述 (group) no 所有的参数都会以该参数值进行分组,默认值:Success 200 {type} no 返回类型(例如:{Boolean}, {Number}, {String}, {Object}, {String[]}) field yes 返回值(返回成功码) =defaultValue no 参数默认值 description no 参数描述 12345/** * @api {get} /user/:id * @apiSuccess {String} firstname Firstname of the User. * @apiSuccess {String} lastname Lastname of the User. */ 包含(group): 12345/** * @api {get} /user/:id * @apiSuccess (200) {String} firstname Firstname of the User. * @apiSuccess (200) {String} lastname Lastname of the User. */ 返回参数中有对象: 1234567/** * @api {get} /user/:id * @apiSuccess {Boolean} active Specify if the account is active. * @apiSuccess {Object} profile User profile information. * @apiSuccess {Number} profile.age Users age. * @apiSuccess {String} profile.image Avatar-Image. */ 返回参数中有数组： 123456/** * @api {get} /users * @apiSuccess {Object[]} profiles List of user profiles. * @apiSuccess {Number} profiles.age Users age. * @apiSuccess {String} profiles.image Avatar-Image. */ @apiSuccessExample返回成功示例 12@apiSuccessExample [{type}] [title] example 参数列表: 参数 必填 描述 type no 返回内容格式 title no 返回示例标题 example yes 返回示例详情(兼容多行) 123456789/** * @api {get} /user/:id * @apiSuccessExample {json} Success-Response: * HTTP/1.1 200 OK * { * &quot;firstname&quot;: &quot;John&quot;, * &quot;lastname&quot;: &quot;Doe&quot; * } */ @apiUse引入注释模块，如果当前模块定义了@apiVersion,那么版本相同或版本最近的注释模块会被引入 1@apiUse name 参数列表: 参数 必填 描述 name yes 引入注释模块的名称 12345678910/** * @apiDefine MySuccess * @apiSuccess {string} firstname The users firstname. * @apiSuccess {number} age The users age. *//** * @api {get} /user/:id * @apiUse MySuccess */ @apiVersion定义接口/注释模块版本 1@apiVersion version 参数列表: 参数 必填 描述 version yes 版本号(支持semver版本规范) 1234/** * @api {get} /user/:id * @apiVersion 1.6.2 */ Tips: 把接口中的通用部分利用@apiDefine摘出来，放在一个公共文件``define.js中，之后可以利用@apiUse`去调用。 历史 api 可以存放在history.js中 生成 API 文档当然你注释参数写好了之后它也不会帮你自动生成，你需要自己运行以下命令： 1$ apidoc -i [项目完整路径] -o apidoc/ 参数列表: 参数 描述 -c, --config 指定使用的配置文件. (默认根目录的 apidoc.json apidoc.json ) 例： apidoc -c path/to/apidoc.json -e, --exclude-filters 输出文件时排除文件。 (默认: []) 例: apidoc -e node_modules -f, --file-filters RegEx-Filter，选择要解析的文件（可以使用许多-f）。默认.cs .dart .erl .go .java .js .php .py .rb .ts. 示例（仅解析.js 和.ts 文件）： apidoc -f &quot;.*\\\\.js$&quot; -f &quot;.*\\\\.ts$&quot; -i, --input 输入/源目录名。项目文件的位置。例：apidoc -i myapp/ -o, --output 输出目录名。放置生成的文档的位置，例：apidoc -o apidoc/ -t, --template 使用模板输出文件。您可以创建和使用自己的模板。例：apidoc -t mytemplate/ -h, --help 查看帮助文档 参考链接 apidoc apiDoc - 超简单的文档生成器 apiDoc 教程","link":"/articles/2021/07/15/apidoc/"},{"title":"如何从 Apple 美区官网购买礼品卡","text":"淘宝上怕有黑卡，那么我们现在可以通过美区官方的通道购买礼品卡，当然，你需要至少有个 双币信用卡 。按理应该 visa 卡都能用。大家可以试试看。 PS ：这个方法不是马上会收到，需要一点时间，官方写的是 4 小时以内，我大概不到 1 个小时就收到了。 Step_1 购买地址https://www.apple.com/shop/gift-cards/itunes-electronic Step_2 填写购买信息 Step_3 登陆 apple ID Step_4 填写支付信息美国地址生成器 Step_5 获取礼品兑换码 Step_6 在手机上输入兑换码打开Apple Store登录美区账号，点击头像。","link":"/articles/2021/04/02/apple-gift-card/"},{"title":"Charles 手机抓包设置","text":"本文主要讲述的是如何使用 Charles 对手机进行抓包。 如果是使用 Charles 抓包。一定要保证手机和电脑连的是一个网。 手机抓包设置，需要进行 3 步； 第一步，在 Charles 里设置允许手机联网的权限；你需要把 Charles 设置为允许的状态并且设置允许的端口号，这样手机端才能正常的接入； 第二步，把手机按照 Charles 的 IP 和端口进行配置； 第三步，手机配对成功后，Charles 还会弹窗是否允许；（Charles 虽然开放了端口，但并不知道是那一台手机会配入，此窗口起到提示和安全防护的作用；） 经过上面的三步，Charles 就可以对手机进行抓包了。 第一步：设置 Charles 为允许状态，并设置好接入端口 第二步：手机通过设置 http 代理服务器，连接到电脑把手机按照 Charles 的 IP 和端口进行配置，当手机连接 wifi 时，wifi 的 HTTP 代理选择手动那项（安卓类似） 第三步，手机配对成功后，Charles 弹窗询问是否允许设置好之后，我们打开 iPhone 上的任意需要网络通讯的程序，就可以看到 Charles 弹出 iPhone 请求连接的确认菜单 如上图的弹窗，点击允许即可；此时已经配对成功，开始愉快的抓包了。 charles 连接不上手机的处理方式1、检查电脑和手机有没有连接的同一个 wifi，必须连接的是一个网 2、更换 charles 和移动端设备的端口，默认是 8888，可以改成其他的试试 3、有可能路由器设置的 ap 间不能相互访问，需要登录路由器，需要登录路由器。进行求改。 4、关闭电脑的防火墙。试试 首先，如果，防火墙关了还是不行，那么请把手机 wifi 断掉后重新连接，这样一般就可以解决问题了。 如果以上方法还是不行的话，那么请将手机 wifi 位置的 ip 地址设置成静态 ip，然后重启 charles 工具。 5、在 charles 上添加手机的 ip 试试 参考链接 Charles 手机抓包设置","link":"/articles/2021/09/01/charles-proxy/"},{"title":"Chromium 历史版本离线安装包 - 下载方法","text":"Chrome(Chromium) 历史旧版本离线安装包下载方法。 Chrome 离线包 - 最新版（官方） 页面：https://www.google.com/intl/en/chrome/browser/desktop/index.html?standalone=1 点击Accept and Download会下载离线包（界面与在线安装类似，但确实是离线包） Chrome 离线包 - 历史版本（官方）下载：https://commondatastorage.googleapis.com/chromium-browser-snapshots/index.html 上述链接来自 Chromium 官网，含 Mac、Linux、Windows、Android、ChromiumOS 等 参考这里 https://chromium.googlesource.com/chromiumos/manifest-versions/+/master/paladin/buildspecs/ 来下载对应的离线版本包 参考这里https://vikyd.github.io/download-chromium-history-version/#/ 来下载对应的离线版本包","link":"/articles/2021/04/01/chrome-history-download/"},{"title":"修复 CI 构建博客造成的更新时间错误","text":"当使用 Travis CI or Github Actions 自动化部署时，发现部署成功后，所有文章的更新时间都变成了此次提交修改的时间，但有些文章在上一次提交后是没有发生过任何修改的。 这是因为 git 在推送更新时，并不记录保存文件的访问时间、修改时间等元信息，（原因在这里）所以每次使用 git 把项目 clone 下来时，文件的时间都是克隆时的时间。又因为如果没有在 front-matter 中指定 updated，Hexo 会默认使用文件的最后修改时间作为文章的更新时间，所以会出现所有文章的更新时间都发生变化的情况。 总的来说，使用 git clone 下来的文件的时间都不是原来文件的时间，而自动化部署每次都需要 clone 源码才能进行后面的生成和部署操作，所以目前如果想正确显示更新时间。需要： 方法一：使用 updated 属性字段在文章中的front-matter中添加updated: 更新时间项 front-matter12345title: 修复 CI 构建博客造成的更新时间错误author: Seatoc: truedate: 2021-01-07 15:53:16updated: 2021-01-07 15:53:16 以后修改文件的话也只需修改updated项对应日期即可，但是这样有个弊端，完全需要靠自己自觉去修改更新时间，自己一旦忘掉，那么更新时间的意义也就荡然无存了，因此这里推荐第二种方法。 方法二：使用 git 推送时间如果你用的是Travis Ci的话，只需要在.travis.yml添加如下配置： .travis.yml123before_install: # Restore last modified time - 'git ls-files -z | while read -d '''' path; do touch -d &quot;$(git log -1 --format=&quot;@%ct&quot; &quot;$path&quot;)&quot; &quot;$path&quot;; done' 如果你用的是Github Actions的话，只需要在对应的yml添加如下配置： actions123456jobs: &lt;jobs_id&gt;: steps: - name: Restore file modification time run: | git ls-files -z | while read -d '' path; do touch -d &quot;$(git log -1 --format=&quot;@%ct&quot; &quot;$path&quot;)&quot; &quot;$path&quot;; done 当然git ls-files 如果不好用可以改成 find： bash1find source/_posts -name '*.md' | while read file; do touch -d &quot;$(git log -1 --format=&quot;@%ct&quot; &quot;$file&quot;)&quot; &quot;$file&quot;; done 实际上，clone 下来的文件的时间还是克隆时的时间，然后通过上面的命令，它将 clone 下来的文件的时间改成了该文件最近一次变动的推送时间（也即文件最后一次修改的 push 时间）。 注：如果github actions中使用actions/checkout@v2，请设定它的参数fetch-depth: 0，因为0表示获取所有分支和标签的所有历史记录。默认值为1 小知识： bash12345678# 获取 git 仓库中所有文件的最新修改时间git ls-tree -r --name-only HEAD | while read filename; do echo &quot;$(git log -1 --format=&quot;%ad&quot; -- $filename) $filename&quot;done# 获取 git 仓库中所有文件的最初创建时间git ls-tree -r --name-only HEAD | while read filename; do echo &quot;$(git log --format=&quot;%ad&quot; -- $filename | tail -1) $filename&quot;done 参考链接 GIT 获取文件最初创建及最新修改日期 How to retrieve the last modification date of all files in a git repository：介绍了如何获取 git 仓库中，所有文件的最新修改时间。 Finding the date/time a file was first added to a Git repository：介绍了如何获取 git 仓库中，所有文件最初的创建时间。 Hexo 相关问题和优化 The update time of the article is incorrect 修复 CI 构建博客造成的更新时间错误","link":"/articles/2021/01/07/ci-hexo-update-time/"},{"title":"谷歌浏览器历史版本下载","text":"本文将介绍谷歌浏览器历史版本如何下载及其代码仓库原理介绍。 打开网页 https://mrseawave.github.io/chromium-history-page/ ，选择对应的 OS，与 version 点击进行下载即可。 网页源码：https://github.com/MrSeaWave/chromium-history-page dataSource：https://github.com/MrSeaWave/chromium-history-dataSource crawler(BASE): https://github.com/MrSeaWave/chromium-history-crawler 原理介绍crawler 仓库代码解析 Step_1寻找所有的 version&amp;&amp;version 对应的 position getPositionByVersion1$ node ./src/getPositionByVersion.js versionUrl + versionPositionUrl====&gt;生成 all-version.json, version-position.json versionUrl ：爬虫获取所有 version versionPositionUrl: 通过指定的 version 获取特定的 position all-version.json: all-version.json1234567[ &quot;90.0.4399.1&quot;, &quot;90.0.4399.0&quot;, &quot;90.0.4398.1&quot;, &quot;90.0.4398.0&quot; // ...] version-position.json: version-position.json1234567{ &quot;90.0.4399.1&quot;: &quot;846615&quot;, &quot;90.0.4399.0&quot;: &quot;846615&quot;, &quot;90.0.4398.1&quot;: &quot;846545&quot;, &quot;90.0.4398.0&quot;: &quot;846545&quot; // ...} Step_2寻找不同 os 对应的 position：position/position-Mac.json etc. getPositionWithOsList1$ node ./src/getPositionWithOsList.js positionUrl====&gt;position/position-Mac.json position-Mac.json: position-Mac.json1234567[ &quot;15734&quot;, &quot;15749&quot;, &quot;15839&quot;, &quot;15942&quot; // ...] Step_3结合step_1与step_2的数据生成最终文件：ver-pos-os/version-position-Mac.json verPosOsGen.js1$ node ./src/verPosOsGen version-position.json &amp;&amp; position/position-os.json ===&gt; ver-pos-os/version-position-Mac.json etc. ver-pos-os.json: ver-pos-os.json1234567{ &quot;90.0.4398.1&quot;: &quot;846545&quot;, &quot;90.0.4398.0&quot;: &quot;846545&quot;, &quot;90.0.4396.2&quot;: &quot;845872&quot;, &quot;90.0.4396.1&quot;: &quot;845872&quot; // ...} json stepsjson-steps123all-version.json -&gt; version-position.json -&gt; -&gt; ver-pos-[os].json position-[os].json -&gt; Step_4 数据存储：将上述steps中生成的json文件夹下的数据复制到chromium-history-dataSource仓库中，留作备份。 网页发布：将ver-pos-os/version-position-Mac.json复制到前端代码仓库:chromium-history-page public文件夹下，并且发布前端代码至chromium-history-page的gh-pages分支上 至此打开网页即可看到谷歌浏览器的历史版本。🚀🚀🚀 参考链接 仓库代码参考：chromium-history-version-crawler","link":"/articles/2021/04/06/download-chromium-history-version/"},{"title":"export 与 export default 的区别","text":"本文将介绍 export 与 export default 的差异性。 1. export default 在一个模块里只能有一个，但是 export 可以有多个123456789// model.jslet e1 = 'export 1';let e2 = 'export 2';let e3 = 'export 3';let e4 = 'export 4';export { e2 };export { e3 };export { e4 };export default e1; 1234567// 使用模块的run.jsimport e1, { e2, e3, e4 } from './model.js';console.log(e1);console.log(e2);console.log(e3);console.log(e4); 1234567run.js运行结果$ node run.jsexport 1export 2export 3export 4 如果在model.js再添加一个export default 12let e5 = 'export e5';export default e5; 123456$ node run.jsfile:///Users/xxx/workspace/model.js:11export default e5 ^^^^^^^^^^^SyntaxError: Identifier '.default' has already been declared 2. 模块中通过export 导出的(属性或者方法)可以修改，但是通过export default导出的不可以修改基本类型： 123456789// model.jslet e1 = 'export 1';let e2 = 'export 2';export function modifyFunc() { e1 = 'export 1 modified'; e2 = 'export 2 modified';}export { e2 };export default e1; 1234567// 使用模块的run.jsimport e1, { e2, modifyFunc } from './model.js';console.log(e1);console.log(e2);modifyFunc();console.log(e1);console.log(e2); 12345$ node run.jsexport 1export 2export 1export 2 modified Babel 编译后代码 123456789101112131415161718'use strict';Object.defineProperty(exports, '__esModule', { value: true,});exports.modifyFunc = modifyFunc;exports.default = exports.e2 = void 0;let e1 = 'export 1';let e2 = 'export 2';exports.e2 = e2;function modifyFunc() { e1 = 'export 1 modified'; exports.e2 = e2 = 'export 2 modified';}var _default = e1;exports.default = _default; 对象 123456789let e1 = { v1: 'v1' };let e2 = { v2: 'v2' };export function modifyFunc() { e1 = { v1: 'v1 modified' }; e1.v1 = 'v1 next modified'; e2 = { v22: 'v2 modified' };}export { e2 };export default e1; 1234567// 使用模块的run.jsimport e1, { e2, modifyFunc } from './model.js';console.log(e1);console.log(e2);modifyFunc();console.log(e1);console.log(e2); 12345$ node run.js{ v1: 'v1' }{ v2: 'v2' }{ v1: 'v1' }{ v22: 'v2 modified' } Babel 编译后代码 12345678910111213141516171819202122232425262728'use strict';Object.defineProperty(exports, '__esModule', { value: true,});exports.modifyFunc = modifyFunc;exports.default = exports.e2 = void 0;// model.jslet e1 = { v1: 'v1',};let e2 = { v2: 'v2',};exports.e2 = e2;function modifyFunc() { e1 = { v1: 'v1 modified', }; e1.v1 = 'v1 next modified'; exports.e2 = e2 = { v22: 'v2 modified', };}var _default = e1;exports.default = _default; 首先需要了解到： ES6 中模块通过export和export default暴露出来的属性或者方式并不是普通的赋值或者引用，它们是对模块内部定义的标志符类似指针的绑定。 对于一个导出的属性或者方法，在什么地方导出不重要，在什么时候导入也不重要，重要的是:访问这这个绑定的时候的当前值。 123456789// model.jslet e1 = 'export 1';let e2 = 'export 2';export { e2 };export default e1;e1 = 'export 1 modified';setTimeout(() =&gt; { e2 = 'export 2 modified';}, 1000); 1234567// 使用模块的run.jsimport e1, { e2 } from './model.js';console.log(e1);console.log(e2);setTimeout(() =&gt; { console.log('-----later-----', e2);}, 5000); 1234$ node run.jsexport 1export 2-----later----- export 2 modified Babel 编译后代码 12345678910111213141516'use strict';Object.defineProperty(exports, '__esModule', { value: true,});exports.default = exports.e2 = void 0;// model.jslet e1 = 'export 1';let e2 = 'export 2';exports.e2 = e2;var _default = e1;exports.default = _default;e1 = 'export 1 modified';setTimeout(() =&gt; { exports.e2 = e2 = 'export 2 modified';}, 1000); 但是，export是绑定到标识符，改变标志符的值，然后访问这个绑定，得到的是新值；export default绑定的是标志符指向的值，如果修改标志符指向另一个值，这个绑定的值不会发生变化。 如果想修改默认导出的值，可以使用export {e1 as default}这种方法。 1234// model.jslet e1 = 'export 1';export { e1 as default };e1 = 'export 1 modified'; 123// 使用模块的run.jsimport e1 from './model.js';console.log(e1); 123$ node run.jsexport 1 modified Babel 编译后代码 12345678910'use strict';Object.defineProperty(exports, '__esModule', { value: true,});exports.default = void 0;// model.jslet e1 = 'export 1';exports.default = e1;exports.default = e1 = 'export 1 modified'; 3. export default与export语法差异。 export var e1='...' 是合法语句，但是export default var e2='...'是不合法的（let和const也一样）。 export default可以直接添加标识符导出，例如export default e2;export如果要导出已经声明的表示符,必须使用{},例如export {e1},注意：这里{}不是声明一个对象。 可查看例子源码","link":"/articles/2021/06/03/export-export-default/"},{"title":"工程化配置 git commit 规范","text":"如果你团队的 git commit 信息紊乱，太过糟糕，觉得有必要统一规范 commit格式，又或者你是一个强迫症患者，有必要让 commit 信息整整齐齐的展示。那么，你可以往下瞅瞅。 本文使用的插件版本 pkg123456{ &quot;@commitlint/cli&quot;: &quot;^12.0.1&quot;, &quot;@commitlint/config-conventional&quot;: &quot;^12.0.1&quot;, &quot;husky&quot;: &quot;4.3.8&quot;, &quot;standard-version&quot;: &quot;^9.1.1&quot;} git commit 规范格式现在比较大众化的 commit 格式无非有两种： git12$ &lt;commit-type&gt;[(commit-scope)]: &lt;commit-message&gt;$ &lt;commit-icon&gt;: &lt;commit-message&gt; &lt;commit-type&gt; 常见为： chore：构建配置相关。 docs：文档相关。 feat：添加新功能。 fix：修复 bug。 perf：性能相关。 refactor：代码重构，一般如果不是其他类型的 commit，都可以归为重构。 revert：分支回溯。 style：样式相关。 test：测试相关。 [(commit-scope)] 可选，表示范围，例如：refactor(cli)，表示关于 cli 部分的代码重构。 &lt;commit-message&gt; 提交记录的信息，有些规范可能会要求首字母大写。 &lt;commit-icon&gt; 用图标来替代 &lt;commit-type&gt; 所表示的功能。 具体规范信息格式在这里查看（这里不做过多阐述） 用于 commit 规范的工具 commitizen commitlint gitmoji 本文主要讲述第二种(commitlint)使用方法，如想使用更多请查看demo commitlint 使用yarn1$ yarn add @commitlint/config-conventional @commitlint/cli --D 在专门的 commitlint 配置文件 commitlint.config.js 中配置如下： commitlint.config.js123module.exports = { extends: ['@commitlint/config-conventional'],}; 类似于 eslint，commitlint 还支持类似于 .commitlintrc.js、.commitlintrc.json、.commitlintrc.yml 名称的配置文件，又或者在 package.json 中添加 commitlint 字段。 然后安装 husky，这是为了添加 git hooks，使得 git commit 也能够符合 commit 规范。 yarn1$ yarn add husky --dev 在 package.json 中配置 husky 钩子： (v1.0.1版本以后为HUSKY_GIT_PARAMS，v0.14.3为GIT_PARAMS) package.json1234567{ &quot;husky&quot;: { &quot;hooks&quot;: { &quot;commit-msg&quot;: &quot;commitlint -e $HUSKY_GIT_PARAMS&quot; } }} 上面的操作如果都成功的话，那么你使用 git commit 命令时，就必须老老实实的使用符合 commitlint 规范的信息了 standard-version 使用yarn1$ yarn add standard-version -D standard-version是帮助项目自动生成ChangeLog、升版本、打tag的工具，它基于semver和Conventional Commits规范。（PS：配合git commit规范化食用更加。 当执行server-version命令后，它会自动完成以下操作： 取得当前版本（比如package.json里面的version字段），升版本：1.0.0 =&gt; 1.1.0 或者 1.0.0 =&gt; 2.0.0等（如何升级可以由参数控制） 基于commits生成ChangeLog文件 提交一个commit，包含ChangeLog和版本变更的文件 打tag 以上功能都是可配置跳过的，对应：bump、changelog、commit、tag。比如在配置文件中按照如下配置，就可以跳过打tag操作： 12345{ &quot;skip&quot;: { &quot;tag&quot;: true }} 为standard-version添加配置有两种方式： 目前使用的配置文件如下，其它配置参考官方文档： .versionrc.js1234567891011121314151617181920212223242526272829303132333435363738394041424344// https://github.com/conventional-changelog/conventional-changelog-config-spec/blob/master/versions/2.1.0/README.mdmodule.exports = { // 跳过一些操作 bump、changelog、commit、tag skip: { // 不跳过打tag操作 tag: false, }, //types为Conventional Commits标准中定义，目前支持 //https://github.com/conventional-changelog/commitlint/tree/master/%40commitlint/config-conventional types: [ { type: 'feat', section: '新特性' }, { type: 'fix', section: 'Bug修复' }, { type: 'docs', section: '文档' }, { type: 'chore', section: '配置项', hidden: true }, { type: 'style', section: '格式', hidden: true }, { type: 'refactor', section: '重构', hidden: true }, { type: 'perf', section: '性能', hidden: true }, { type: 'test', section: '测试', hidden: true }, { type: 'build', section: '构建', hidden: true }, { type: 'ci', section: 'CI', hidden: true }, { type: 'revert', section: '回滚', hidden: true }, ], //compare 链接 推荐自行修改为仓库地址 如 compareUrlFormat: '{{host}}/{{owner}}/{{repository}}/compare/{{previousTag}}...{{currentTag}}', //hash链接 推荐自行修改为仓库地址 如 https://github.com/MrSeaWave/commit-standard-demo/commit/{{hash}} commitUrlFormat: '{{host}}/{{owner}}/{{repository}}/commit/{{hash}}', //issue链接 issueUrlFormat: '{{host}}/{{owner}}/{{repository}}/issues/{{id}}', //server-version自动commit的模板 releaseCommitMessageFormat: 'build: v{{currentTag}}版本发布', //需要server-version更新版本号的文件 bumpFiles: [ { filename: 'MY_VERSION_TRACKER.txt', // The `plain-text` updater assumes the file contents represents the version. type: 'plain-text', }, { filename: 'package.json', // The `json` updater assumes the version is available under a `version` key in the provided JSON document. type: 'json', }, ],}; package.json 配置: package.json12345678&quot;scripts&quot;: { ..., &quot;release&quot;: &quot;standard-version&quot;, &quot;release:major&quot;: &quot;standard-version --release-as major&quot;, &quot;release:minor&quot;: &quot;standard-version --release-as minor&quot;, &quot;release:patch&quot;: &quot;standard-version --release-as patch&quot;, &quot;release:prerelease&quot;: &quot;standard-version --prerelease&quot; } PS: standard-version 有很多其他的特性，这里不过多涉及， 有兴趣的可以自行尝试。也可以查看此demo 参考链接 Git 的学与记：工程化配置 commit 规范 代码风格自动化","link":"/articles/2021/03/31/git-commit-ci/"},{"title":"Git提交信息规范","text":"Git 每次提交代码，都要写 Commit message（提交说明） 1$ git commit -m &quot;hello world&quot; 上面代码的-m 参数，就是用来指定 commit mesage 的。 如果一行不够，可以只执行git commit，就会跳出文本编辑器，让你写多行. 1$ git commit Commit message 的格式每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。 12345&lt;Header&gt;&lt;Body&gt;&lt;Footer&gt; 其中，Header 是必需的，Body 和 Footer 可以省略。 HeaderHeader 部分只有一行，包括三个字段：type（必需）、scope（可选）、subject（必需）。 1&lt;type&gt;: &lt;subject&gt; typetype 用于说明 commit 的类别，只允许使用下面 7 个标识。 feat：新功能（feature） fix：修补 bug docs：文档（documentation） style： 格式（不影响代码运行的变动） refactor：重构（即不是新增功能，也不是修改 bug 的代码变动） test：增加测试 chore：构建过程或辅助工具的变动 subjectsubject 是 commit 目的的简短描述，不超过 50 个字符。 以动词开头，使用第一人称现在时，比如 change，而不是 changed 或 changes 第一个字母小写 结尾不加句号（.） BodyBody 部分是对本次 commit 的详细描述，可以分成多行。下面是一个范例。 1234567More detailed explanatory text, if necessary. Wrap it toabout 72 characters or so.Further paragraphs come after blank lines.- Bullet points are okay, too- Use a hanging indent 有两个注意点。 使用第一人称现在时，比如使用 change 而不是 changed 或 changes。 应该说明代码变动的动机，以及与以前行为的对比。 FooterFooter 部分只用于两种情况： 关联 Issue 关闭 Issue 关联 Issue本次提交如果和摸个 issue 有关系则需要写上这个，格式如下： 1Issue #1, #2, #3 关闭 Issue如果当前提交信息解决了某个 issue，那么可以在 Footer 部分关闭这个 issue，关闭的格式如下： 1Close #1, #2, #3 Revert还有一种特殊情况，如果当前 commit 用于撤销以前的 commit，则必须以revert:开头，后面跟着被撤销 Commit 的 Header。 1234revert: feat(pencil): add 'graphiteWidth' optionThis reverts commit 667ecc1654a317a13331b17617d973392f415f02. Body 部分的格式是固定的，必须写成 This reverts commit &amp;lt;hash&gt;.，其中的hash是被撤销 commit 的 SHA 标识符。 如果当前 commit 与被撤销的 commit，在同一个发布（release）里面，那么它们都不会出现在 Change log 里面。如果两者在不同的发布，那么当前 commit，会出现在 Change log 的Reverts小标题下面。 例子12345678910feat: 添加了分享功能给每篇博文添加了分享功能- 添加分享到微博功能- 添加分享到微信功能- 添加分享到朋友圈功能Issue #1, #2Close #1 使用软件进行 commit 规范化 JS: commit-demo 参考文档 Commit message 和 Change log 编写指南 我的提交信息规范","link":"/articles/2021/03/31/git-commit-message/"},{"title":"git仓库的代理","text":"因为种种原因，github访问很困难，仓库代码的提交比较受限，因此想到通过挂代理的方式让代码可以正常提交。 首先第一步，肯定需要shdowsocks代理工具。 其次 全局设定： http1$ git config --global http.proxy http://127.0.0.1:1087 https1$ $ git config --global https.proxy https://127.0.0.1:1087 or 只针对特定仓库设定： http1$ git config http.proxy http://127.0.0.1:1087 https1$ git config https.proxy https://127.0.0.1:1087 注：127.0.0.1:1087是因为","link":"/articles/2021/04/02/git-proxy/"},{"title":"git-pull-default","text":"问题背景当使用 git 版本为 2.27.0 以上时，使用git pull命令出现以下的警告： 123456789101112hint: Pulling without specifying how to reconcile divergent branches ishint: discouraged. You can squelch this message by running one of the followinghint: commands sometime before your next pull:hint:hint: git config pull.rebase false # merge (the default strategy)hint: git config pull.rebase true # rebasehint: git config pull.ff only # fast-forward onlyhint:hint: You can replace &quot;git config&quot; with &quot;git config --global&quot; to set a defaulthint: preference for all repositories. You can also pass --rebase, --no-rebase,hint: or --ff-only on the command line to override the configured default perhint: invocation. 该警告的中文版本文案描述如下： 12345678910warning: 不建议在没有为偏离分支指定合并策略时执行pull操作。您可以在执行下一次pull操作之前执行下面一条命令来抑制本消息：git config pull.rebase false # 合并（默认缺省策略）git config pull.rebase true # 变基git config pull.ff only # 仅快进您可以将 &quot;git config&quot; 替换为 &quot;git config --global&quot; 以便为所有仓库设置缺省的配置项。您也可以在每次执行 pull 命令时添加 --rebase、--no-rebase，或者 --ff-only 参数覆盖缺省设置。 解决方案先说结论： 若无特殊需求执行：git config pull.rebase false(默认) 如何解决问题在上述的警告文案描述中我们可以发现两个重要的 Git 配置信息pull.rebase和pull.ff。 pull.ff先来了解一下pull.ff 在《Git 官方文档-参考-pull.ff》文章中可以查看到它的定义： 当把pull.ff设置为false时，这个变量告诉 Git 在这种情况下(相当于执行命令git pull --no-ff)，如果执行不带选项的git pull命令时先尝试快进合并，如果不行再进行正常合并生成一个新的提交。 当把pull.ff设置为only时，只允许快进合并(相当于执行命令git pull --ff-only)，如果执行不带选项的git pull命令时，如果不能进行快进合并则终止当前操作。 如果将pull.ff设置为only，而执行不带选项的git pull命令被终止，其实可以使用带参数的git pull --no-ff或者git pull --rebase命令来执行pull操作。 pull.rebase在《Git 官方文档-参考-pull.base》文章中可查看pull.rebase的定义，此处只解释当选项pull.rebase的参数为true或者false时的定义： 当pull.rebase为 true 时，运行不带选项的命令git pull相当于执行git pull --rebase。 当pull.rebase为 false 时，运行不带选项的命令git pull不会被改变含义，即不会变基。如果想变基，需要在执行命令时显式地加上选项--rebase，即git pull --rebase。 理解git pull命令的原理及其各选项的含义git pull命令的原理git fetch会查询git remote中所有的远程仓库所包含分支的最新提交，并将其记录到.git/FETCH_HEAD文件中。 .git/FETCH_HEAD是一个版本链接，指向着目前已经从远程仓库取下来的所有分支的最新提交。 git pull命令等价于：先执行git fetch，再执行git merge FETCH_HEAD将远程仓库对应分支的最新提交合并到当前本地分支中。 git fetch &amp;&amp; git merge git pull命令中各选项的含义git pull常见的选项搭配： 不带任何选项的git pull命令：先尝试快进合并，如果不行再进行正常合并生成一个新的提交。 git pull --rebase命令：先尝试快进合并，如果不行再进行变基合并。 git pull --ff-only命令：只尝试快进合并，如果不行则终止当前合并操作。 git pull --no-ff命令：禁止快进合并，即不管能不能快进合并，最后都会进行正常合并生成一个新的提交。 理解git pull命令出现问题的原因 执行不带任何选项的git pull命令时，会产生三种歧义： git pull --ff-only、git pull --no-ff、git pull --rebase，而这三种 pull 方式的合并策略差异很大，即对整个分布式项目的版本管理有很大的影响作用。 而我们执行不带任何选项的git pull命令时，Git 就不知道我们到底想用哪种合并策略来执行git pull，因此 Git 会给出上述的警告文案，建议我们通过git config命令指定不带选项的git pull命令应该按照这三种合并策略的哪种来执行。 解决问题再次回顾问题描述： 12345678910warning: 不建议在没有为偏离分支指定合并策略时执行pull操作。您可以在执行下一次pull操作之前执行下面一条命令来抑制本消息：git config pull.rebase false # 合并（默认缺省策略）git config pull.rebase true # 变基git config pull.ff only # 仅快进您可以将 &quot;git config&quot; 替换为 &quot;git config --global&quot; 以便为所有仓库设置缺省的配置项。您也可以在每次执行 pull 命令时添加 --rebase、--no-rebase，或者 --ff-only 参数覆盖缺省设置。 首先理解什么是偏离分支： 当本地的分支落后于远程分支时，本地分支又自行修改项目文件生成了新的提交，这时本地分支再执行git pull命令就不能快进合并，并且还容易发生冲突。这时的本地分支便称为偏离分支，因为这时的本地分支的最新提交跟远程分支的最新提交不同，产生了偏离。 接着理解什么是合并策略： 合并策略便是 git merge --ff-only、git merge --no-ff、git merge --rebase这三种常见的合并策略，分别代表着快进合并、非快进普通合并、变基合并。 通过上述的解析，现在我们理解了为什么理解git pull命令出现问题的原因，因此只要我们在 Git 中配置选项pull.rebase或pull.ff的参数即可。配置后，即便我们再执行不带任何选项的git pull命令，也不会再出现上述的警告文案啦。 若无特殊需求执行：git config pull.rebase false(默认) 参考链接 Git 问题解决：warning: Pulling without specifying how to reconcile divergent branches is discouraged. Git 问题解决方案:不建议在没有为偏离分支指定合并策略时执行 pull 操作(Pulling without specifying how to reconcile divergent branches) git 合并操作总结","link":"/articles/2021/11/15/git-pull-default/"},{"title":"git-repository","text":"本文讲述如何上传本地代码到远程的空仓库。 Create a new repository123456git clone https://github.com/MrSeaWave/tem.gitcd temtouch README.mdgit add README.mdgit commit -m &quot;add README&quot;git push -u origin master Push an existing folder123456cd existing_foldergit initgit remote add origin https://github.com/MrSeaWave/tem.gitgit add .git commit -m &quot;Initial commit&quot;git push -u origin master Push an existing Git repository12345cd existing_repogit remote rename origin old-origingit remote add origin https://github.com/MrSeaWave/tem.gitgit push -u origin --allgit push -u origin --tags","link":"/articles/2021/06/03/git-repository/"},{"title":"如何使用Github Action 自动 lerna publish","text":"本文讲述的是如何利用Github Action自动化执行 lerna publish。 动机大家都明白，人是很懒的，自从接触到Github Action后我就在想，能不能解放自己的双手，让 Github 帮我来自动发包至 npm 仓库。由此引出了本文。 假设你对 Github Actions 已经有了最基本的了解。如果不太了解，可以参考往期文章：github-actions入门， 比如，你知道下面这个配置表示当 push 到 master 分支时会触发 action，作用是在 ubuntu 环境中把代码 checkout 出来，然后使用 node 14.X 先后执行 npm i 和 npm run test。 123456789101112131415161718192021222324name: teston: push: branches: [ master ]jobs: test: runs-on: ubuntu-latest strategy: matrix: node-version: [14.x] steps: - name: checkout uses: actions/checkout@main - name: use Node.js uses: actions/setup-node@v2 with: node-version: ${{ matrix.node-version }} - name: install run: npm i - name: test run: npm run test 那么接下来照葫芦画瓢开始针对publish 进行针对操作。 如何设置准备 Npm Token我们都知道，以往在发布 npm 包的时候，我们需要先运行 npm login 登录我们自己的账号，用来验证我们的身份，使用 Github Action 也要验证我们的身份，不过需要用另外一种方式—&gt;使用 npm token。 登录 npm 后，找到个人中心菜单里面的 “Access Tokens” 菜单，然后点击右上角的 “Generate New Token” 生成 token 按钮，生成一个新 token ，然后把新 token 复制出来，我们后面步骤要用到。 注：npm access token 有三种，但既有 publish 权限且可绕过 2FA 的只有 automation token。 放置 Npm Token找到你的 Github 项目，然后点击 Setting 选项，如图： 然后在左侧菜单中找到 Secrets ，在点击 New repository secret 按钮，创建一个新的秘钥，这里的 name 起名为 NPM_TOKEN，下面要用到，value 则是刚才 npm 中生成的 token， 如图， 设定针对 CI 使用的 npm scripts以下为 package.json 中的scripts设定： 12345{ &quot;scripts&quot;: { &quot;release&quot;: &quot;npm run build &amp;&amp; lerna publish --yes --no-verify-access&quot; }} 通常在发布之前会进行打包，所以这里把build 脚本放在一起来使用。 Lerna 在使用 npm 的 automation token 会遇到问题，必须使用 --no-verify-access 绕过。详情参考 issue。 设定 Github Actions前置条件已经完成，那么我们就可以在我们的本地项目中，创建 .github\\workflows\\auto-publish.yml 文件，内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# 自动发布name: Auto Publishon: push: # 针对指定分支 branches: - master # 针对指定文件修改，这里可参考https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#onpushpull_requestpaths paths: - 'packages/**/*.js' - 'packages/**/*.scss' - '**/package*.json' # 让你能够手动触发，方便测试，参考https://docs.github.com/en/actions/learn-github-actions/events-that-trigger-workflows#workflow_dispatch workflow_dispatch:jobs: auto-publish: runs-on: ubuntu-latest strategy: matrix: node-version: [14.x] steps: - name: Checkout uses: actions/checkout@main with: # 0 indicates all history for all branches and tags，保留所有历史，为了让lerna publish 时可以生成有效的change log fetch-depth: '0' # 设定node 环境 - name: Use Node.js uses: actions/setup-node@v2 with: node-version: ${{ matrix.node-version }} registry-url: https://registry.npmjs.org/ # 设定安装工具--&gt; yarn - name: Global install Yarn 🔨 run: npm install -g yarn - name: Print Env 📄 run: | echo &quot;node&quot; node -v echo &quot;npm&quot; npm -v echo &quot;yarn&quot; yarn -v # 安装依赖 - name: Install dependencies 📦️ run: yarn install - name: Setup credentials # lerna publish 后会提交代码到master分支，这里是为了配置 git 用户，区分用户 run: | git config --global user.email action@github.com git config --global user.name Github Action # run: | # git config --global user.email MrDaemon@outlook.com # git config --global user.name Sea - name: Publish 🚀 run: npm run release # 利用 automation token publish 至 npm，这里NPM_TOKEN 就是我们上文中设定的 env: NODE_AUTH_TOKEN: ${{secrets.NPM_TOKEN}} 到这里就全部设定完毕了。接下來只需要： 在 master 上修改指定文件夹代码，并 push。 触发 Github Actions 的 auto-publish job，它会运行脚本自动发布至 npm。 可参考：MrSeaWave/lerna-demo 可能你会有如下的疑问，lerna publish 后也会修改代码（如：package.json 修改），并 push 到 master，那么会不会在这个脚本上一直套娃，无限循环的运行呢？ 答案是不会的，官方解释如下: 参考链接 workflow-syntax-for-github-actions#onpushpull_requestpaths 用 Lerna 管理共同前端設定，並透過 Github Actions 自動發布至 npm Github Actions 实用参考","link":"/articles/2021/12/16/github-actions-auto-publish/"},{"title":"GitHub Actions 如何使用缓存","text":"前言在之前的文章中 《github-actions入门》《 如何使用Github Action 自动 lerna publish 》中，介绍了 Github Actions 的一些用法，其中在构建过程中，会安装很多第三方依赖，而这些依赖会很耗时，因此可以考虑是否有优化的空间，并不需要每次都重新下载，而是可以将这些依赖缓存起来，加快构建速度。 这里专门开一篇文章，来记录 Github Actions 的缓存优化相关的知识。 Cache在构建过程中，进行缓存，加快构建速度。 主要使用action/cache。 原理缓存大致原理就是把目标路径打包存储下来，并记录一个唯一 key。 下次启动时，根据 key 去查找。找到了就再按路径解压开。 缓存大小限制注意缓存有大小限制。对于免费用户，单个包不能超过 500MB，整个仓库的缓存不能超过 2G。 缓存运作流程该action主要包含三个属性： path: 需要缓存的文件的路径 key: 对缓存的文件指定的唯一表示 restore-key: 当 key 没有命中缓存时，用于恢复缓存 key 值的有序列表 下面以node项目为例，将node_modules缓存起来。 这里只列出关键步骤： 12345678910111213steps: - name: Cache node_modules id: cache-node-modules uses: actions/cache@v2 with: path: node_modules key: ${{ runner.os }}-${{ matrix.node-version }}-nodeModules-${{ hashFiles('package-lock.json') }}-${{ hashFiles('package.json') }} restore-keys: | ${{ runner.os }}-${{ matrix.node-version }}-nodeModules- - name: Install dependencies 📦️ if: steps.cache-node-modules.outputs.cache-hit != 'true' run: npm install 首先使用action/cache指定path和key； 这里的key包含 OS 信息、node 版本 和 package-lock.json和package.json文件的 hash 值，通常 OS 是固定下来的； 而一旦使用了新的第三方库，package-lock.json &amp; package.json的 hash 值就会改变，得到一个新的key； action/cache会抛出一个cache-hit的输出，如果找到对应key的缓存，值为true。 在随后的安装步骤中，可以使用if对cache-hit做判断。如果找到缓存就跳过，否则就安装依赖。 在第一次运行时，cache 找不到，执行npm install，在随后的 post cache 步骤中对node_modules做缓存。 第二次运行时，找到 cache, 则跳过npm install，直接使用缓存： 更多使用请参考官网 &amp; actions/cache &amp; Cache node - npm 参考链接 Caching dependencies to speed up workflows Cache Examples Qt 使用 github-Actions 缓存优化 Github Actions 总结","link":"/articles/2021/12/17/github-actions-cache/"},{"title":"GitHub Actions 如何手动触发","text":"前言GitHub Ac­tions 在早期可能是处于初级开发阶段，它的功能非常原生，甚至没有直接提供一个手动触发按钮。一般的触发方式为代码变动（push 、pull_request），发布文件（release）或者定时（schedule）等，这些属于自动触发方式。如果我们需要在 GitHub 仓库没有任何变动的情况下手动触发就需要使用一些奇技淫巧。经历了漫长的功能迭代，官方最终正式带来了手动触发功能，这也宣告了一个瞎折腾时代的结束，一个崭新的折腾时代开始。 手动触发workflow_dispatch在时隔多年后 GitHub Ac­tions 终于引入了一个手动触发的按钮，不过默认是不开启的，需要在 work­flow 文件中设置 workflow_dispatch 触发事件。一个最简单的例子： 12on: workflow_dispatch: 设置好触发事件后就能在相关 work­flow 的页面下看到 Run workflow 按钮。 需要注意的是，正如官网所说你的这个 workflow 必须是在默认分支上。 更复杂一点还可以实现在手动触发时填写参数，控制不同的工作流程或者直接改写某个环境变量等操作。目前官方文档已经相当完善，想要去深入可以去查看。 一个填写参数的例子： 123456789101112131415161718192021name: Manual Triggeron: # 手动触发事件 workflow_dispatch: inputs: logLevel: description: 'Log level' required: true default: 'warning' tags: description: 'Test scenario tags'jobs: printInputs: runs-on: ubuntu-latest steps: - run: | echo &quot;Log level: ${{ github.event.inputs.logLevel }}&quot; echo &quot;Tags: ${{ github.event.inputs.tags }}&quot; echo &quot;Inputs: ${{ toJson(github.event.inputs) }}&quot; 如果我们在配置中定义了参数，则手动执行时也会需要填参数。上面在workflow_dispatch下通过定义inputs设定参数。在jobs中我们则可以在github.event.inputs中取到对应的参数。下面是上述代码运行结果： repository_dispatchrepository_dispatch让用户通过 API 批量手动执行，这个 event 的主要作用是让其他的程序通过 api 调用，通过自定义事件类型来驱动执行，这个 event 对应的 workflow 也必须在默认分支下定义。具体可参考官方文档，下面是个简单例子 比如我们定义: 123on: repository_dispatch: types: [opened, deleted] 然后执行 http 请求: 12345curl \\-X POST \\-H &quot;Accept: application/vnd.github.v3+json&quot; \\https://api.github.com/repos/{owner}/{repo_name}/dispatches \\-d '{&quot;event_type&quot;:&quot;opened&quot;}' 那么就可以被执行了，其中的opened, deleted是我们自定义的事件名字，client_payload是我们自定义的额外信息数据。 运行如下： 12345678910curl --location --request POST 'https://api.github.com/repos/MrSeaWave/lerna-demo/dispatches' \\--header 'Accept: application/vnd.github.v3+json' \\--header 'Authorization: Bearer 自定义的github token' \\--header 'Content-Type: application/json' \\--data-raw '{ &quot;event_type&quot;: &quot;opened&quot;, &quot;client_payload&quot;: { &quot;text&quot;: &quot;my custom text here&quot; }}' 其中在Authorization一览中增加在github中申请的token，否则容易出现&quot;message&quot;: &quot;Not Found&quot;的结果，就像这个问题一样。 上面运行成功结果： 更多用法请关注 Github 官网~ 参考链接 workflow_dispatch manually-running-a-workflow repository_dispatch Create a repository dispatch event GitHub Actions 手动触发方式进化史 10 个你该了解的 GitHub Actions 进阶技巧 使用 GithubActions 自动化工作流","link":"/articles/2021/12/17/github-actions-manual-trigger/"},{"title":"remote Support for password authentication was removed on August 13, 2021","text":"本文主要介绍 github 开发人员在七夕搞事情：remote: Support for password authentication was removed on August 13, 2021. 问题描述如果你在七夕（没错就是 2021 年 8 月 14 日）的这一天刚好加班，又刚好去访问了全球最大的同性交友网站，又刚好去更新提交代码，又或你创建了一个新的仓库送给自己，又刚好想把这个仓库送给（push）github，你就刚好会遇到这个问题：remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead. 具体如下： 1234$ git pushremote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.remote: Please see https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ for more information.fatal: Authentication failed for 'https://github.com/MrSeaWave/blogs.git/' 这是什么情况，大概意思就是你原先的密码凭证从2021年8月13日开始就不能用了，必须使用个人访问令牌（personal access token），就是把你的密码替换成token！ github 为什么要把密码换成 token官方解释 修改为 token 的好处 令牌（token）与基于密码的身份验证相比，令牌提供了许多安全优势： 唯一： 令牌特定于 GitHub，可以按使用或按设备生成 可撤销：可以随时单独撤销令牌，而无需更新未受影响的凭据 有限 ： 令牌可以缩小范围以仅允许用例所需的访问 随机：令牌不需要记住或定期输入的更简单密码可能会受到的字典类型或蛮力尝试的影响 如何生成自己的 token 在个人设置页面，找到Setting 链接 2、选择设置Developer setting，选择个人访问令牌Personal access tokens，然后选中生成令牌Generate new token 设置 token 的有效期，访问权限等 选择要授予此令牌token的范围或权限。 要使用token从命令行访问仓库，请选择repo。 要使用token从命令行删除仓库，请选择delete_repo 其他根据需要进行勾选 生成令牌Generate token 注意：记得及时把你的 token 保存下来，因为你再次刷新网页的时候，你已经没有办法看到它了 之后用自己生成的token登录，把上面生成的token粘贴到输入密码的位置，然后成功push代码！ 1234567891011121314$ git pushUsername for 'https://github.com': MrSeaWavePassword for 'https://MrSeaWave@github.com':husky &gt; pre-push (node v14.17.5)---- push files ----Enumerating objects: 11, done.Counting objects: 100% (11/11), done.Delta compression using up to 4 threadsCompressing objects: 100% (5/5), done.Writing objects: 100% (6/6), 755 bytes | 755.00 KiB/s, done.Total 6 (delta 4), reused 0 (delta 0)remote: Resolving deltas: 100% (4/4), completed with 4 local objects.To https://github.com/MrSeaWave/blogs.git 5162910..388fa6f master -&gt; master 也可以 把token直接添加远程仓库链接中，这样就可以避免同一个仓库每次提交代码都要输入token了： git remote set-url origin https://&lt;your_token&gt;@github.com/&lt;USERNAME&gt;/&lt;REPO&gt;.git &lt;your_token&gt;：换成你自己得到的 token &lt;USERNAME&gt;：是你自己github的用户名 &lt;REPO&gt;：是你的仓库名称 例如： git remote set-url origin https://ghp_LJGJUevVou3FXXXXXXXXXXXXXX@github.com/MrSeaWave/blogs/ FAQ 如果 push 等操作没有出现输入密码选项，请先输入如下命令，之后就可以看到输入密码选项了 git config --system --unset credential.helper SourceTree也遇到类似问题 当SourceTree提交时遇到： 12345678910111213141516Pushing to https://github.com/MrSeaWave/MacApp.gitremote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.remote: Please see https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ for more information.fatal: Authentication failed for 'https://github.com/MrSeaWave/MacApp.git/'Pushing to https://github.com/MrSeaWave/MacApp.gitremote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.remote: Please see https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ for more information.fatal: Authentication failed for 'https://github.com/MrSeaWave/MacApp.git/'Pushing to https://github.com/MrSeaWave/MacApp.gitremote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.remote: Please see https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ for more information.fatal: Authentication failed for 'https://github.com/MrSeaWave/MacApp.git/'Pushing to https://github.com/MrSeaWave/MacApp.gitremote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.remote: Please see https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ for more information.fatal: Authentication failed for 'https://github.com/MrSeaWave/MacApp.git/' 可以git remote set-url origin https://&lt;your_token&gt;@github.com/&lt;USERNAME&gt;/&lt;REPO&gt;.git 也可以：（密码处填写token） 参考链接 Token authentication requirements for Git operations Creating a personal access token github 开发人员在七夕搞事情：remote: Support for password authentication was removed on August 13, 2021. GitHub 不再支持密码验证解决方案：SSH 免密与 Token 登录配置","link":"/articles/2021/08/29/github-login-token/"},{"title":"hexo 相关问题以及优化配置","text":"前言本文记录一些 hexo 出现的问题及其解决方案，以及相关配置 hexo 环境 env1234hexo: 5.3.0hexo-cli: 4.2.0os: Darwin 19.6.0 darwin x64node: 15.2.1 禁止爬虫跟踪外链搜索引擎的蜘蛛来爬取文章内容时，如果你的文章中有外部链接，它就会到外链的站点去爬取，有可能再也不会回来了。为了告诉搜索引擎不要跟踪这些外链，需要在这些链接标签中添加属性 rel=&quot;nofollow&quot; 或 rel=&quot;external nofollow&quot; 。 rel=&quot;nofollow&quot; 是通用格式，即是告诉搜索引擎不要跟踪此链接，rel=&quot;external nofollow&quot; 是更具体的写法，进一步告诉搜索引擎这是一个外部的链接，不要跟踪它。 我们可以使用 hexo-filter-nofollow 自动为 Hexo 博客中的外链添加 rel=&quot;external nofollow noreferrer&quot;的插件，从而改善你的网站的安全性和 SEO。 安装install1$ npm i hexo-filter-nofollow --save 编辑 _config.yml在 站点配置文件 _config.yml 末尾添加如下内容： _config.yml123456nofollow: enable: true field: site exclude: - 'exclude1.com' - 'exclude2.com' enable - 是否启用插件，默认值为 true field - 插件的处理范围，默认值为 site，可选 post 或 site post - 仅处理文章内容 site - 处理全站所有页面 exclude - 域名白名单，不同的子域名视为不同的域名（如 www） exclude1.com不包括 www.exclude1.com 或 en.exclude1.com 永久链接因链接层级过深、链接中包含中文、 title 变动导致链接也经常发生变动，这些都不利于 SEO 。 方法一：按照文件名称生成假设文章： md123456# source/_posts/lorem/hello-world.mdtitle: Hello World Pagedate: 2013-07-14 17:01:34categories: - foo - bar 根据官网介绍在_config.yml中设定： _config.yml123456# title: 文件名称 (relative to “source/_posts/“ folder)permalink: :title/# url:-----&gt; /lorem/hello-world/# name: 文件名称permalink: :name/# url:-----&gt; /hello-world/ 问题来了，如果按照文件名称生成永久链接的，我的文件格式都要是这类 英文字母.md 的格式。如果是中文中文.md那么就会变成/中文/，浏览器地址栏上很不美观，对 SEO 也不好。 有没有办法让 Markdown 文件用 你好世界.md 这类中文文件名保存，生成的永久链接格式又是 /hello-world/ 这种样式呢？ Markdown Front-matter 区域可以看到，我这里除了 title， date 以及 tags 外，自己添加了一个新的变量 customUrl ，这个新的变量用来保存每个文章的英文名字，这样一来可以有利于 SEO，二来可以缩短博客文章 URL 的层数。 front-matter123title: Hello World Page# 自定义的变量customUrl: custom-hello-world 再在 hexo 配置文件 _config.yml 中，把 permalink: 的值设为 :customUrl/ 。 _config.yml12permalink: :customUrl/# url:------&gt; /custom-hello-world/ 方法二：使用 hexo-abbrlink推荐使用插件 hexo-abbrlink 生成 permalink 。 安装install1$ npm install hexo-abbrlink --save 使用然后在配置文件_config.yml 中修改： _config.yml12345permalink: :abbrlink/#abbrlink配置abbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: dec # 进制：dec(default) and hex 执行 hexo clean &amp;&amp; hexo g 重新生成静态文件后，源文件 front-matter 中会包含 abbrlink: xxx 。 如果文章中未指定 abbrlink: xxx，将会根据算法随机生成数字 这样就确保了链接的唯一化，只要不修改 md 文件的 abbrlink 的值，url 就永久不会改变。 使用这种方法生成 permalink 时，在每次提交修改前，最好先执行 hexo clean &amp;&amp; hexo g，确保提交前你所有的文章的 front-matter 中都包含 abbrlink ，避免因 title 的改变导致生成 abbrlink 不一致（如果已存在 abbrlink，就不会重新生成，不论title 是否发生变化）。 如何引用自己撰写的文章文章中，有时候需要自己给自己引流，所以经常要引用自己的文章，最好的方法就是在生成系统之内直接引用。 Hexo 提供了 标签插件 来完成这个功能。 12{% post_path filename %}{% post_link filename [title] [escape] %} 在使用此标签时可以忽略文章文件所在的路径或者文章的永久链接信息、如语言、日期。 例如，在文章中使用 {% post_link how-to-bake-a-cake %} 时，只需有一个名为 how-to-bake-a-cake.md 的文章文件即可。即使这个文件位于站点文件夹的 source/posts/2015-02-my-family-holiday 目录下、或者文章的永久链接是 2018/en/how-to-bake-a-cake，都没有影响。 默认链接文字是文章的标题，你也可以自定义要显示的文本。 默认对文章的标题和自定义标题里的特殊字符进行转义。可以使用escape选项，禁止对特殊字符进行转义。 链接使用文章的标题 1{% post_link hexo-3-8-released %} Hexo 3.8.0 Released 链接使用自定义文字 1{% post_link hexo-3-8-released '通往文章的链接' %} 通往文章的链接 对标题的特殊字符进行转义 1{% post_link hexo-4-released 'How to use &lt;b&gt; tag in title' %} How to use tag in title 禁止对标题的特殊字符进行转义 1{% post_link hexo-4-released '&lt;b&gt;bold&lt;/b&gt; custom title' false %} bold custom title 注，使用 post_path 时不能用在 md 语法中 参考链接 Hexo 相关问题和优化 hexo-filter-nofollow - Hexo 官方的 nofollow 插件 Hexo 永久链接管理 永久链接（Permalinks） hexo-abbrlink 标签插件（Tag Plugins）","link":"/articles/2021/01/08/hexo-configuration/"},{"title":"如何在 Hexo 中对文章 md 文件分类","text":"本文将介绍如何在 Hexo 中对文章 md 文件按日期进行分类 起因在默认配置下，我们使用hexo new post [title]会在source/_post/目录下生成对应的markdown文件，当我们写的博客越来越多的时候，会发现，所有文章都是在source/_post/下，查找起来会不大方便，因此希望对它进行一个分类，但是在生成的文章链接上保持不变。 方法通过查看hexo 配置文档 发现： permalink 用于设置文章的永久链接格式new_post_name 新文章的文件名称 因此我们可以通过配置new_post_name让创建的文件按时间分类，其次可通过new命令指定创建时的文件路径(hexo new page --path about/me &quot;About me&quot;)，从而进行归类。 这里介绍new_post_name方法，我们可以指定： 12permalink: 'articles/:year/:month/:day/:name/'new_post_name: ':year/:title.md' 这时候每次运行hexo new post [title]时新建的文件将按年份存放，生成的 html 文件将会按照年月日展示，比如source/_post/2021/test.md对应的博客地址：2021/06/25/test/。 整理现在新建文章的路径我们是已经处理好了，那以前创建的文章是不是要一个个手动分类呢？这里参考此文章，我们可以使用终端进行处理： 思路为： 找出 2021 年的文章 移动到 2021 文件夹下 找出 2020 年的文章，按 1-2 步的方式处理…… 1234567891011# 进入_post目录cd source/_post# 创建一个2021年1月1日的文件，用于过滤出2018年的文章touch -t 202101010000 timestamp# 创建2021文件夹mkdir 2021# 将2021年的文章移到2021文件夹下for file in `find . -type f -newer timestamp`; do mv $file 2021 ; done# 删除刚才创建的用于过滤的文件rm timestamp 参考链接 如何在 Hexo 中对文章 md 文件分类","link":"/articles/2021/06/25/hexo-new-post-path/"},{"title":"Prettier: support &quot;overrides&quot; option on code styles import","text":"在直接调用 WebStorm 自带的 Prettier 去格式化 wxml / wxss / wxs 文件会提示： File xxx has unsupported type 猜想 Prettier 应该提供任意文件映射为任意已支持的文件类型的格式化配置。查阅官方文档后：Setting the parser option，于是有了下面配置。 prettierrc123456789101112131415161718192021222324{ &quot;prettier&quot;: { &quot;overrides&quot;: [ { &quot;files&quot;: &quot;*.wxml&quot;, &quot;options&quot;: { &quot;parser&quot;: &quot;html&quot; } }, { &quot;files&quot;: &quot;*.wxss&quot;, &quot;options&quot;: { &quot;parser&quot;: &quot;css&quot; } }, { &quot;files&quot;: &quot;*.wxs&quot;, &quot;options&quot;: { &quot;parser&quot;: &quot;babel&quot; } } ] }} 于是在某个小程序文件中再次尝试调用 WebStorm 自带的 Prettier，发现依然是那个错误提示，重启也无果。。但是 vscode 却可以正常使用了。 又试了下手动在命令行里敲： 1npx prettier xx --write 成功，于是判断问题出在 webstorm 上。 尝试修复： 全局安装 Prettier，这样方便跨项目复用（可选 Preferences - Tools - External Tools 点击当前窗口左下角 + 号 Name、Description 自己起一个吧 Program 里填写：Prettier 安装位置/bin-prettier.js Arguments 里填写：$FilePath$ --write Working directory 不用管，ok、apply 双连保存配置 以上步骤完成之后你就可以通过顶部菜单：Tools - External Tools - 你起的 Tool Name 来格式化当前的小程序文件了。再说说快捷键的配置步骤： Preferences - Keymap 当前窗口右上角搜索你创建的 Tool Name 在搜索结果里选中它 Add Keyboard Shortcut 吧！ 参考链接 WebStorm 微信小程序代码提示 + Prettier 代码格式化 Prettier: support “overrides” option on code styles import","link":"/articles/2021/04/14/idea-prettier/"},{"title":"Husky hooks skipped","text":"在sourceTree遇到使用husky 会报错的情况： error123....Can't find yarn in PATH:......Skipping pre-push hook 解决方案： add this in ~/.huskyrc: huskyrc1PATH=&quot;/usr/local/bin:$PATH&quot; 参考链接 Husky hooks skipped Commit hooks are skipped due to PATH issues","link":"/articles/2021/04/02/husky-error-gui/"},{"title":"IDEA粘贴多行代码时，总是自动缩进","text":"当我们在使用 IntelliJ IDEA 去粘贴多行代码时，会发现总是自动缩进，或者被格式化。 这时候我们可以去如下位置进行设置，来取消这种行为。 settings —&gt;&gt; Eidtor —&gt;&gt; General —&gt;&gt; smart keys —&gt;&gt; reformat on paste 选择: NONE 注：可以直接搜索 reformat on paste","link":"/articles/2021/12/13/idea-reformat-on-paste/"},{"title":"rust 安装","text":"Rust 通常被称为 rust-lang。Rust 是一个由 Mozilla Research 赞助的通用的、多范式、现代的、跨平台和开源系统编程语言。 它旨在实现安全性、速度和并发性等目标。 Rust 在语法上与 C++ 相似，但它的设计者希望它在保持性能的同时提供更好的内存安全性。 Rust 目前在许多组织中使用，例如 Firefox、Chef、Dropbox、Oracle、GNOME 等。 如何在 Mac 中安装 Rust 语言？我们可以通过多种方式安装 Rust，但以下是官方推荐的安装方式。 install12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485$ curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | shinfo: downloading installerWelcome to Rust!This will download and install the official compiler for the Rustprogramming language, and its package manager, Cargo.Rustup metadata and toolchains will be installed into the Rustuphome directory, located at: /Users/xmly/.rustupThis can be modified with the RUSTUP_HOME environment variable.The Cargo home directory located at: /Users/xmly/.cargoThis can be modified with the CARGO_HOME environment variable.The cargo, rustc, rustup and other commands will be added toCargo's bin directory, located at: /Users/xmly/.cargo/binThis path will then be added to your PATH environment variable bymodifying the profile files located at: /Users/xmly/.profile /Users/xmly/.zshenvYou can uninstall at any time with rustup self uninstall andthese changes will be reverted.Current installation options: default host triple: x86_64-apple-darwin default toolchain: stable (default) profile: default modify PATH variable: yes1) Proceed with installation (default)2) Customize installation3) Cancel installation&gt;info: profile set to 'default'info: default host triple is x86_64-apple-darwininfo: syncing channel updates for 'stable-x86_64-apple-darwin'info: latest update on 2020-12-31, rust version 1.49.0 (e1884a8e3 2020-12-29)info: downloading component 'cargo' 4.1 MiB / 4.1 MiB (100 %) 3.3 MiB/s in 1s ETA: 0sinfo: downloading component 'clippy'info: downloading component 'rust-docs' 13.8 MiB / 13.8 MiB (100 %) 2.3 MiB/s in 6s ETA: 0sinfo: downloading component 'rust-std' 21.1 MiB / 21.1 MiB (100 %) 2.3 MiB/s in 9s ETA: 0sinfo: downloading component 'rustc' 50.8 MiB / 50.8 MiB (100 %) 2.3 MiB/s in 22s ETA: 0sinfo: downloading component 'rustfmt'info: installing component 'cargo'info: using up to 500.0 MiB of RAM to unpack componentsinfo: installing component 'clippy'info: installing component 'rust-docs' 13.8 MiB / 13.8 MiB (100 %) 3.4 MiB/s in 4s ETA: 0sinfo: installing component 'rust-std' 21.1 MiB / 21.1 MiB (100 %) 3.6 MiB/s in 5s ETA: 0sinfo: installing component 'rustc' 50.8 MiB / 50.8 MiB (100 %) 7.4 MiB/s in 7s ETA: 0sinfo: installing component 'rustfmt'info: default toolchain set to 'stable-x86_64-apple-darwin' stable-x86_64-apple-darwin installed - rustc 1.49.0 (e1884a8e3 2020-12-29)Rust is installed now. Great!To get started you need Cargo's bin directory ($HOME/.cargo/bin) in your PATHenvironment variable. Next time you log in this will be doneautomatically.To configure your current shell, run:source $HOME/.cargo/env 运行以下命令配置当前 shell。 source1$ source $HOME/.cargo/env 运行以下命令验证已安装的 Rust 版本。 rust version12$ rustc --versionrustc 1.49.0 (e1884a8e3 2020-12-29) 如何测试 Rust 编程语言安装 Rust 后，请按照以下步骤检查 Rust 语言是否正常工作。 创建一个文件并添加以下代码并保存。确保 Rust 文件始终以 .rs 扩展名结尾。 index1234$ vim index.rsfn main() { println!(&quot;Hello World&quot;);} 运行以下命令编译 rust 代码。 rust1$ rustc index.rs 上面的命令将在同一目录中创建一个可执行的 Rust 程序。 ls1234$ ls -lhtotal 760-rwxr-xr-x 1 xmly staff 375K 1 20 10:45 index-rw-r--r-- 1 xmly staff 41B 1 20 10:36 index.rs 运行 Rust 可执行文件得到输出。 run12$ ./indexHello World 好了！正常工作了。 参考链接 Rustup for managing Rust versions rust","link":"/articles/2021/01/20/install-rust/"},{"title":"如何杀死 lcasensor 进程","text":"本文讲述如何杀死 lcasensor（内网的监控软件，敏感数据监控）这个进程。 一下操作均是在 MacOs 环境下运行。 1. 定位进程信息1$ ps aux |grep didi 找到 4 个相似进程： /opt/didi/lca/bin/lcasensor /opt/didi/lca/bin/lcaupdater /opt/didi/lca/bin/LCAService /opt/didi/lca/bin/lcaagent 2. 检查自动启动目录 /Library/LaunchDaemons /Library/LaunchAgents ~/Library/LaunchAgents /System/Library/LaunchDaemons /System/Library/LaunchAgents 找到 4 份配置文件： /Library/LaunchAgents/com.didi.lca.lcaagent.plist /Library/LaunchDaemons/com.didi.lca.lcasensor.plist /Library/LaunchDaemons/com.didi.lca.lcaservice.plist /Library/LaunchDaemons/com.didi.lca.lcaupdater.plist 3. 修改自动启动选项分别修改com.didi.lca.*.plist的内容，主要改下面 2 个地方。 请确认修改以后的效果是：KeepAlive=false，RunAtLoad=false com.didi.lca.*.plist1234&lt;key&gt;KeepAlive&lt;/key&gt;&lt;false/&gt;&lt;key&gt;RunAtLoad&lt;/key&gt;&lt;false/&gt; 4. 重新启动电脑验证检查一下进程信息，确认进程已经停止运行 1$ ps aux |grep didi 删除上述提到的相关文件即可避免再次运行 1234$ sudo rm -rf /Library/LaunchAgents/com.didi.lca.*.plist$ sudo rm -rf /Library/LaunchDaemons/com.didi.lca.*.plist$ sudo rm -rf /opt/didi/lca$ sudo rmdir /opt/didi End! 🎉🎉🎉 参考链接 知乎","link":"/articles/2021/04/16/kill-lcasensor/"},{"title":"koa 静态资源处理","text":"本文将介绍 koa 静态资源处理。 如今有静态资源（dist/index.html）： 12345678910111213&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot; /&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no&quot; /&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;root-slave-container&quot;&gt;Hello World&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 和dist/index.js 1console.log('Hello World'); koa-static如果网站提供静态资源（图片、字体、样式表、脚本……），为它们一个个写路由就很麻烦，也没必要。koa-static模块封装了这部分的请求，起到了静态文件托管的作用。 示例代码如下： 12345678import Koa from 'koa';import path from 'path';import koaStatic from 'koa-static';const app = new Koa();app.use(koaStatic(path.resolve(__dirname, '../dist')));app.listen(3000); 运行上述代码后访问http://localhost:3000，在浏览器上即可看到这个网址内容，默认加载index.html文件。 访问http://localhost:3000/index.js Koa 会在静态资源目录下查找文件，所以不会把静态目录作为 URL 的一部分。 虚拟静态目录如果要给静态资源文件创建一个虚拟的文件前缀(实际上文件系统中并不存在) ，可以使用koa-mount中间件指定一个虚拟的静态目录。 koa-mount 是一个将中间件挂载到指定路径的 Koa 中间件。它可以挂载任意 Koa 中间件. 语法如下： 123import koaMount from 'koa-mount';app.use(koaMount('/koa-static', koaStatic(path.resolve(__dirname, '../dist')))); 访问http://localhost:3000/koa-static即可看到文件内容， 访问http://localhost:3000/koa-static/index.js 小 Tip：在部署打包好的 react 项目时，前端使用的是 HTML5 的 history，页面一刷新就 404 了，所以后端配置koa-history-api-fallback中间件来支持：（中间件实现的功能是如果 当 URL 匹配不到任何静态资源，返回指定的页面（中间件默认返回的是 index.html，配置参考文档） 12345678import historyApiFallback from 'koa-history-api-fallback';// 加载路由信息app.use(router.routes());app.use(router.allowedMethods());app.use(historyApiFallback());app.use(koaStatic(path.resolve(__dirname, '../public'))); historyApiFallback 一定要放在所有接口路由后面，否则所有接口都是返回 index.html 了。historyApiFallback 一定要在静态资源前面，否则资源找不到 koa-static-cache这个中间件的目的也是帮助我们托管静态资源文件。按照配置的路径在浏览器的 URL 地址中输入带prefix前缀的路径就能访问到 static 目录下的文件。和koa-static区别是： 示例代码： 1234567import koaStaticCache from 'koa-static-cache';app.use( koaStaticCache(path.resolve(__dirname, '../dist'), { prefix: '/koa-static', // 如果当前请求的url是以 /koa-static 开始，则作为静态资源请求 })); 当我们访问http://localhost:3000/koa-static/index.html，这个时候中间件就会将我们的请求代理到dist文件夹下的index.html，读取文件，自动识别 MIME 类型，然后进行响应。 访问http://localhost:3000/koa-static/index.js 参考链接 koa-static koa-mount Koa : what is the difference between koa-route and koa-mount. When should I use each? koa-static-cache koa-history-api-fallback react+koa 实现登陆、聊天、留言板功能后台","link":"/articles/2021/07/15/koa-static/"},{"title":"koa后端数据校验","text":"对每个接口的传入参数进行校验，是一个 Web 后端项目的必备功能，本文将介绍 koa 中如何使用joi进行数据格式检验。 安装 Joi1$ yarn add Joi 接下来将以对register的user进行后端数据校验为例 创建数据校验中间件middlewares/validator.js 12345678910111213141516171819/** * @desc 数据校验中间件 * @param {function} validateFunc validators 里的校验器函数 */function validatorMiddleware(validateFunc) { return async function validator(ctx, next) { const { error } = validateFunc(ctx.request.body); if (error) { console.log('校验器【 %s 】，数据校验失败', validateFunc.name); console.error(error); // 使用joi时的自定义错误||joi提供的错误展示 ctx.body = error.message || error.details[0].message; return; } await next(); };}export default validatorMiddleware; 创建 User 校验规则，并校验src/validators/user.js 123456789101112131415161718/** * 校验用户数据格式 * @param {Object} data 用户数据 */export function userValidator(data) { const schema = Joi.object({ userName: Joi.string() .min(2) .max(255) .pattern(/^[a-zA-Z][a-zA-Z0-9_]+$/) .required(), password: Joi.string() .pattern(/^[a-zA-Z0-9]{3,30}$/) .error(new Error('密码格式不对，请重新设定')), repeat_password: Joi.ref('password'), }); return schema.validate(data);} 注册接口使用数据校验中间件，传入 userValidator 校验 Usersrc/routes/user.js 12345678910import Router from '@koa/router';import validatorMiddleware from '../middlewares/validator';import { handleUserRegister } from '../controllers/user';import { userValidator } from '../validators/user';const router = new Router({ prefix: '/user' });router.post('/register', validatorMiddleware(userValidator), handleUserRegister);export default router; 更多校验方法 ajv：基于JSON Schema的数据校验库 JSON Schema： JSON Schema 并不是某个库，只是一种标准，简单的来说就是通过 json 格式来描述数据，而 ajv 就是对 JSON Schema 的具体实现之一. class-validator：采用注解的方式进行校验，底层使用的是老牌的校验包validator.js，配合ts语法进行使用。 routing-controllers ：使用ts构建的一个帮助很方便处理router的框架 参考链接 Koa+TypeScript 从 0 到 1 实现简易 CMS 框架（三）：用户模型、参数校验与用户注册接口 使用 class-validator 替换 Joi 包的方法 koa 后端数据校验-ajv 项目重构记录","link":"/articles/2021/07/06/koa-validator/"},{"title":"lerna","text":"lerna-demoLerna 是一个工具，它优化了使用 git 和 npm 管理多包存储库的工作流。 本文通过一个示例讲述了如何基于 Lerna 管理多个 package，并和其它工具整合，打造高效、完美的工作流，最终形成一个最佳实践。 工作的两种模式 fixed是默认模式，在这模式下所有包都使用lerna.json里的version字段值。 independent模式是每个包使用独立的版本号 Fixed/Locked mode (default)vue,babel 都是用这种，在 publish 的时候,会在 lerna.json 文件里面&quot;version&quot;: &quot;0.1.0&quot;依据这个号，进行增加，只选择一次，其他有改动的包自动更新版本号。 Independent modelerna init --independent 初始化项目。 lerna.json 文件里面&quot;version&quot;: &quot;independent&quot;, 每次 publish 时，您都将得到一个提示符，提示每个已更改的包，以指定是补丁、次要更改、主要更改还是自定义更改。 项目构建init12$ mkdir lerna-demo &amp;&amp; cd $_$ npx lerna init 生成以下文件 1234lerna-demo/ packages/ package.json lerna.json 增加 packages创新一些新的 pkg 123456789101112$ cd packages$ mkdir pkg-a pkg-b pkg-c$ cd pkg-a$ npm init --y$ cd pkg-b$ npm init --y或者使用$ lerna create pkg-d --y 项目结构如下 123456789101112131415161718192021$ tree.├── README.md├── lerna.json├── package.json└── packages ├── pkg-a │ └── package.json ├── pkg-b │ └── package.json ├── pkg-c │ └── package.json └── pkg-d ├── README.md ├── __tests__ │ └── pkg-d.test.js ├── lib │ └── pkg-d.js └── package.json7 directories, 10 files 依赖管理 yarn是lerna的最佳搭档。 lerna默认使用npm作为安装依赖包工具，但也可以选择其他工具。把 npm 替换成 yarn 只需在 lerna 的配置文件添加两行代码即可，配置完以后立刻顺畅百倍。 1234567// lerna.json{ &quot;packages&quot;: [&quot;packages/*&quot;], // 配置package目录 &quot;version&quot;: &quot;independent&quot;, &quot;npmClient&quot;: &quot;yarn&quot;, &quot;useWorkspaces&quot;: true // 使用yarn workspaces} 配置 package.json 使用yarn workspaces 1234567891011{ &quot;name&quot;: &quot;root&quot;, &quot;private&quot;: true, // root禁止发布 &quot;devDependencies&quot;: { &quot;lerna&quot;: &quot;^4.0.0&quot; }, &quot;workspaces&quot;: [ // 配置package目录 &quot;packages/*&quot; ]} 安装依赖只要在项目主目录下执行 1$ yarn install yarn 会自动读取 workspace 配置，就能自动安装、处理、软链接各个子包的依赖，统一放在根目录下。也可以使用 lerna 的安装命令 1$ lerna bootstrap 但可能不如 yarn 的包管理机制好用，可以看这篇文章《Lerna 的依赖管理及 hoisting 浅析》 增删依赖123$ lerna add chalk # 为所有 package 增加 chalk 模块$ lerna add semver --scope pkg-a # 为 pkg-a 增加 semver 模块$ lerna add pkg-a --scope pkg-b # 增加内部模块之间的依赖 or 123$ yarn workspaces run add chalk # 为所有 package 增加 chalk 模块$ yarn workspace pkg-a add semver # 为 pkg-a 增加 semver 模块$ yarn workspace pkg-b add pkg-a@1.0.0 # 这里必须加上版本号，否则报错,将pkg-a作为pkg-b的依赖 更多请查看lerna add 对应的 yarn 的更多命令： 主项目添加依赖 1$ yarn add [packageName] -W -D -W 是指定在项目根目录执行命令 删除公共依赖 1$ yarn remove -W -D [packageName] 给所有子项目增删依赖 12$ yarn workspaces run add [packageName]$ yarn workspaces run remove [packageName] 给某个项目增删依赖 1$ yarn workspace [packageNameA] add [packageNameB] // packageNameA是指定安装依赖的包名，packageNameB是公共的包名或者项目内的包名 1$ yarn workspace [packageName] remove [packageName] 当项目依赖凌乱的时候，可以使用命令清理依赖 1$ lerna clean 其余还有一些命令如下，更多命令参考lerna 123lerna ls // 列出仓库中包信息lerna changed // 查看项目变动lerna exec // 执行命令 12lerna run &lt; script &gt; -- [..args] # 运行所有包里面的有这个script的命令$ lerna run --scope my-component test 1yarn workspaces info // 查看项目内信息 构建使用lerna run命令构建项目 1$ lerna run build // 会执行子包中build命令构建 发布123$ lerna publish # 发布自上一个版本以来发生了变化的包$ lerna publish from-git # 发布当前提交中标记的包$ lerna publish from-package # 发布注册表中没有最新版本的包 在运行时，该命令做了下面几件事中的一个： 发布自上一个版本以来更新的包(背后调用了 lerna version)。 这是 lerna 2.x 版本遗留下来的。 发布在当前提交中标记的包(from-git)。 发布在最新提交时注册表中没有版本的包(from-package)。 发布在前一次提交中更新的包(及其依赖项)的“金丝雀(canary)”版。 注意Lerna 永远不会发布标记为 private 的包（package.json 中的”private“: true） 在所有的发布过程中，都有生命周期在根目录和每个包中运行(除非使用了--ignore-scripts)。 请查看每个包的配置以了解发布作用域限定的包、自定义注册表和自定义标记的详细信息。 不支持只发布某个 packagelerna 官方不支持仅发布某个 package，见 issues/1691，如果需要，只能自己手动的进入 package 进行发布，这样 lerna 自带的各种功能就需要手动完成且可能和 lerna 的功能相互冲突 由于 lerna 会自动的监测 git 提交记录里是否包含指定 package 的文件修改记录，来确定版本更新，这要求设置好合理的 ignore 规则（否则会造成频繁的，无意义的某个版本更新），好处是其可以自动的帮助 package 之间更新版本 例如如果pkg-b 依赖了 pkg-a，如果 pkg-a 发生了版本变动，会自动的将 pkg-b 的对 pkg-a 版本依赖更新为 pkg-a 的最新版本。 如果 pkg-b 发生了版本变动，对 pkg-a 并不会造成影响。 版本迭代lerna 通过 version 命令来为各个模块进行版本迭代。基本命令如下： 1$ lerna version [major | minor | patch | premajor | preminor | prepatch | prerelease] 如果不选择此次迭代类型，则会进入交互式的提示流程来确定此次迭代类型 例如： 123$ lerna version 1.0.1 # 按照指定版本进行迭代$ lerna version patch # 根据 semver 迭代版本号最后一位$ lerna version # 进入交互流程选择迭代类型 自动生成 CHANGELOG当您使用这个参数运行时，lerna version将使用传统的提交规范来确定版本并生成 CHANGELOG.md 文件 1$ lerna version --conventional-commits 自动确立了版本更新 经测试 version_bump 是依赖于文件检测和 subject 结合，并不依赖于 scope，scope 的作用是用来生成 changelog 的吧，即如果是修改了 pkg-b 的文件，但是 commit 记录写的是 fix(pkg-a)，lerna 是会生成 pkg-b 的版本更新，并不会去更新 pkg-a 的版本 手动选择发布版本如果 git commit message 发现不太靠谱，且无法修改的话，那么需要手动的确认新版本，version 默认是手动选择版本 1$ lerna version version 成功后会自动的推送到主分支 lerna version 自动生成的提交格式为“ publish xxx”,并不符合 conventional-commit 规范，因此需要加以修改，我们通过 message 参数可以修改自动生成的提交记录 123456789101112// lerna.json{ &quot;packages&quot;: [&quot;packages/*&quot;], &quot;version&quot;: &quot;independent&quot;, &quot;npmClient&quot;: &quot;yarn&quot;, &quot;useWorkspaces&quot;: true, &quot;command&quot;: { &quot;publish&quot;: { &quot;message&quot;: &quot;chore: publish&quot; } }} 之后可以用lerna publish发布新包 1$ lerna publish from-git // 显式发布在当前提交中标记的包 例子项目例子可参考eg 参考链接 lerna lerna 中文 基于 Lerna 管理 packages 的 Monorepo 项目最佳实践 基于 lerna 和 yarn workspace 的 monorepo 工作流 Lerna 中文教程详解 大前端项目代码重用，也许 lerna 是最好的选择 使用 Lerna、Yarn 管理 Monorepo 项目","link":"/articles/2021/06/07/lerna/"},{"title":"myBlogTestEmail","text":"","link":"/articles/2021/01/05/myBlogTestEmail/"},{"title":"Mac 上的 APP 推荐","text":"值得推荐的 mac 软件 开发相关 IntelliJ IDEA ：编辑器 vscode：编辑器 sourceTree：git GUI Charles：HTTP 信息抓包工具 Postman：测试 Web API &amp; HTTP iTerm2：强大的终端神器 Sequel Pro：My Sql 管理页面 Redis Desktop Manager：Redis 管理页面 Dash 程序员的 API 文档查询利器 Mac OS 命令行工具 Homebrew：Mac OS（或 Linux）缺失的软件包的管理器。 Oh My Zsh：oh my zsh Fig： 终端自动补全工具 基本软件 Alfred: Mac 效率神器 Bartender （Menubar 菜单栏管理小助手 系统清理 CleanMyMac X App Cleaner &amp; Uninstaller（应用深度清理卸载工具 Typora: （markdown 书写工具 Upic（Mac 图床客户端 截图 xnip (截图): 带有滚动效果，推荐 LICEcap （录制 gif）：Gif 录制软件，简单小巧快捷。 Kap (屏幕录像&amp;&amp;录制 gif) 带有点击效果，推荐 gifox (录制 gif，无点击效果，备选方案) Snipaste （截图备选方案） Text Scanner（将图片上文字内容转换成可编辑文本） 时间管理 OmniFocus Recess （时间管理，强制休息） drawio：线上流程图软件 团队管理，任务管理 teambition 笔记、知识库 notion 思维导图 xmind 幕布 TeamView（远程操作 1Password （保存密码 outlook（邮箱 The Unarchiver（解压缩工具 Vpn ShadowsocksX-NG-R8 ClashX Pro，源码地址ClashX 屏保 机械手表 WatchOSX 倒计时 CountDown 翻页式钟表 fliqlo Sip（屏幕取色工具 colorsnapper: 屏幕取色工具 IINA（视频播放工具 Paste（剪贴板 ScreenFlow（屏幕录像&amp;&amp;视频剪辑 KeyCastr（显示按键操作 Xscope (强大的设计辅助软件，标尺) Reeder（RSS 订阅器新闻阅读器 Yoink（一款移动复制文件效率工具","link":"/articles/2021/03/23/mac-apps/"},{"title":"如何在MAC上安装Mysql","text":"本文将介绍如何在 Mac 上安装 Mysql。 官网安装包下载所有平台的 MySQL 下载地址为： MySQL 下载 。 挑选你需要的 MySQL Community Server 版本及对应的平台。 因为我本地是X86_64，（通过$ uname -m查看）所以这里选择了： 查找以前的版本并下载这一步并不算难，秉持着完整记录的想法还是记一下，不需要的可以绕过。 安装 根据安装包的指示一步步下载就可以了，如果下载 8 以上的版本在这一步的时候注意选择第二项，下载 5 的话记得保存一下系统给的默认密码（下载过程会弹出提示框） 安装成功后，可在系统偏好设置中看到 MySQL，（8 版本是一头小海豚，5 的是一个圆齿轮） 打开如下： 环境变量配置安装成功后，使用 mysql 命令会报：command not found 的错误，是因为还没有配置环境变量。 配置环境变量首先要知道你使用的 Mac OS X 是什么样的 Shell，打开终端，输入：echo $SHELL 我这里用的是zsh，所以直接在~/.zshrc里增加环境变量，在最下方增加 12345# mysql Pathexport PATH=${PATH}:/usr/local/mysql/bin# 快速启动、结束MySQL服务, 可以使用alias命令，可以不加alias mysqlstart='sudo /usr/local/mysql/support-files/mysql.server start'alias mysqlstop='sudo /usr/local/mysql/support-files/mysql.server stop' 最后保存退出，并在终端输入：source ~/.zshrc 回车执行，运行环境变量 最后在终端输入mysql -u root -p启动 MySQL，（安装地址是/usr/local/mysql） 使用 homebrew 安装 MySQL可以参考 homebrew 安装 MySQL，这里不再阐述。 卸载可以参考 Mac 下干净彻底地卸载 MySQL，这里不再阐述。 参考链接 MySQLZ MySQL 安装 MySQL 安装（Mac 版） 小白入门：MySQL 超详细安装教程（mac 版）","link":"/articles/2021/12/31/mysql-install/"},{"title":"Nodejs 中基于 Stream 的多文件合并实现","text":"最近在做关于node 端的上传文件时，碰到一个问题，如何将多个文件合并至一个文件呢？（前端上传的切割文件在服务端进行合并） 单文件合并的 Stream 操作将'./test1.txt'写入'./test2.txt'中， 创建一个可读流 readable 一个可写流 writeable，通过管道 pipe 将可写流绑定到可读流，一个简单的 Stream 操作就完成了，运行代码就会发现，'./test1.txt'已经写入至'./test2.txt' 12345678const fs = require('fs');// 创建文件流const readable = fs.createReadStream('./test1.txt');// 创建写入流const writeable = fs.createWriteStream('./test2.txt');// 数据写入文件readable.pipe(writeable); 其中pipe 这个方法有两个参数： 1readable.pipe(destination[, options]) destination：写入数据的目标，是一个可写流对象，也就是一个数据写入的目标对象，例如，上面我们创建的 writeable 就是一个可写流对象 options： end：当读取结束时结束写入。 默认值: true。 默认情况下我们是不需要手动调用写入流 writeable 的 end 方法进行关闭。 如果我们设置 pipe 中 end 为 false 时， 写入的目标流将会一直处于打开状态， 此时就需要监听可读流的 end 事件，结束之后手动调用可写流的 end 事件。 12345678910// 数据写入文件// readable.pipe(writeable);readable.pipe(writeable, { end: false,});readable.on('end', () =&gt; { // 关闭流之前立即写入最后一个额外的数据块 writeable.end('写入结束');}); 注意：如果可读流期间发生什么错误，则写入的目标流将不会关闭，例如：process.stderr 和 process.stdout 可写流在 Nodejs 进程退出前将永远不会关闭，所以需要监听错误事件，手动关闭可写流，防止内存泄漏。 多个文件通过 Stream 操作合并为一个文件利用可读流的 pipe 中 end 为 false ，保持写入流一直处于打开状态。一开始可写流处于打开状态，直到所有的可读流结束，我们再将可写流给关闭。 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162const { createReadStream, readdirSync, createWriteStream } = require('fs');const path = require('path');/** * @desc 多个文件通过Stream合并为一个文件 * 设置可读流的 end 为 false 可保持写入流一直处于打开状态，不自动关闭 * 直到所有的可读流结束，再将可写流给关闭。 * @param {object[]} fileList * @param {string} fileList.filePath 待合并的文件路径 * @param {WriteStream} fileWriteStream 可写入文件的流 * @returns {*} */function streamMergeRecursive(fileList, fileWriteStream) { if (!fileList.length) { console.log('-------- WriteStream 合并完成 --------'); // 最后关闭可写流，防止内存泄漏 // 关闭流之前立即写入最后一个额外的数据块(Stream 合并完成)。 fileWriteStream.end('---Stream 合并完成---'); return; } const data = fileList.shift(); const { filePath: chunkFilePath } = data; console.log('-------- 开始合并 --------\\n', chunkFilePath); // 获取当前的可读流 const currentReadStream = createReadStream(chunkFilePath); // 监听currentReadStream的on('data'),将读取到的内容调用fileWriteStream.write方法 // end:true 读取结束时终止写入流,设置 end 为 false 写入的目标流(fileWriteStream)将会一直处于打开状态，不自动关闭 currentReadStream.pipe(fileWriteStream, { end: false }); // 监听可读流的 end 事件，结束之后递归合并下一个文件 或者 手动调用可写流的 end 事件 currentReadStream.on('end', () =&gt; { console.log('-------- 结束合并 --------\\n', chunkFilePath); streamMergeRecursive(fileList, fileWriteStream); }); // 监听错误事件，关闭可写流，防止内存泄漏 currentReadStream.on('error', (error) =&gt; { console.error('-------- WriteStream 合并失败 --------\\n', error); fileWriteStream.close(); });}/** * @desc 合并文件入口 * @param {string} sourceFiles 源文件目录 * @param {string} targetFile 目标文件 */function streamMergeMain(sourceFiles, targetFile) { // 获取源文件目录(sourceFiles)下的所有文件 const chunkFilesDir = path.resolve(__dirname, sourceFiles); const list = readdirSync(chunkFilesDir); const fileList = list.map((name) =&gt; ({ name, filePath: path.resolve(chunkFilesDir, name), })); // 创建一个可写流 const fileWriteStream = createWriteStream(path.resolve(__dirname, targetFile)); streamMergeRecursive(fileList, fileWriteStream);}streamMergeMain('./chunkFiles', './targetFile.png'); 运行代码后生成指定文件targetFile.png 参考链接 createReadStream createWriteStream readable.pipe(destination[, options]) 使用 koa-body 实现文件上传下载 Node.js Stream 流的使用及实现总结 Nodejs 中基于 Stream 的多文件合并实现","link":"/articles/2021/12/30/node-combine-more-files/"},{"title":"Node.js设置定时任务","text":"在实际开发项目中，会遇到很多定时任务的工作。比如：定时导出某些数据、定时发送消息或邮件给用户、定时备份什么类型的文件等等&gt; 一般可以写个定时器，来完成相应的需求，在 node.js 中自已实现也非常容易，接下来要介绍的是node-schedule来完成定时任务 安装1$ yarn add node-schedule 基础用法使用 schedule.scheduleJob() 即可创建一个定时任务，一个简单的上手示例： 123456const schedule = require('node-schedule');// 当前时间的秒值为 10 时执行任务，如：2021-7-8 13:25:10let job = schedule.scheduleJob('10 * * * * *', () =&gt; { console.log('job schedule', new Date());}); 时间数值按下表表示: 123456789* * * * * *┬ ┬ ┬ ┬ ┬ ┬│ │ │ │ │ |│ │ │ │ │ └ 星期几，取值：0 - 7，其中 0 和 7 都表示是周日│ │ │ │ └─── 月份，取值：1 - 12│ │ │ └────── 日期，取值：1 - 31│ │ └───────── 时，取值：0 - 23│ └──────────── 分，取值：0 - 59└─────────────── 秒，取值：0 - 59（可选） 也可以指定一个具体的时间，如： 123456789const schedule = require('node-schedule');// 定义一个未来的时间let date = new Date(2021, 6, 13, 15, 50, 0);// 定义一个任务let job = schedule.scheduleJob(date, () =&gt; { console.log('job schedule', new Date());}); 进阶用法除了基础的用法，我们还可以使用一些更为灵活的方法来实现定时任务。 隔一段时间执行一次12345678910const schedule = require('node-schedule');// 定义规则let rule = new schedule.RecurrenceRule();rule.second = [0, 10, 20, 30, 40, 50]; // 每隔 10 秒执行一次 可使用 0/10 * * * * *// 启动任务let job = schedule.scheduleJob(rule, () =&gt; { console.log('job schedule', new Date());}); rule 支持设置的值有 second、minute、hour、date、dayOfWeek、month、year 等用法，如： 每秒执行1rule.second = [0,1,2,3......59]; 每分钟 0 秒执行1rule.second = 0; 每小时 30 分执行12rule.minute = 30;rule.second = 0; 每天 0 点执行123rule.hour = 0;rule.minute = 0;rule.second = 0; 每月 1 号的 10 点执行1234rule.date = 1;rule.hour = 10;rule.minute = 0;rule.second = 0; 每周一、周三、周五的 0 点和 12 点执行1234rule.dayOfWeek = [1, 3, 5];rule.hour = [0, 12];rule.minute = 0;rule.second = 0; 设定开始时间与结束时间12345const startTime = new Date(Date.now() + 5000);const endTime = new Date(startTime.getTime() + 5000);const job = schedule.scheduleJob({ start: startTime, end: endTime, rule: '*/1 * * * * *' }, function () { console.log('job schedule', new Date());}); 取消任务可以使用 cancel() 终止一个运行中的任务。 1job.cancel(); 注意：在使用 pm2 cluster 模式启动会导致定时任务多次执行，解决办法： pm2 启动会默认自带一个 'NODE_APP_INSTANCE' 的环境变量, 它从 0 开始自增, 永远不能能重复, 每一个 worker 拥有一个值 程序中启动定时任务, 或者执行方法的时候判断下if(process.env.NODE_APP_INSTANCE === '0'){// TO DO ...} 这样就可以在某个 worker 里执行一次（NODE_APP_INSTANCE 也可以在 pme.json 中重命名该变量名称 instance_var: 'INSTANCE_ID'） 最终封装代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293// 设定定时任务const schedule = require('node-schedule');// 解析cron表达式const parser = require('cron-parser');// 允许'0'号进程设定定时任务，防止 pm2 多实例冲突const isAllowWorkerSchedule = !process.env.NODE_APP_INSTANCE || process.env.NODE_APP_INSTANCE === '0';/** * @desc 解析cron表达式 * @param {string} cron cron 表达式 * @param {object} [options] 配置 * @return {string[]} */function parserCron(cron, options) { const interval = parser.parseExpression(cron, options); const dates = new Array(5).fill('').map((i) =&gt; interval.next().toString()); console.log('parserCron:\\n'); console.log(dates.join('\\n')); return dates;}/** * @desc 运行定时器 * @param {string} cron cron 表达式 * @param {function} func 函数 * @return {*} */function runScheduleCronStyle(cron, func) { console.log('进程process.env.NODE_APP_INSTANCE:', process.env.NODE_APP_INSTANCE); // 只在某个worker里运行，防止pm2 启动多个定时,(process.env.NODE_APP_INSTANCE === '0') if (!isAllowWorkerSchedule) { console.log('不允许开启定时器'); return; } console.log('开始定时器:', cron); parserCron(cron); const job = schedule.scheduleJob(cron, func); return job;}/** * @desc 运行指定时间内的定时器 * @param {object} d * @param {string} d.cron cron 表达式 * @param {Date} [d.startTime] 开始时间 * @param {Date} [d.endTime] 结束时间 * @param {function} func 函数 * @return {*} */function runAreaScheduleCronStyle({ cron, startTime, endTime }, func) { console.log('进程process.env.NODE_APP_INSTANCE:', process.env.NODE_APP_INSTANCE); // 只在某个worker里运行，防止pm2 启动多个定时,(process.env.NODE_APP_INSTANCE === '0') if (!isAllowWorkerSchedule) { console.log('不允许开启定时器'); return; } console.log('开始指定时间内定时器:', cron); parserCron(cron, { currentDate: startTime, endDate: endTime }); const job = schedule.scheduleJob({ rule: cron, start: startTime, end: endTime }, func); return job;}/** * @desc 取消当前的job任务 * @param job * @param {boolean} [reschedule] */function cancelScheduleJob(job, reschedule) { if (!isAllowWorkerSchedule) return; console.log('取消定时器'); job.cancel(reschedule);}const job = runScheduleCronStyle('0/10 * * * * *', () =&gt; { console.log('job--:' + new Date());});const jobArea = runAreaScheduleCronStyle( { cron: '0/10 * * * * *', startTime: new Date('2021/07/13 16:30'), endTime: new Date('2021/07/13 16:31:20') }, () =&gt; { console.log('jobArea--:' + new Date()); });const job2 = runScheduleCronStyle('0/20 * * * * *', () =&gt; { console.log('job2--:' + new Date());});// 一分钟后关闭setTimeout(() =&gt; cancelScheduleJob(job), 60 * 1000); 参考链接 Node.js 设置定时任务：node-schedule 模块的使用 如何解决 pm2 部署 nodejs 项目时 node-schedule 这类模块重复执行？ Nodejs 学习笔记（十二）— 定时任务（node-schedule) node-schedule","link":"/articles/2021/07/13/node-schedule/"},{"title":"node 端生成水印图片","text":"在项目中通常会出现给图片增加水印的需求，本文将介绍如何在使用 node 时处理图片，增加水印功能。 文字和图片不能直接合并，需要将文字先转换成图形，然后再将图形进行合并，大致步骤如下： 利用text-to-svg，将文字转成 SVG 图形； 利用sharp，将 SVG 图形与背景图片合并； 生成水印图片将文字转换为 SVG 图形，需要借助 Node 的模块text-to-svg，该模块能够将文字按照指定字体生成 SVG 图形 代码如下： 123456789101112131415161718/** * @desc 将水印文字转换成 svg，再转换成buffer * @param {string} text 水印文字 * @param {number} fontSize 字体大小 * @param {string} color 字体颜色 * @return {Buffer} */function text2SVG({ text, fontSize = 72, color = 'rgba(204,204,204,0.45)' }) { // 加载字体文件 const text2SVG = Text2SVG.loadSync(path.resolve(__dirname, '../../assets/PingFang-SC-Regular.ttf')); const options = { fontSize, anchor: 'top', // 坐标中的对象锚点 attributes: { fill: color }, // 文字颜色 }; const textSVG = text2SVG.getSVG(text, options); return Buffer.from(textSVG);} 这时候生成的水印图片是平行文字： 我们需要旋转 45 度后的图片： 代码如下： 123456789101112/** * @desc 水印图片旋转45度倾斜 * @param {string} text 水印文字 * @return {Promise&lt;Buffer|*&gt;} */async function rotateWatermarkBuffer(text) { // ` ${text} ` 增加下文字间距 const textBuffer = text2SVG({ text: ` ${text} ` }); return sharp(textBuffer) .rotate(45, { background: { r: 255, g: 255, b: 255, alpha: 0 } }) // 旋转45度，并且透明色 .toBuffer();} 合并图形用于合并图片的库有很多，比如gm、jimp、mapnik、sharp等，其中sharp是基于libvips库来实现的，性能是最高的，所以采用了 sharp 来合并图形。 123456789101112131415/** * @desc 入口文件 * @param {string|Buffer} img 图片本地路径或图片 Buffer 数据 * @param {string} text 水印文字 * @param {string} filepath 保存合成水印后的文件路径 * @return {Promise&lt;Object&gt;} */async function init({ img, text, filepath }) { const textBuffer = await rotateWatermarkBuffer(text); const imgInfo = await sharp(img) // 重复（tile）合并图像 .composite([{ input: textBuffer, tile: true }]) .toFile(filepath); return imgInfo;} 最终代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162const path = require('path');const sharp = require('sharp');const Text2SVG = require('text-to-svg');async function nodeGenWatermark({ img, text, filepath }) { /** * @desc 将水印文字转换成 svg，再转换成buffer * @param {string} text 水印文字 * @param {number} fontSize 字体大小 * @param {string} color 字体颜色 * @return {Buffer} */ function text2SVG({ text, fontSize = 72, color = 'rgba(204,204,204,0.45)' }) { const fontPath = path.resolve(__dirname, '../../assets/PingFang-SC-Regular.ttf'); // 加载字体文件 const text2SVG = Text2SVG.loadSync(fontPath); const options = { fontSize, anchor: 'top', // 坐标中的对象锚点 attributes: { fill: color }, // 文字颜色 }; const textSVG = text2SVG.getSVG(text, options); return Buffer.from(textSVG); } /** * @desc 水印图片旋转45度倾斜 * @param {string} text 水印文字 * @return {Promise&lt;Buffer|*&gt;} */ async function rotateWatermarkBuffer(text) { // ` ${text} ` 增加下文字间距 const textBuffer = text2SVG({ text: ` ${text} ` }); return sharp(textBuffer) .rotate(45, { background: { r: 255, g: 255, b: 255, alpha: 0 } }) // 旋转45度，并且透明色 .toBuffer(); } /** * @desc 入口文件 * @param {string|Buffer} img 图片本地路径或图片 Buffer 数据 * @param {string} text 水印文字 * @param {string} filepath 保存合成水印后的文件路径 * @return {Promise&lt;Object&gt;} */ async function init({ img, text, filepath }) { const textBuffer = await rotateWatermarkBuffer(text); const imgInfo = await sharp(img) // 重复（tile）合并图像 .composite([{ input: textBuffer, tile: true }]) .toFile(filepath); return imgInfo; } await init({ img, text, filepath });}nodeGenWatermark({ img: path.resolve(__dirname, '../../assets/chrome.png'), text: '水印', filepath: path.resolve(__dirname, '../../assets/output.png'),}); 至此，我们就实现了一个简单的给图片加水印的功能，让我们看看生成效果： 参考链接 sharp text-to-svg sharp 使用文档 node 文字生成图片 Node.js 服务端图片处理利器——sharp 进阶操作指南","link":"/articles/2021/07/13/node-watermark/"},{"title":"在 nodejs 中使用ES6","text":"本文将介绍如何在 nodejs 中使用 ES6 的功能。 在学习 JavaScript 语言，你会发现它有两种格式的模块。 一种是 ES6 模块，简称 ESM；另一种是 Node.js 专用的 CommonJS 模块，简称 CJS。这两种模块不兼容。 Node.js 是服务器端开发的 Javascript 标准平台。Node.js 模块处理的默认标准是CommonJS。，使用module.exports （导出） 和 require （导入）。对于 ES6 环境中的 Node.js，我们需要一个编译器将 ES6 转换为CommonJS 两种模块的差异ES6 模块和 CommonJS 模块有很大的差异。 语法上面，CommonJS 模块使用require()加载和module.exports输出，ES6 模块使用import和export。 用法上面，require()是同步加载，后面的代码必须等待这个命令执行完，才会执行。import命令则是异步加载，或者更准确地说，ES6 模块有一个独立的静态解析阶段，依赖关系的分析是在那个阶段完成的，最底层的模块第一个执行。 Node.js 的区分Node.js 要求 ES6 模块采用.mjs后缀文件名。也就是说，只要脚本文件里面使用import或者export命令，那么就必须采用.mjs后缀名。Node.js 遇到.mjs文件，就认为它是 ES6 模块，默认启用严格模式，不必在每个模块文件顶部指定&quot;use strict&quot;。 如果不希望将后缀名改成.mjs，可以在项目的package.json文件中，指定type字段为module。 123{ &quot;type&quot;: &quot;module&quot;} 一旦设置了以后，该目录里面的 JS 脚本，就被解释用 ES6 模块。 12# 解释成 ES6 模块$ node my-app.js 如果这时还要使用 CommonJS 模块，那么需要将 CommonJS 脚本的后缀名都改成.cjs。如果没有type字段，或者type字段为commonjs，则.js脚本会被解释成 CommonJS 模块。 总结为一句话：.mjs文件总是以 ES6 模块加载，.cjs文件总是以 CommonJS 模块加载，.js文件的加载取决于package.json里面type字段的设置。 注意，ES6 模块与 CommonJS 模块尽量不要混用。require命令不能加载.mjs文件，会报错，只有import命令才可以加载.mjs文件。反过来，.mjs文件里面也不能使用require命令，必须使用import。 CommonJS 模块加载 ES6 模块CommonJS 的require()命令不能加载 ES6 模块，会报错，只能使用import()这个方法加载。 123(async () =&gt; { await import('./es6-pkg.mjs');})(); 上面代码可以在 CommonJS 模块中运行。 require()不支持 ES6 模块的一个原因是，它是同步加载，而 ES6 模块内部可以使用顶层await命令，导致无法被同步加载。 ES6 模块加载 CommonJS 模块ES6 模块的import命令可以加载 CommonJS 模块，但是只能整体加载，不能只加载单一的输出项。 12345// 正确import packageMain from 'commonjs-package';// 报错import { method } from 'commonjs-package'; 这是因为 ES6 模块需要支持静态代码分析，而 CommonJS 模块的输出接口是module.exports，是一个对象，无法被静态分析，所以只能整体加载。 加载单一的输出项，可以写成下面这样。 12import packageMain from 'commonjs-package';const { method } = packageMain; FAQ当你的项目在配置 package.json 的 type为 model 后，且使用了 babel 可能会报错： 1Error while loading config - You appear to be using a native ECMAScript module configuration file, which is only supported when running Babel asynchronously 这是因为可能你的 babel 配置为 Javascript 文件扩展名 (babel.config.js)。 注： babel js 文件扩展支持.js，.mjs，.cjs babel.config.js and .babelrc.js behave like the .mjs equivalents when your package.json file contains the &quot;type&quot;: &quot;module&quot; option, otherwise they are exactly the same as the .cjs files. 因此对于你当前的项目。正确的文件扩展名是 .cjs 12345678910111213// babel.config.cjsmodule.exports = { presets: [ [ '@babel/preset-env', { targets: { node: 'current', }, }, ], ],}; 参考链接 Enabling ES6 Features (Import and Export Default) In Node.js with Babel Node.js 如何处理 ES6 模块 babel-config","link":"/articles/2021/08/29/node-with-es6/"},{"title":"oh-my-zsh","text":"本文将介绍一款顺手的shell —— zsh 主要介绍的是 oh my zsh 为什么是 zsh，其含义是： The last shell you’ll ever need! 可以理解为，一旦用上它，就别无所求了。跟 Bash 相比，Zsh 的补全功能强大了许多，可以自动补全命令、参数、文件名、进程、用户名、变量、权限符，等等…… 另外，还支持插件，通过插件又可以扩展出许多功能来。 Zsh 是什么 Zsh 是一款强大的虚拟终端，既是一个系统的虚拟终端，也可以作为一个脚本语言的交互解析器。 12345# 打开终端，在终端上输入:$ zsh --version# 这个命令来查看我们的电脑上是否安装了 Zsh# 端查询版本为： zsh 5.7.1 (x86_64-apple-darwin19.0) 终端查询版本为： zsh 5.7.1 (x86_64-apple-darwin19.0) 1234567891011121314# 查看系统当前 shell$ cat /etc/shells# List of acceptable shells for chpass(1).# Ftpd will not allow users to connect who are not using# one of these shells./bin/bash/bin/csh/bin/dash/bin/ksh/bin/sh/bin/tcsh/bin/zsh 因为 zsh 的默认配置极其复杂繁琐，让人望而却步，因此使用 Oh My Zsh 这个开源项目，让 zsh 配置降到 0 门槛。而且它完全兼容 bash 。所以，我们可以理解为 Oh My Zsh 是一个方便你配置和使用 Zsh 的一个开源工具。 Oh My Zsh 是什么 Oh My Zsh 是一款社区驱动的命令行工具，正如它的主页上说的，Oh My Zsh 是一种生活方式。它基于 zsh 命令行，提供了主题配置，插件机制，已经内置的便捷操作。给我们一种全新的方式使用命令行。 Oh My Zsh 是基于 zsh 命令行的一个扩展工具集，提供了丰富的扩展功能。 安装 Oh My Zsh 前提条件：必须已安装 zsh 如果是 linux 系统，首先你需要安装 zsh 123sudo yum install zsh或者sudo apt-get install zsh mac 系统下我们无需安装. 以下操作都是基于 Mac 系统。 安装 Oh My Zsh可以通过 curl 、wget、fetch 三种方式来安装，用一条命令即可安装。 Method Command curl sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot; wget sh -c &quot;$(wget -O- https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot; fetch sh -c &quot;$(fetch -o - https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot; 安装过程中输出如下： 1234567891011121314151617181920xxxx% sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;Cloning Oh My Zsh...Cloning into '/Users/xxxx/.oh-my-zsh'...remote: Counting objects: 831, done.remote: Compressing objects: 100% (700/700), done.remote: Total 831 (delta 14), reused 775 (delta 10), pack-reused 0Receiving objects: 100% (831/831), 567.67 KiB | 75.00 KiB/s, done.Resolving deltas: 100% (14/14), done.Looking for an existing zsh config...Found ~/.zshrc. Backing up to ~/.zshrc.pre-oh-my-zshUsing the Oh My Zsh template file and adding it to ~/.zshrc __ __ ____ / /_ ____ ___ __ __ ____ _____/ /_ / __ \\/ __ \\ / __ `__ \\/ / / / /_ / / ___/ __ \\ / /_/ / / / / / / / / / / /_/ / / /_(__ ) / / / \\____/_/ /_/ /_/ /_/ /_/\\__, / /___/____/_/ /_/ /____/ ....is now installed!Please look over the ~/.zshrc file to select plugins, themes, and options.p.s. Follow us at https://twitter.com/ohmyzsh.p.p.s. Get stickers and t-shirts at http://shop.planetargon.com. 卸载 Oh My Zsh 终端输入 ： 12$ uninstall_oh_my_zshAre you sure you want to remove Oh My Zsh? [y/N] Y 终端提示信息： 1234567Removing ~/.oh-my-zshLooking for original zsh config...Found ~/.zshrc.pre-oh-my-zsh -- Restoring to ~/.zshrcFound ~/.zshrc -- Renaming to ~/.zshrc.omz-uninstalled-20170820200007Your original zsh config was restored. Please restart your session.Thanks for trying out Oh My Zsh. It's been uninstalled. Zsh 常用设置跟 Bash 一样，Bash 的配置文件叫做.bashrc，Zsh 的配置文件，也放在用户当前目录，叫做.zshrc。 配置主题1234567$ vim ~/.zshrc# 找到 ZSH_THEME# robbyrussell 是默认的主题ZSH_THEME=&quot;robbyrussell&quot;# ZSH_THEME=&quot;样式名称&quot; 保存这个文件文件，重新打开终端。 查看主题名称 Oh My Zsh 默认自带了一些默认主题，存放在 ~/.oh-my-zsh/themes 目录中。我们可以查看这些主题 终端输入： 1$ cd ~/.oh-my-zsh/themes &amp;&amp; ls 更多主题设置 定制主题 Oh My Zsh,『 Agnoster 主题配置 』 Zsh 常用方法命令别名通过在.zshrc中配置alias，可以方便的为其他的命令设置别名，这是个很不错的功能。 比如跟 git 相关的： 123456789101112131415161718192021222324252627282930alias g='git'alias ga='git add'alias gaa='git add --all'alias gapa='git add --patch'alias gb='git branch'alias gba='git branch -a'alias gbda='git branch --merged | command grep -vE &quot;^(\\*|\\s*master\\s*$)&quot; | command xargs -n 1 git branch -d'alias gbl='git blame -b -w'alias gbnm='git branch --no-merged'alias gbr='git branch --remote'alias gbs='git bisect'alias gbsb='git bisect bad'alias gbsg='git bisect good'alias gbsr='git bisect reset'alias gbss='git bisect start'alias gco=&quot;git checkout&quot;alias gc=&quot;git commit -m&quot;alias gd='git diff'alias gf='git fetch'alias gs=&quot;git status&quot;alias gsm=&quot;git summary&quot;alias gl=&quot;git log&quot;alias gm=&quot;git merge&quot;alias gpl=&quot;git pull&quot;alias gps=&quot;git push&quot;alias grv='git remote -v'alias grb='git rebase' 比如push提交到远程git仓库的时候，就不必老老实实的输入 git push origin master 了，只需要输入 gps origin master 即可。于是 git pull 也简化成了 gpl , git commit -m 也简化成了 gc 切换目录在 Zsh 中，可以通过输入 . 号来跳转，比如： 直接输入.. 和 … 可以快速切换到上层和上上层目录 直接输入n+1个点，可以往上层跳转 n 层 进程 id 补全Zsh 的补全功能非常不错，除了一般的目录和文件名补全，还可以自动补全进程 ID。比如，我们通常要kill掉一个进程，得先用 ps -aux|grep process_name 先拿到进程 id，然后再 kill pid 来终止掉一个进程。在 Zsh 中可以直接这样：(记得按Tab键) 快速跳转Zsh 支持目录的快速跳转，我们可以使用 d 这个命令，列出最近访问过的各个目录，然后选择目录前面的数字进行快速跳转： 目录名简写与补全如果确切的知道我们要进入某一层目录，但是目录名比较长，没关系，Zsh 帮你搞定！ 比如我们要进入到 ~/workSpace/privateStudy/tem，我们只需要输入每个目录的首字母就行，然后按TAB键补全，Zsh 会帮你搞定剩下的： 常用命令参数补全Zsh 在行的，不光是目录名的补全，常用的命令参数，它也能给你提供参考：(记得按Tab键) 重复上一条命令输入 r ，可以很便捷的重复执行上一条命令。 Zsh 常用插件推荐Zsh 支持插件，通过插件扩展可以实现许多方便的功能。这里介绍一下我常用的几个 Zsh 插件： 12# vim ~/.zshrcplugins=(git autojump zsh-autosuggestions) 所有的 zsh 的插件都是在这里配置的，具体安装方法查看各个插件自己的 install zsh-autosuggestions命令自动提示插件，这个是个很有意思也很高效的插件。能记录平时你输入过的命令，下次再输入的时候，它会提前提示你，方便懒人。如果是你需要的命令，直接 → 搞定，来直接看看效果吧： 配合 item2 的Solarized dark主题时推荐ZSH_AUTOSUGGEST_HIGHLIGHT_STYLE='fg=23' autojumpautojump是一个目录直接快速跳转的效率工具，它会自动记录之前访问过的目录，并计算权重。用法也很简单 j directory_name 即可。比如我要访问 ~/workSpace/src ，只需要输入 j src 就行了…… zsh-syntax-highlightingzsh-syntax-highlighting为shell zsh提供语法突出显示。它允许高亮显示在zsh提示符下输入到交互式终端的命令。这有助于在运行命令之前检查它们，特别是在捕获语法错误方面。 Before: After: Tips Oh My Zsh 的自动更新提示误触关掉了解决办法 打开终端输入：upgrade_oh_my_zsh jsontoolsjsontools 格式化 json 数据的命令行工具 如下数据： 加上pp_json后，输入格式化后的 json 文件： 更多用法查看官网 参考链接 ohmyzsh 程序员内功系列–iTerm 与 Zsh 篇 Oh My Zsh, 『 安装 &amp; 配置 』 oh-my-zsh 配置你的 zsh 提高 shell 逼格终极选择 How to change zsh-autosuggestions color Mac 安装 oh my zsh 插件 Top 10 Oh My Zsh Plugins For Productive Developers","link":"/articles/2021/08/29/oh-my-zsh/"},{"title":"npm publish 过滤部分文件","text":"npm publish 的时候会把项目目录里面所有的文件都publish到npm仓库中， 但是往往有一部分目录和文件不想发布上去，比如项目的源码、编译脚本等等信息。 如何发布用户需要使用的相关文件呢？方法一：使用 .gitignore 设置忽略哪些文件.gitignore 设置的忽略文件，在 git 代码管理和 npm publish 都会被忽略 方法二：使用 .npmignore 设置忽略哪些文件.npmignore 的写法跟 .gitignore 的规则完全一样。若同时使用了 .npmignore 和 .gitignore，只有 .npmignore 会生效，优先级比较高。 方法三：使用 package.json 的 files 字段选择发布哪些文件直接在 package.json 中 files 字段设置发布哪些文件或目录。这个优先级高于 .npmignore 和 .gitignore。 PS：选择哪种方法，根据自己的需求而定。一般情况，使用方法三。 另：npm publish 默认的忽略规则 默认被忽略： .*.swp ._* .DS_Store .git .gitignore .hg .npmignore .npmrc .lock-wscript .svn .wafpickle-* config.gypi CVS npm-debug.log 默认被包含，即便设置忽略也无效 package.json README (and its variants) CHANGELOG (and its variants) LICENSE / LICENCE 参考链接 npm","link":"/articles/2021/12/10/npm-publish-filter/"},{"title":"优化 puppeteer","text":"本文将讲述如何优化puppeteer 什么是 puppeteer Puppeteer 是一个 Node 库，它提供了高级 API 来通过 DevTools 协议控制 Chromium 或 Chrome。 通过Puppeteer我们可以编写脚本模拟浏览器的相关行为，实现以下功能： 网页截图并保存为图片或 pdf 。 模拟表单提交，键盘输入，按钮点击，滑块移动等 dom 操作。 实现 UI 的自动化测试。 作为抓包工区对网页性能进行调试和分析。 编写定制化爬虫，解决传统 HTTP 抓取 SPA 页面难以处理异步请求的问题。 为什么要优化随着最近项目进度的复杂，项目在使用 Puppeteer 时遇到一些问题，这些问题包括：经常卡住，运行慢、卡，浏览器关不掉，CPU 和 内存 经常是满载运行的，特别是 CPU ，经常是 99% 的使用率。 Chromium 消耗最多的资源是 CPU，一是渲染需要大量计算，二是 Dom 的解析与渲染在不同的进程，进程间切换会给 CPU 造成压力（进程多了之后特别明显）。 其次消耗最多的是内存，Chromium 是以多进程的方式运行，一个页面会生成一个进程，一个进程占用 30M 左右的内存，大致估算 1000 个请求占用 30G 内存，在并发高的时候内存瓶颈最先显现。 优化最终会落在内存和 CPU 上（所有软件的优化最终都要落到这里），通常来说因为并发造成的瓶颈需要优化内存，计算速度慢的问题要优化 CPU。 优化点优化 Chromium 启动项 如果将 Dom 解析和渲染放到同一进程，肯定能提升时间（进程上下文切换的时间）。对应的配置是 single-process 部分功能 disable 掉，比如 GPU、Sandbox、插件等，减少内存的使用和相关计算。 代码如下： 123456789101112const browser = await puppeteer.launch({ headless: true, // 以 无头模式（隐藏浏览器界面）运行浏览器 args: [ '--disable-gpu', // GPU硬件加速 '--disable-dev-shm-usage', // 创建临时文件共享内存 '--disable-setuid-sandbox', // uid沙盒 '--no-first-run', // 没有设置首页。在启动的时候，就会打开一个空白页面。 '--no-sandbox', // 沙盒模式 '--no-zygote', '--single-process', // 单进程运行 ],}); 复用 browser每次请求都启动 Chromium，再打开 tab 页，请求结束后再关闭 tab 页与浏览器。 流程大致如下： 请求到达 -&gt; 启动 Chromium -&gt; 打开 tab 页 -&gt; 运行代码 -&gt; 关闭 tab 页 -&gt; 关闭 Chromium -&gt; 返回数据 真正运行代码的只是 tab 页面，理论上启动一个 Chromium 程序能运行成千上万的 tab 页，可不可以复用 Chromium 只打开一个 tab 页然后关闭呢？ 当然是可以的。 Puppeteer 提供了 puppeteer.connect() 方法，可以连接到当前打开的浏览器。而且puppeteer.connect比puppeteer.launch启动一个浏览器实例要快很多（参考) 流程如下： 请求到达 -&gt; 连接 Chromium -&gt; 打开 tab 页 -&gt; 运行代码 -&gt; 关闭 tab 页 -&gt; 返回数据 代码如下： 123456789101112131415// 使用缓存wsEndpointconst wsEndpoint = this.wsEndpoint;let browser;try { browser = !wsEndpoint ? await puppeteer.launch(config) : await puppeteer.connect({ browserWSEndpoint: this.wsEndpoint, });} catch (err) { browser = await puppeteer.launch(config);} finally { // 缓存wsEndpoint this.wsEndpoint = browser.wsEndpoint();} 在进一步优化是在程序启动时，初始化一定数量的无头浏览器，并保存 WSEndpoint 列表，当收到请求时，通过随机数做简单的负载均衡（利用多核特性）。 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839const config = { headless: true, args: [ '--disable-gpu', '--disable-dev-shm-usage', '--disable-setuid-sandbox', '--no-first-run', '--no-sandbox', '--no-zygote', '--single-process', ],};const MAX_WSE = 4; // 启动几个浏览器const WSE_LIST = []; // 存储browserWSEndpoint列表init();// 初始化function init() { (async () =&gt; { for (let i = 0; i &lt; MAX_WSE; i++) { const browser = await puppeteer.launch(config); WSE_LIST[i] = await browser.wsEndpoint(); } })();}// 使用场景app.get('/', function (req, res) { const tmp = Math.floor(Math.random() * MAX_WSE); (async () =&gt; { const browserWSEndpoint = WSE_LIST[tmp]; const browser = await puppeteer.connect({ browserWSEndpoint }); const page = await browser.newPage(); await page.goto('http://example.com'); await page.screenshot({ path: 'example.png' }); await page.close(); res.send('Hello World!'); })();}); 最终代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347/** * @desc Puppeteer 实例 * 请求到达 -&gt; 连接 Chromium -&gt; 打开 tab 页 -&gt; 运行代码 -&gt; 关闭 tab 页 -&gt; 返回数据 * */import puppeteer from 'puppeteer';import { htmlGenWaterMark } from './watermark';class PuppeteerHelper { constructor() { this.instance = null; // 启动4个浏览器 this.MAX_WSE = 4; // 存储browser.WSEndpoint列表 this.WSE_LIST = []; // 限定页面打开次数 this.PAGE_COUNT = 1000; // 存储浏览器打开页面次数 this.PAGE_NUM = []; // 重启浏览器的timer this.replaceTimer = []; // puppeteer 配置 this.p_config = { headless: true, // 以 无头模式（隐藏浏览器界面）运行浏览器 args: [ '--disable-gpu', // GPU硬件加速 '--disable-dev-shm-usage', // 创建临时文件共享内存 '--disable-setuid-sandbox', // uid沙盒 '--no-first-run', // 没有设置首页。在启动的时候，就会打开一个空白页面。 '--no-sandbox', // 沙盒模式 '--no-zygote', '--single-process', // 单进程运行 ], }; // 初始化 this._init(); } static getInstance() { if (!this.instance) { this.instance = new PuppeteerHelper(); } return this.instance; } // 初始化 /** * @desc 初始化 * 使用puppeteer.connect比puppeteer.launch启动一个浏览器实例要快很多 * https://stackoverflow.com/questions/52431775/whats-the-performance-difference-of-puppeteer-launch-versus-puppeteer-connect * 当开启多个browser实例时，可以通过缓存wsEndpoint来达到复用的目的 * */ _init() { (async () =&gt; { console.log('【PuppeteerHelper】puppeteer config:', this.p_config); for (let i = 0; i &lt; this.MAX_WSE; i++) { await this._generateBrowser(i); } console.log('【PuppeteerHelper】WSE_LIST：', this.WSE_LIST); })(); } /** * @desc 生成指定编号的浏览器 * @param {number} num 编号 * */ async _generateBrowser(num) { // 先通过 puppeteer.launch() 创建一个浏览器实例 Browser 对象 const browser = await puppeteer.launch(this.p_config); // 存储浏览器 websocket 的地址 this.WSE_LIST[num] = await browser.wsEndpoint(); // 初始化打开次数,因为浏览器会打开一个空白页 this.PAGE_NUM[num] = 1; return browser; } /** * @desc 替换当前浏览器实例 * @param {Promise&lt;Browser&gt;} browser 当前浏览器实例 * @param {number} num 当前浏览器编号 * @param {number} retries 重试次数，超过这个次数直接关闭浏览器 * */ async _replaceBrowserInstance(browser, num, retries = 2) { clearTimeout(this.replaceTimer[num]); const pageNum = this.PAGE_NUM[num]; // 当前浏览器处于打开的页面个数 const openPages = await browser.pages(); const oneMinute = 60 * 1000; // 因为浏览器会打开一个空白页，如果当前浏览器还有任务在执行，一分钟后再关闭 if (openPages &amp;&amp; openPages.length &gt; 1 &amp;&amp; retries &gt; 0) { const nextRetries = retries - 1; console.log( '【PuppeteerHelper】当前使用浏览器编号：%s，browser.pages：%s，retries', num, openPages.length, retries ); this.replaceTimer[num] = setTimeout(() =&gt; this._replaceBrowserInstance(browser, num, nextRetries), oneMinute); // 返回旧的浏览器使用 return browser; } // 关闭浏览器 browser.close(); // 使用新的浏览器 const newBrowser = await this._generateBrowser(num); console.log( '【PuppeteerHelper】当前使用浏览器编号：%s 已打开页面总次数（%s）超过上限，创建新实例，新的wsEndpoint：%s', num, pageNum, this.WSE_LIST[num] ); return newBrowser; } /** * @desc 提供浏览器实例 * */ async _currentBrowser() { // 通过随机数做简单的负载均衡,确定使用的第几台浏览器 const tmp = Math.floor(Math.random() * this.MAX_WSE); const browserWSEndpoint = this.WSE_LIST[tmp]; const pageNum = this.PAGE_NUM[tmp]; console.log( '【PuppeteerHelper】当前使用浏览器编号：%s ，wsEndpoint：%s，过去已打开页面总次数 %s', tmp, browserWSEndpoint, pageNum ); let browser; try { // 使用节点来重新建立连接 browser = await puppeteer.connect({ browserWSEndpoint }); // 如果当前浏览器超过规定次数，则替换浏览器 if (this.PAGE_NUM[tmp] &gt; this.PAGE_COUNT) { browser = this._replaceBrowserInstance(browser, tmp); } } catch (err) { // 连接失败重新创建新的浏览器实例 browser = await this._generateBrowser(tmp); console.log( '【PuppeteerHelper】当前使用浏览器编号：%s 连接失败，创建新实例，新的wsEndpoint：%s', tmp, this.WSE_LIST[tmp] ); console.log('【PuppeteerHelper】WSE_LIST：', this.WSE_LIST); } // 增加打开页面次数 this.PAGE_NUM[tmp]++; return browser; } /** * @desc 自定义等待 * @param page 页面 * @param {number} [timeout] 自定义等待时长，单位ms，默认30S * */ async _waitRender(page, timeout) { console.log('【_waitRender】开启自定义等待,自定义等待时长：%s ms,（默认30s）', timeout); // 在页面中定义自己认为加载完的事件，在合适的时间点我们将该事件设置为 true // 如果 _renderDone 出现且为 true 那么就截图，如果是 Object，说明页面加载出错了，可以捕获该异常进行提示 const renderDoneHandle = await page.waitForFunction('window._renderDone', { polling: 120, timeout: timeout, }); const renderDone = await renderDoneHandle.jsonValue(); if (typeof renderDone === 'object') { console.log(`【_waitRender】加载页面失败： -- ${renderDone.msg}`); await page.close(); throw new Error(`客户端请求重试： -- ${renderDone.msg}`); } else { console.log('【_waitRender】页面加载成功'); } } /** * @desc 水印 * @param page * @param {string} text 水印文字 * @return {Promise&lt;void&gt;} * @private */ async _watermark(page, text) { // 将 content 中的字符内容作为 script 添加到 head 中. await page.addScriptTag({ content: htmlGenWaterMark.toString() }); await page.evaluate( (options) =&gt; { window.htmlGenWaterMark(options); }, { text: text } ); } /** * @desc 截图 * @param {string} url 网址链接 * @param {string} filePath 图片保存路径,如果未提供，则保存在当前程序运行下的example.png * @param {number} width 可视区域宽度，截图设定fullPage,可滚动，因此此设定可能对截图无意义 * @param {number} height 可视区域高度，截图设定fullPage,可滚动，因此此设定暂时对截图无意义 * @param {string} screenshotType 截图类型 * @param {string} selector 选择器 * @param {number} altitudeCompensation 高度补偿 * @param {object} headers 每个 HTTP 请求都会带上这些请求头。值必须是字符串 * @param {boolean} openWait 是否开启等待 * @param {number} waitTimeout 自定义等待时长 * @param {boolean} openWatermark 是否开启等待 * @param {string} watermarkText 是否开启等待 * */ async screenshot({ url, filePath = './example.png', width = 800, height = 600, screenshotType = 'default', selector, altitudeCompensation = 0, headers, openWait, waitTimeout, openWatermark, watermarkText = '水印', }) { console.log('【PuppeteerHelper】开始截图'); // 获得可以使用的一台浏览器 const browser = await this._currentBrowser(); // 然后通过 Browser 对象创建页面 Page 对象 const page = await browser.newPage(); try { // 设置可视区域大小,默认的页面大小为800x600分辨率 await page.setViewport({ width, height }); // 设定请求头 headers &amp;&amp; (await page.setExtraHTTPHeaders(headers)); // 然后 page.goto() 跳转到指定的页面 await page.goto(url, { // 不再有网络连接时触发（至少500毫秒后）,认为页面跳转完成 waitUtil: 'networkidle0', }); // 在浏览器环境中执行函数, 获取页面的宽度和高度 // eslint-disable-next-line no-unused-vars const documentSize = await page.evaluate(() =&gt; { return { width: document.documentElement.clientWidth, // document.body.scrollHeight height: document.body.clientHeight, }; }); // 加载自定义等待时间 openWait &amp;&amp; (await this._waitRender(page, waitTimeout)); // 加载水印 openWatermark &amp;&amp; (await this._watermark(page, watermarkText)); // 针对body元素进行截图 // const element = await page.$('body'); // const picture = await page.screenshot({ path: filePath }); // 调用 page.screenshot() 对页面进行截图 const picture = await this._capture(page, { screenshotType, filePath, selector, altitudeCompensation }); return picture; } finally { console.log('【PuppeteerHelper】结束截图，关闭当前页面'); // 无论截图失败还是成功都会关闭当前页面 await page.close(); } } /** * @desc 按照截图类型获取指定区域图片 * @param page * @param {string} screenshotType 截图类型 * @param {string} filePath 图片保存路径,如果未提供，则保存在当前程序运行下的example.png * @param {string} selector 选择器 * @param {number} altitudeCompensation 高度补偿 * @return {Promise&lt;Buffer&gt;} * @private */ async _capture(page, { screenshotType, filePath, selector, altitudeCompensation = 0 }) { switch (screenshotType) { case 'selector': { const element = await page.$(selector); const boundingBox = await element.boundingBox(); const picture = await element.screenshot({ path: filePath, clip: boundingBox }); return picture; } case 'scrollBody': { // page.evaluate方法遍历所有div节点，找到一个scrollHeight大于视口高度的节点，将其标记为滚动节点。如果所有元素节点的scrollHeight都不大于视口高度，则body为滚动节点。 const { scrollHeight, isBody, width } = await page.evaluate(() =&gt; { const clientHeight = document.documentElement.clientHeight; const clientWidth = document.documentElement.clientWidth; const divs = [...document.querySelectorAll('div')]; const len = divs.length; let isBody = false; let boxEl = null; let i = 0; for (; i &lt; len; i++) { const div = divs[i]; if (div.scrollHeight &gt; clientHeight) { boxEl = div; break; } } if (!boxEl &amp;&amp; i === len) { boxEl = document.querySelector('body'); isBody = true; } return { scrollHeight: boxEl.scrollHeight, isBody: isBody, width: clientWidth }; }); // 有新的滚动节点时设定可视区域高度 !isBody &amp;&amp; (await page.setViewport({ height: scrollHeight + altitudeCompensation, width: width })); // 截图 const picture = await page.screenshot({ path: filePath, fullPage: true, }); return picture; } case 'default': default: { const picture = await page.screenshot({ // 截图保存路径 path: filePath, fullPage: true, // clip: { // x: 0, // y: 0, // height: documentSize.height, // width: documentSize.width // } }); return picture; } } }}export default PuppeteerHelper.getInstance(); 使用 tab 方式渲染后请求速度提升了 200ms 左右，一个 tab 进程使用内存降到 20M 以内，带来的收益也非常可观。 不过这里要注意，官方并不建议这样做，因为一个 tab 页阻塞或者内存泄露会导致整个浏览器阻塞并 Crash。万全的解决办法是定期重启程序，当请求 1000 次或者内存超过限制后重启对应的进程。 过滤请求当我们使用puppeteer对页面异步渲染的dom结构进行解析时，往往需要等待页面完成渲染完成之后，才能使用脚本进行操作。但页面渲染过程中也包含了许多静态资源如：图片/音频/视频/样式文件等。此时我们可以通过page.setRequestInterception方法，对网页请求进行过滤，拦截静态资源的请求，加快页面渲染速度。 代码如下： 123456789101112// 开启请求拦截功能await page.setRequestInterception(true);page.on('request', (req) =&gt; { // 根据请求类型过滤 const resourceType = req.resourceType(); if (resourceType === 'image') { req.abort(); } else { req.continue(); }}); 推荐拦截的请求类型： 1234567891011121314151617181920212223const blockedResourceTypes = ['image', 'media', 'font', 'texttrack', 'object', 'beacon', 'csp_report', 'imageset'];const skippedResources = [ 'quantserve', 'adzerk', 'doubleclick', 'adition', 'exelator', 'sharethrough', 'cdn.api.twitter', 'google-analytics', 'googletagmanager', 'google', 'fontawesome', 'facebook', 'analytics', 'optimizely', 'clicktale', 'mixpanel', 'zedo', 'clicksor', 'tiqcdn',]; 代理请求除了过滤请求之外，我们也可用代理网页渲染过程中发出的请求。在某些爬虫项目达到不被发爬的目的， 代码如下： 1234567891011121314151617page.on('request', async (req) =&gt; { // 代理请求 const response = await fetch({ url: req.url(), method: req.method(), headers: req.headers(), body: req.postData(), agent: new HttpProxyAgent(getProxyIp()), }); // 响应请求 req.respond({ status: response.statusCode, contentType: response.headers['content-type'], headers: response.headers || req.headers(), body: response.body, });}); 参考链接 Puppeteer Puppeteer 自动化的性能优化与执行速度提升 puppeteer 优化小技巧","link":"/articles/2021/07/05/optimize-puppeteer/"},{"title":"package.json 各字段的作用","text":"package.json 文件可以使你的 npm 包对于其他人来说更容易管理和下载。发布 npm 包也是必须要有该文件的。 name npm 包的名字，必须是一个小写的单词，可以包含连字符-和下划线_。发布时必填。 version npm 包的版本号，必须是x.x.x的形式，并且遵循语义化版本规则。发布时必填。 阶段 规则 例子 首次发版 从 1.0.0 开始 1.0.0 补丁发布 递增第三位数 1.0.8 次要版本 递增第二位数，将第三位置位 0 1.2.0 主要版本 递增第一位数，将后俩位数置位 0 3.0.0 注：版本号不存在十进制说法，当代码一直处于同一阶段更新时，版本号可以一直增加、1.0.35、1.12.5都是可以的。 description npm 包的简短描述，它会显示在 npm 官方搜索的列表中。 12&quot;description&quot;: &quot;This is description&quot; keywords npm 包的关键词，是一个字符串数组，可以帮助其他人在 npm 搜索列表中发现你的包。 1234567&quot;keywords&quot;: [ &quot;react&quot;, &quot;component&quot;, &quot;ui&quot;, &quot;sea&quot;], homepage npm 包项目主页地址，可以是托管平台的地址。 12&quot;homepage&quot;: &quot;https://github.com/MrSeaWave/blogs&quot; bugs npm 包问题反馈的地址，可以是 github 的 issue 或者是邮箱地址。对于那些使用遇到问题的人很有帮助。 12345&quot;bugs&quot;: { &quot;url&quot;: &quot;https://github.com/MrSeaWave/blogs/issues&quot;, &quot;email&quot;: &quot;MrDaemon@outlook.com&quot;} license 为 npm 包指定许可证，以便其他人知道他们被允许使用方式以及该 npm 包被施加的任何限制。 author npm 包的作者，电子邮件和网站都是可以的，以下俩种方式都可以。 12345678 &quot;author&quot;: &quot;Sea &lt;MrDaemon@outlook.com&gt; (https://github.com/MrSeaWave)&quot;&quot;author&quot;: { &quot;name&quot; : &quot;Sea&quot;, &quot;email&quot; : &quot;MrDaemon@outlook.com&quot;, &quot;url&quot; : &quot;https://github.com/MrSeaWave&quot;} files npm 包作为依赖安装时要包括的文件，格式是文件正则的数组，[&quot;*&quot;]代表所有文件。也可以使用npmignore 来忽略个别文件。 files字段优先级最大，不会被npmignore和.gitignore覆盖。 以下文件总是被包含的，与配置无关 package.json README.md CHANGES / CHANGELOG / HISTORY LICENCE / LICENSE 以下文件总是被忽略的，与配置无关 .git .DS_Store node_modules .npmrc npm-debug.log package-lock.json … main 指定 npm 包的入口文件，例 &quot;main&quot;: &quot;src/index.js&quot;当require(name)的时候实质是引入了改文件。 bin 开发可执行文件时，bin 字段可以帮助你设置链接，不需要手动设置 PATH。 1234&quot;bin&quot; : { &quot;myCli&quot; : &quot;./cli.js&quot;} 当像上面这样指定时，下载 npm 包，会自动链接cli.js到use/local/bin/myCli，可以直接在命令行执行myCli实质上执行的是 npm 包的cli,js文件，需要在可执行文件头部加上#!/usr/bin/env node，否则会在没有 node 的时候执行。当只有一个可执行文件且名字和包名一样，可以直接写成字符串形式。 12&quot;bin&quot;: &quot;./cli.js&quot; repository npm 包托管的地方，对于想贡献代码的人是有帮助的。 12345&quot;repository&quot;: { &quot;type&quot;: &quot;git&quot;, &quot;url&quot;: &quot;https://github.com/MrSeaWave/blogs&quot;} scripts 可执行的命令。具体文档 12345&quot;scripts&quot;: { &quot;dev&quot;: &quot;cross-env NODE_ENV=development node server.js&quot;, &quot;build&quot;: &quot;cross-env NODE_ENV=production node server.js&quot;} dependencies npm 包所依赖的其他 npm 包，当使用npm install 下载该包时，dependencies中指定的包都会一并被下载。指定版本范围的规则如下： version 严格匹配 &gt; version 必须大于该版本 &lt;= version 必须小于等于该版本 ^version 兼容版本 1.2.x : 1.2.0, 1.2.1 等，不能是 1.3x … 12345&quot;dependencies&quot;: { &quot;react&quot;: &quot;^17.0.2&quot;, &quot;react-dom&quot;: &quot;^17.0.2&quot;} devDependencies npm 包所依赖的构建和测试相关的 npm 包，放置到devDependencies，当使用npm install 下载该包时，devDependencies中指定的包不会一并被下载。 123456&quot;devDependencies&quot;: { &quot;eslint&quot;: &quot;^8.1.0&quot;, &quot;jest&quot;: &quot;^24.8.0&quot;, &quot;webpack&quot;: &quot;^5.0.0&quot;} peerDependencies 指定 npm 包与主 npm 包的兼容性，当开发插件时是需要的，例如开发 React 组件时，其组件是依赖于react、react-domnpm 包的，可以在peerDependencies指定需要的版本。 12345&quot;peerDependencies&quot;: { &quot;react&quot;: &quot;&gt;=16.8.0&quot;, &quot;react-dom&quot;: &quot;&gt;=16.8.0&quot;} 注：如果peerDependencies指定的 npm 包没有下载，npm 版本 1 和 2 会直接下载。 npm3 不会下载，会给出警告。 engines 指定 npm 包可以使用的 Node 版本 1234&quot;engines&quot; : { &quot;node&quot; : &quot;&gt;=10.0.0&quot;} resolutionsyarn 中带的字段 resolutions 字段统一所有依赖和依赖的依赖的版本，具体查看 12345{ &quot;resolutions&quot;:{ // ----救火队长 &quot;coa&quot;:&quot;x.xx.x&quot; }} 参考 npm 官方文档-更全 掘金-package.json 各字段的作用","link":"/articles/2021/12/08/packageJson-field/"},{"title":"pm2 进程间通信","text":"本文将介绍 pm2 进程间如何通信 pm2-master.js，发送数据，可以在 pm2 内部或者外部运行 123456789101112131415161718192021222324252627282930313233343536373839const pm2 = require('pm2');const neighborIds = [];pm2.connect(function () { // 列出正在运行的进程并获取它们的名称/ID pm2.list(function (err, processes) { for (const i in processes) { console.log('Id:', processes[i].pm_id, 'Name:', processes[i].name); if (processes[i].name === 'pm2-slave') { neighborIds.push(processes[i].pm_id); } } console.log('neighborIds: ', neighborIds); // 将信息发送到指定进程 pm2.sendDataToProcessId( neighborIds[0], { type: 'process:msg', data: { some: 'data', }, topic: true, }, function (err, res) { console.log('callback', err, res); } ); });});// 接收信息pm2.launchBus(function (err, pm2_bus) { pm2_bus.on('process:msg', function (packet) { console.log('pm2-master launchBus', packet); });}); pm2-slave.js，接收数据，不需要引用 pm2 的包，但是一定要在 pm2 里运行 1234567891011121314const sendMsgToMaster = () =&gt; { process.send({ type: 'process:msg', data: { success: true, num: Math.random(), }, });};process.on('message', function (packet) { console.log('got message from pm2-master', packet); setTimeout(sendMsgToMaster, 2 * 1000);}); ecosystem.config.js，pm2 配置 123456789101112131415161718192021module.exports = { apps: [ // pm2-master 可以不用 pm2 运行 // { // name: 'pm2-master', // script: './pm2-master.js', // instances: 1, // watch: ['pm2-master.js'], // merge_logs: true, // exec_mode: 'cluster', // max_memory_restart: '600M', // instance_var: 'NODE_APP_INSTANCE' // }, { name: 'pm2-slave', script: './pm2-slave.js', watch: ['pm2-slave.js'], exec_mode: 'cluster', }, ],}; 参考链接 process.send process.on pm2 Send message to process pm2-ipc.js Sending data to PM2 process using programatic API","link":"/articles/2021/07/20/pm2-ipc/"},{"title":"RGB颜色插值渐变原理","text":"本文将要讲述 RGB 颜色插值渐变原理及其实现。 其实 RGB 颜色变换的原理就是线性插值。 例如将颜色RGB(0,0,0)变换为RGB(255,255,255)，其中要输出 100 次结果，则增加量就是(255-0)/100，将RGB分开计算也是一样。 同理，RGB(100,200,150)变换为RGB(255,0,255)，增加量的计算如下: 123R = (255 - 100) / 100 = 1.55;G = (0 - 200) / 100 = -2;B = (255 - 150) / 100 = 1.05; 这 100 个片段是有关增加量的递归结果，将片段连续播放，就形成了动画。 下面是一个用HTML5+JavaScript实现的 RGB 颜色插值渐变动画，在线DEMO 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;RGB Color Interpolation Gradient&lt;/title&gt; &lt;style&gt; body &gt; * { margin: 0 auto; width: 300px; } div { height: 300px; background-color: rgb(0, 0, 0); } input { display: block; width: 100%; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt;&lt;/div&gt; &lt;p&gt;R(&lt;span&gt;0&lt;/span&gt;):&lt;input type=&quot;range&quot; id=&quot;red&quot; min=&quot;0&quot; max=&quot;255&quot; value=&quot;0&quot; /&gt;&lt;/p&gt; &lt;p&gt;G(&lt;span&gt;0&lt;/span&gt;):&lt;input type=&quot;range&quot; id=&quot;green&quot; min=&quot;0&quot; max=&quot;255&quot; value=&quot;0&quot; /&gt;&lt;/p&gt; &lt;p&gt;B(&lt;span&gt;0&lt;/span&gt;):&lt;input type=&quot;range&quot; id=&quot;blue&quot; min=&quot;0&quot; max=&quot;255&quot; value=&quot;0&quot; /&gt;&lt;/p&gt; &lt;p&gt;To RGB:&lt;input type=&quot;text&quot; value=&quot;255,255,255&quot; /&gt;&lt;button&gt;Animation&lt;/button&gt;&lt;/p&gt; &lt;script&gt; NodeList.prototype.forEach = Array.prototype.forEach; let rgb = [0, 0, 0]; let div = document.querySelector('div'); let inputs = document.querySelectorAll(&quot;input[type='range']&quot;); let toRGB = document.querySelector(&quot;input[type='text']&quot;); let button = document.querySelector('button'); let red = inputs[0]; let green = inputs[1]; let blue = inputs[2]; let lock = false; function change(i) { let span = inputs[i].parentElement.querySelector('span'); return function (e) { let value; if (e) { value = parseInt(e.target.value); span.innerHTML = value; rgb[i] = value; } else { value = parseInt(inputs[i].value); span.innerHTML = value; } div.style.backgroundColor = 'rgb(' + Math.round(rgb[0]) + ',' + Math.round(rgb[1]) + ',' + Math.round(rgb[2]) + ')'; }; } let redChange = change(0); let greenChange = change(1); let blueChange = change(2); red.addEventListener('change', redChange); green.addEventListener('change', greenChange); blue.addEventListener('change', blueChange); button.addEventListener('click', function () { if (lock) { return; } let finalValue = toRGB.value; let patternRGB = /^(([0-9])|([1-9]\\d)|(1[0-9]{2})|(2[0-4][0-9])|(25[0-5]))[,](([0-9])|([1-9]\\d)|(1[0-9]{2})|(2[0-4][0-9])|(25[0-5]))[,](([0-9])|([1-9]\\d)|(1[0-9]{2})|(2[0-4][0-9])|(25[0-5]))$/; if (!patternRGB.test(finalValue)) { alert('Format is not correct, you should enter a value like 255,255,255'); return; } finalValue = finalValue.split(','); let rf = finalValue[0]; let gf = finalValue[1]; let bf = finalValue[2]; lock = true; red.disabled = true; green.disabled = true; blue.disabled = true; rgb[0] = Math.round(rgb[0]); rgb[1] = Math.round(rgb[1]); rgb[2] = Math.round(rgb[2]); let r = rgb[0]; let g = rgb[1]; let b = rgb[2]; let ri = (rf - r) / 100; let gi = (gf - g) / 100; let bi = (bf - b) / 100; setTimeout(function (i) { i = i || 1; rgb[0] += ri; rgb[1] += gi; rgb[2] += bi; red.value = rgb[0]; green.value = rgb[1]; blue.value = rgb[2]; redChange(); greenChange(); blueChange(); if (i &lt; 100) { let f = arguments.callee; setTimeout(function () { f(i + 1); }, 50); } else { lock = false; red.disabled = false; green.disabled = false; blue.disabled = false; } }, 0); }); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;","link":"/articles/2021/06/11/rgb-color-gradient-interpolation-principle-and-algorithm/"},{"title":"ssh-key","text":"本文将介绍的是如何在 mac 上上配置 SSH Key 中的 private key。 在 Mac 上配置 SSH Key 中的 private key当往github的项目上提交代码时，github需要知道你电脑上有没有和那些Deploy keys中某个public key配对的private key。接下来就是配置怎样找到这个private key 生成 1 个 SSH Key: 1$ ssh-keygen -t rsa -C &quot;youremail@xxx.com&quot; 按回车后 12345678Generating public/private rsa key pair.Enter file in which to save the key (/Users/localMac/.ssh/id_rsa): id_rsa_TestSSH_github(取个名字)Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved inid_rsa_TestSSH_github.Your public key has been saved inid_rsa_TestSSH_github.pub. 最好每次生成时都给SSH Key取个名字，这样后面在管理时自己也一目了然。我这里的格式是id_rsa_项目名_git提供方，我生成的所有key都遵循这个规则命名。建议你也有你自己的一种命名方式，并且保持统一。如果不取名字，默认的是id_rsa，如果后面生成时不命名，会把这个覆盖掉。密码可以不设置，免得每次提交时还要输入一次，安全性自己衡量吧。第一次生成key时，会在~目录下创建一个.ssh目录。 12$ cd ~/.ssh$ ls 把id_rsa_TestSSH_github.pub添加到github对应的项目的Deploy keys中。 ssh服务器默认是去找id_rsa，现在需要把这个key添加到ssh-agent中，这样ssh服务器才能认识id_rsa_TestSSH_github 1$ ssh-add -K ~/.ssh/id_rsa_TestSSH_github 这里为什么加上了一个-K 参数呢？因为在 Mac 上，当系统重启后会“忘记”这个密钥，所以通过指定-K 把 SSH key 导入到密钥链中 查看添加结果： 1$ ssh-add -l 创建本地的配置文件 ~/.ssh/config，编辑如下： 12345678910Host TestSSH.github.com HostName github.com User git PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_TestSSH_githubHost YourProjectName.gitlab.com HostName gitlab.com User git PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_YourProjectName_gitlab Host 的名字可以随意取，我这边按照的规则是项目名.git 服务器来源，接下来会用到这个名字。测试是否配置正确： 1$ ssh -T git@TestSSH.github.com (就是刚刚你给Host取的名字) 敲一下回车，如下出现下面的提示就连接成功了： 1Hi MrSeaWave/TestSSH! You've successfully authenticated, but GitHub does not provide shell access. 一定要注意哦，帐号名称/项目名称，如果这个 key 没有连接成功，它有可能提示的是别的 key 的。 修改 github 项目配置，使项目本身能关联到使用的 key。 如果你在之前已经把项目 clone 到本地了，有两种解决方法：(1) 打开项目目录/.git/config，将[remote “origin”]中的url中的github.com修改为TestSSH.github.com，就是你在第 4 步中给Host取的那个名字。如下： 123remote &quot;origin&quot;] url = git@TestSSH.github.com:MrSeaWave/TestSSH.git fetch = +refs/heads/*:refs/remotes/origin/* (2) 也可以在提交时修改 12$ git remote rm origin$ git remote add origin git@TestSSH.github.com:MrSeaWave/TestSSH.git 如果还没有 clone 到本地，则在 clone 时可以直接将github.com改为TestSSH.github.com，如下： 1$ git clone git@TestSSH.github.com:MrSeaWave/TestSSH.git Happy Coding😄","link":"/articles/2021/10/26/ssh-key/"},{"title":"github-actions 入门","text":"GitHub Actions 是 GitHub 的持续集成服务，于 2018 年 10 月推出。 GitHub Actions 简介GitHub Actions 帮助您自动完成软件开发周期内的任务。 GitHub Actions 是事件驱动的，意味着您可以在指定事件发生后运行一系列命令。 例如，每次有人为仓库创建拉取请求时，您都可以自动运行命令来执行软件测试脚本。 此示意图说明如何使用 GitHub Actions 自动运行软件测试脚本。事件会自动触发其中包作业的工作流程。 然后，作业使用步骤来控制操作运行的顺序。 这些操作是自动化软件测试的命令。 很多操作在不同项目里面是类似的，完全可以共享。GitHub 注意到了这一点，想出了一个很妙的点子，允许开发者把每个操作写成独立的脚本文件，存放到代码仓库，使得其他开发者可以引用。 如果你需要某个 action，不必自己写复杂的脚本，直接引用他人写好的 action 即可，整个持续集成过程，就变成了一个 actions 的组合。这就是 GitHub Actions 最特别的地方！ GitHub 做了一个官方市场，可以搜索到他人提交的 actions。另外，还有一个 awesome actions 的仓库，也可以找到不少 action。 上面说了，每个 action 就是一个独立脚本，因此可以做成代码仓库，使用userName/repoName的语法引用 action。比如，actions/setup-node就表示github.com/actions/setup-node这个仓库，它代表一个 action，作用是安装 Node.js。事实上，GitHub 官方的 actions 都放在 github.com/actions 里面。 既然 actions 是代码仓库，当然就有版本的概念，用户可以引用某个具体版本的 action。下面都是合法的 action 引用，用的就是 Git 的指针概念，详见官方文档。 actions123actions/setup-node@74bc508 # 指向一个 commitactions/setup-node@v1.0 # 指向一个标签actions/setup-node@master # 指向一个分支 基础概念GitHub Actions 有一些自己的术语。 workflow （工作流程）：持续集成一次运行的过程，就是一个 workflow。 job （任务）：一个 workflow 由一个或多个 jobs 构成，含义是一次持续集成的运行，可以完成多个任务。 step（步骤）：每个 job 由多个 step 构成，一步步完成。 action （动作）：每个 step 可以依次执行一个或多个命令（action）。 虚拟环境GitHub 托管的运行器是由安装了 GitHub Actions 运行器应用程序的 GitHub 托管的虚拟机。 GitHub 提供使用 Linux、Windows 和 macOS 操作系统的运行器。 GitHub Ac­tions 为每个任务 (job) 都提供了一个虚拟机来执行，每台虚拟机都有相同的硬件资源： 2 核 CPU 7 GB RAM 内存 14 GB SSD 硬盘空间 虚拟环境 YAML 工作流程标签 Windows Server 2019 windows-latest 或 windows-2019 Ubuntu 20.04 ubuntu-20.04 Ubuntu 18.04 ubuntu-latest 或 ubuntu-18.04 Ubuntu 16.04 ubuntu-16.04 macOS Big Sur 11.0 macos-11.0 macOS Catalina 10.15 macos-latest 或 macos-10.15 注：Ubuntu 20.04 虚拟环境目前仅作为预览提供。 ubuntu-latest YAML 工作流程标签仍使用 Ubuntu 18.04 虚拟环境。 使用限制： 每个 workflow 的运行时限为 72 小时 每小时可以调用 1000 次 GitHub API 。 每个 job 最多可以执行 6 个小时。 免费版的用户最大支持 20 个 job 并发执行，macOS 最大只支持 5 个。 私有仓库 Linux 运行器每月累计使用时间为 2000 分钟，超过后$ 0.008/分钟，公共仓库则无限制。 注： 虽然名称叫持续集成，但当所有任务终止和完成时，虚拟环境内的数据会随之清空，并不会持续。即每个新任务都是一个全新的虚拟环境。 WorkflowGitHub Actions 的配置文件叫做 workflow 文件，存放在代码仓库的.github/workflows目录。 workflow 文件采用 YAML 格式，文件名可以任意取，但是后缀名统一为.yml or .yaml，比如foo.yml or foo.yaml。一个库可以有多个 workflow 文件。GitHub 只要发现.github/workflows目录里面有.yml or .yaml文件，就会自动运行该文件。 workflow 文件的配置字段非常多，详见官方文档。下面是一些基本字段： name 工作流程的名称。 GitHub 在仓库的操作页面上显示工作流程的名称。 如果省略 name，GitHub 将其设置为相对于仓库根目录的工作流程文件路径。 name1name: GitHub Actions Demo on 必要 触发 workflow 的 GitHub 事件的名称。 你可以提供单一事件 string、事件的 array、事件 types 的 array 或事件配置 map，以安排工作流程的运行，或将工作流程的执行限于特定文件、标记或分支更改。 有关可用事件的列表，请参阅“触发工作流程的事件” 使用单一事件 Example using a single event1on: push 上面代码指定，push事件触发 workflow。 使用事件列表的示例 Example using a list of events1on: [push, pull_request] 上面代码指定，push事件或pull_request事件都可以触发 workflow。 完整的事件列表，请查看官方文档。除了代码库事件，GitHub Actions 也支持外部事件触发，或者定时运行。 on.&lt;push|pull_request&gt;.&lt;tags|branches&gt; 指定触发事件时，可以限定分支或标签。 1234on: push: branches: - master 上面代码指定，只有master分支发生push事件时，才会触发 workflow。 jobs workflow运行包括一项或多项jobs。 jobs默认是并行运行。 要按顺序运行作业，您可以使用 &lt;job_id&gt;needs 关键词在其他job上定义依赖项。 每个作业在 runs-on 指定的运行器环境中运行。 jobs.&lt;job_id&gt;.name workflow 文件的主体是jobs字段，表示要执行的一项或多项任务。 jobs字段里面，需要写出每一项任务的job_id，具体名称自定义。job_id里面的name字段是任务的说明。 12345jobs: my_first_job: name: My first job my_second_job: name: My second job 上面代码的jobs字段包含两项任务，job_id分别是my_first_job和my_second_job。 jobs.&lt;job_id&gt;.needs needs字段指定当前任务的依赖关系，即运行顺序。 123456jobs: job1: job2: needs: job1 job3: needs: [job1, job2] 上面代码中，job1必须先于job2完成，而job3等待job1和job2的完成才能运行。因此，这个 workflow 的运行顺序依次为：job1、job2、job3。 jobs.&lt;job_id&gt;.runs-on runs-on字段指定运行所需要的虚拟机环境。它是必填字段。目前可用的虚拟机如下。 123- ubuntu-latest，ubuntu-18.04或ubuntu-16.04- windows-latest，windows-2019或windows-2016- macOS-latest或macOS-10.14 下面代码指定虚拟机环境为ubuntu-18.04。 1runs-on: ubuntu-18.04 jobs.&lt;job_id&gt;.steps steps字段指定每个 Job 的运行步骤，可以包含一个或多个步骤。每个步骤都可以指定以下三个字段。 123- jobs.&lt;job_id&gt;.steps.name：步骤名称。- jobs.&lt;job_id&gt;.steps.run：该步骤运行的命令或者 action。- jobs.&lt;job_id&gt;.steps.env：该步骤所需的环境变量。 下面是一个完整的 workflow 文件的范例。 workflow12345678910111213141516name: Greeting from Monaon: pushjobs: my-job: name: My Job runs-on: ubuntu-latest steps: - name: Print a greeting env: MY_VAR: Hi there! My name is FIRST_NAME: Mona MIDDLE_NAME: The LAST_NAME: Octocat run: | echo $MY_VAR $FIRST_NAME $MIDDLE_NAME $LAST_NAME. 上面代码中，steps字段只包括一个步骤。该步骤先注入四个环境变量，然后执行一条 Bash 命令。 jobs.&lt;job_id&gt;.steps[*].uses 选择要作为job中step的一部分运行的操作。 操作是一种可重复使用的代码单位。 你可以使用工作流程所在仓库中、公共仓库中或发布 Docker 容器映像中定义的操作。 示例123456789steps: # Reference a specific commit - uses: actions/setup-node@74bc508 # Reference the major version of a release - uses: actions/setup-node@v1 # Reference a minor version of a release - uses: actions/setup-node@v1.2 # Reference a branch - uses: actions/setup-node@main 更多uses使用示例参考官网 示例一个简单的 workflow 文件示例workflow example123456789101112131415161718192021222324252627name: Hello Worldon: push: branches: - mainjobs: my_first_job: name: My first job runs-on: ubuntu-latest steps: - name: checkout uses: actions/checkout@main - name: Run a single-line script run: echo &quot;Hello World!&quot; my_second_job: name: My second job runs-on: macos-latest steps: - name: Run a multi-line script env: MY_VAR: Hello World! MY_NAME: P3TERX run: | echo $MY_VAR echo My name is $MY_NAME 上面这个 workflow 文件的要点如下。 整个流程在main分支发生push事件时触发。 有两个个job，一个运行在虚拟机环境ubuntu-latest。一个运行在macos-latest My First Job 第一步是获取源码，使用的 action 是actions/checkout。 第二步是运行一个简单的脚本：echo &quot;Hello World!&quot; My Second Job 设定环境变量 MY_VAR 和MY_NAME 运行脚本打印环境变量 保存上面的文件后，将整个仓库推送到 GitHub。 GitHub 发现了 workflow 文件以后，就会自动运行。你可以在网站上实时查看运行日志，日志默认保存 30 天。 示例文件运行截图： react 项目发布到 Github Pages示例项目需要将构建成果发到 GitHub 仓库，因此需要 GitHub 密钥。按照官方文档，生成一个密钥。然后，将这个密钥储存到当前仓库的Settings/Secrets里面。 在这个仓库的.github/workflows目录，生成一个 workflow 文件，名字可以随便取，这个示例是react-cli.yml。 我们选用一个别人已经写好的 action：JamesIves/github-pages-deploy-action，它提供了 workflow 的范例文件，直接拷贝过来就行了（查看源码） react-cli123456789101112131415161718192021222324name: github-test-actions上的React项目部署到github pageson: push: branches: - react-branchjobs: build-and-deploy: runs-on: ubuntu-latest steps: - name: Checkout 🛎️ uses: actions/checkout@v2 with: persist-credentials: false - name: Install and Build 🔧 run: | npm install npm run build - name: Deploy 🚀 uses: JamesIves/github-pages-deploy-action@3.7.1 with: ACCESS_TOKEN: ${{ secrets.REACT_WORKFLOW_TOKEN }} BRANCH: gh-pages # The branch the action should deploy to. FOLDER: build # The folder the action should deploy. 整个流程在react-branch分支发生push事件时触发。 只有一个job，运行在虚拟机环境ubuntu-latest。 第一步是获取源码，使用的 action 是actions/checkout。 第二步是安装与构建。 第三步是部署，使用的 action 是JamesIves/github-pages-deploy-action，使用三个变量，分别为 GitHub 密钥、发布分支、构建成果所在目录。其中，只有 GitHub 密钥是变量，需要写在双括号里面，其他三个都可以直接写在文件里。 保存上面的文件后，将整个仓库推送到 GitHub。 等到 workflow 运行结束，访问 GitHub Page，会看到网页已经部署到指定网址上了。 参考链接 GitHub Actions GitHub Actions 入门教程 GitHub 托管的运行器的规格 GitHub 使用限制、计费和管理 GitHub 操作的工作流程语法 五分钟了解 YAML actions/checkout github-pages-deploy-action","link":"/articles/2021/01/06/start-github-actions/"},{"title":"终端如何挂代理","text":"本文将介绍终端是如何挂代理的。 前提首先你需要类似于shadowsocksX-NG-R8的代理软件，本文以shadowsocksX-NG-R8为例 正文打开shdowsocks为代理模式。 以zsh作为说明 .zshrc1$ vim ~/.zshrc 第一种： 添加如下代理配置: edit12345678910111213# where need proxyproxy () { export http_proxy=&quot;socks5://127.0.0.1:1086&quot; export https_proxy=&quot;socks5://127.0.0.1:1086&quot; echo &quot;Socks Proxy on&quot;}# where need noproxynoproxy () { unset http_proxy unset https_proxy echo &quot;Socks Proxy off&quot;} 第二种： edit123# proxy listalias proxy='export all_proxy=socks5://127.0.0.1:1086'alias noproxy='unset all_proxy' 注：两种方式皆可，127.0.0.1:1086取自高级设置 :wq保存退出 .zshrc1$ source ~/.zshrc 验证是否proxy成功: 12345678910$ curl cip.ccIP : 101.81.77.200地址 : 中国 上海运营商 : 电信数据二 : 上海市 | 电信数据三 :URL : http://www.cip.cc/101.81.77.200 执行proxy: 1$ proxy 123456789$ curl cip.ccIP : 42.200.244.149地址 : 中国 香港 pccw.com数据二 : 香港 | 电讯盈科商用网络数据三 : 中国香港 | 电讯盈科URL : http://www.cip.cc/42.200.244.149 如果cip.cc不能用，可以换个类似的站点查询 如果不需要走代理，执行： 123$ noproxy$ curl cip.ccIP : 101.81.77.200 Clash 设定代理后访问curl cip.cc时，如果返回的依然是直连的 IP 信息，可能是因为你的代理有规则判断，cip.cc 是国内域名，直连了。建议直接走curl -vv https://www.google.com 参考链接 Mac OSX 终端走 shadowsocks 代理 #18 请问 clashx 怎么设置终端代理呢？","link":"/articles/2021/04/02/terminal-proxy/"},{"title":"uPic 图床配置教程 - Github","text":"简介uPic(upload Picture) 是一款 Mac 端的图床(文件)上传客户端，可将图片、各种文件上传到配置好的指定提供商的对象存储中。然后快速获取可供互联网访问的文件 URL。 配置项说明 用户名: Github 用户名。例如：我的 Github 主页https://github.com/MrSeaWave ，我的用户名就是MrSeaWave 仓库名: 需要储存上传文件的仓库名称。例如：我的仓库地址为https://github.com/MrSeaWave/figure-bed-profile ，仓库名称就是figure-bed-profile 分支: 分支名称，默认是main，如果是其他分支，就必须先创建好分支，才能上传 Token: Github 的个人访问令牌（Personal access tokens） 域名: 默认可不设置域名，会使用 Github 默认的访问地址。当你的仓库开启了pages功能，并配置好了自定义域名时，这里就可以使用你的自定义域名 使用默认 CDN 加速访问: 勾选时会自动使用 jsdelivr CDN 进行加速访问 保存路径: 文件储存的路径（包括文件夹）。 支持 {year} {month} {day} {hour} {minute} {second} {since_second} {since_millisecond} {random} {filename} {.suffix} 等变量。比如：上传的图片为 uPic.jpg，设定为 “uPic/{filename}{.suffix}”，则会保存到 “uPic/uPic.jpg”。 Token 获取方式 进入Github Token 创建页面 勾选 repo 访问权限。然后滚动页面到底部，点击Generate token按钮来生成 token。 复制生成好的 Token 值到 uPic token 输入框。注意：此 Token 只会显示一次！请务必保存好，否则之后丢失了，就得重新创建了。 最终效果保存一下，在菜单栏-图床栏选中刚刚配置好的 Github 图床，上传一张图片试试吧。上传成功后，Github 仓库就会出现你刚上传的文件啦","link":"/articles/2021/03/24/upic-github/"},{"title":"vscode 插件 project-manager 使用","text":"在项目开发的时候，我们经常需要同时操作多个项目，经常需要切换项目。 以前的方式 在工具栏中点击文件，打开，选择本地项目的目录 / 新建窗口 如果有最近打开的项目，点击打开最近的文件 这两种方式对于需要经常切换项目时，比较耗时 为解决这个问题，VSCode 提供了 Project Manager 插件管理，开发时常用的项目。 Project Manager 管理项目可用命令 Project Manager: Save Project 将当前文件夹另存为新项目 Project Manager: Edit Project 手动编辑项目（projects.json） Project Manager: List Projects to Open 列出所有已保存/检测到的项目并选择一个 Project Manager: List Projects to Open in New Window 列出所有已保存/检测到的项目，然后选择一个在新窗口中打开 Project Manager: Refresh Projects 刷新缓存的项目 保存项目command+ shift + p 打开配置文件，输入 Project Manager: Save Projects 您可以随时将当前项目保存在管理器中。你只需要输入一个名字。它甚至会自动为你建议一个名字:) 按 Enter 键后，右下角弹出保存成功提示。 编辑项目为了更轻松地自定义项目列表，您可以 projects.json 直接在 Code 中编辑文件。只需执行 Project Manager: Edit Projects和projects.json 文件被打开。这很简单，我就手动添加了一个 blogs 项目： 确保 JSON 文件格式正确。否则，项目管理器将无法打开它，并且会出现类似这样的错误消息。在这种情况下，您应该使用 Open File 按钮来修复它。 刷新项目command+ shift + p 打开配置，输入 Project Manager: Refresh Projects 刷新项目 项目列表刷新之后，左侧导航栏，多出一个文件夹图标，用于管理项目，点击其中一个，自动切换项目。 可用设置设置插件的可配置项，在 首选项 - 设置 - 拓展 - Project Manager Configuration 位置 举例：您可以选择项目的排序方式 1&quot;projectManager.sortList&quot;: &quot;Name&quot; Saved：您保存项目的顺序 Name：您为项目键入的名称 Path：项目的完整路径 Recent：最近使用的项目","link":"/articles/2021/03/31/vscode-project-manager/"},{"title":"vs-code“实用插件”","text":"在使用vs-code时，整理了一些好用的vs-code插件分享。 基础必备Chinesevscode编辑器汉化包，安装后，在 locale.json 中添加 &quot;locale&quot;: &quot;zh-cn&quot;，即可载入中文（简体）语言包。 Auto Rename Tag自动重命名成对的HTML标记，修改开始标签，结束标签会同步修改。 Auto Close Tag自动闭合HTML/XML标签 HTML SnippetsHTML 代码片段，该插件可为你提供 html 标签的代码提示，不用键入尖括号了。 Bracket Pair Colorizer该插件可以为你把成对的括号做颜色区分，并且提供一根连接线。方便我们审阅代码结构。 CSS Peekcss 样式查看器，可快速查看我们的 css 样式，非常方便快捷。 Npm Intellisense可自动完成导入语句中的 npm 模块。 open in browser快速打开html文件到浏览器预览。 Debugger for Chrome调试工具，必装；具体使用查看官网 vscode-icons提供了非常漂亮的目录树图标主题。 Material Icon Theme提供了非常漂亮的目录树图标主题。（这款最爱。 Atom One Dark ThemeOne Dark Theme based on Atom。 Dracula Official吸血鬼主题。 Path Intellisense自动提示文件路径，支持各种快速引入文件。 Image preview鼠标悬浮在链接上可及时预览图片。 Highlight Matching Tag点击某 Tag 时对应的 Tag 下会有下划线标示，比较实用； Beautify在代码文件右键鼠标一键格式化 html,js,css JavaScript (ES6) code snippetsES6 语法智能提示，以及快速输入。 VeturVScode官方钦定 Vue 插件，Vue开发者必备。内含语法高亮，智能提示，emmet，错误提示，格式化，自动补全，debugger等实用功能。 indent-rainbow用颜色填充缩进，非常直观，如果有缩进错误还会变成红色。（ 对写 Nim or Python 用处极大。 代码风格规范Prettier - Code formatterPrettier 是一个“有态度”的代码格式化工具。，prettier支持我们大前端目前大部分语言处理，包括JavaScript 、Flow、 TypeScript 、CSS 、SCSS 、Less 、JSX 、Vue 、GraphQL 、JSON 、Markdown ESlint规范 js 代码书写规则，如果觉得太过严谨，可自定义规则。 Code Spell Checker是拼写检查程序，检查不常见的单词，如果单词拼写错误，会给出警告提示。 koroFileHeader在vscode中用于生成文件头部注释和函数注释的插件，经过多版迭代后，插件：支持所有主流语言，功能强大，灵活方便，文档齐全，食用简单！ Better Align代码书写的整洁，工整往往是衡量一个程序员素养的标准，这款插件可以让你的代码更排版优雅。 change-case通常我们对一个变量的命名可能是驼峰，可能是全大写，又或是下划线，这里可通过这个插件解决变量命名规范的问题。 选中变量配合组合键[Command+Shift+p]，输入对应格式即可。 1234567891011121314151617extension.changeCase.commands：列出所有“更改案例”命令，如果仅选择一个单词，则带有预览extension.changeCase.camel：更改大小写'camel'：转换为字符串，并用下一个字母大写表示分隔符extension.changeCase.constant：更改大小写“常量”：转换为大写字母，下划线分隔字符串extension.changeCase.dot：更改大小写的“点”：转换为小写，句点分隔的字符串extension.changeCase.kebab：更改大小写“ kebab”：转换为小写字母，用破折号分隔的字符串（参数名的别名）extension.changeCase.lower：更改大小写为“小写”：转换为小写的字符串extension.changeCase.lowerFirst：更改大小写“ lowerFirst”：转换为首字母小写的字符串extension.changeCase.no：转换没有任何大小写的字符串（小写字母，空格分隔）extension.changeCase.param：更改大小写为'param'：转换为小写字母，用破折号分隔的字符串extension.changeCase.pascal：更改大小写“ pascal”：转换为以与camelCase相同的方式表示的字符串，但首字母也大写extension.changeCase.path：更改大小写的“路径”：转换为小写，用斜杠分隔的字符串extension.changeCase.sentence：更改大小写的“句子”：转换为小写的空格分隔的字符串extension.changeCase.snake：更改大小写“ snake”：转换为小写字母，下划线分隔字符串extension.changeCase.swap：更改大小写“交换”：转换为每个大小写相反的字符串extension.changeCase.title：更改大小写“标题”：转换为以空格分隔的字符串，每个单词的第一个字符均大写extension.changeCase.upper：更改大小写为大写：转换为大写字符串extension.changeCase.upperFirst：更改大小写为“ upperFirst”：转换为首字母大写的字符串 Better Comments丰富注释颜色，让注释也具有生命力，如需自定义样式，需要写入配置代码。 1234567891011配置代码&quot;better-comments.tags&quot;: [ { &quot;tag&quot;: &quot;*&quot;, &quot;color&quot;: &quot;#98C379&quot;, &quot;strikethrough&quot;: false, &quot;backgroundColor&quot;: &quot;transparent&quot; }]使用// * 绿色的高亮注释 TODO Tree我们经常会在代码中使用TODO来标记我们的代码，提高可读性，TODO Tree这款插件提供了可视化窗口来查看和管理我们的TODO Tree 其他插件（开发神器GitLensGitLens可以帮助你更好地理解代码。快速查看更改行或代码块的对象，功能强大，功能丰富且高度可定制，可以满足你的需求 GitHistoryGitHistory可查看和搜索 git 日志以及图形和详细信息，同时还支持分支比较，分支管理等操作，非常方便。 Partial Diff文件比较是一个很常见的场景，如果光凭我们肉眼分别的话，累人不说还容易出错。 Partial Diff的出现就正好解决了这个问题。 Markdown All in One这款神器可以让我们在vscode里面快乐的书写Markdown，功能强大。提供了丰富的快捷键，可边写边看，轻松转化为html或pdf文件，十分好用，强烈推荐。 vscode-drawio这款神器可以让我们在vscode里面快乐的画流程图。新建 .drawio 后缀文件并拖入 vscode 中。 Polacode-2020这款神器可以将我们的代码转化成一张逼格满满的图片，在写文章或者代码分享的时候。抛出一张这样的图片，可比随手截图体面多了。 carbon-now-sh也是一款将代码转换成图片的插件，不过它会打开carbon.now.sh网站 REST Client这款神器可以让我们在vscode里面进行接口调试，提供丰富的 api 配置方式，让我们不用离开编辑器也可以随时调用接口调试。 新建一个.http文件，写下基本的测试代码，点击 Send Request即可在右边窗口查看接口返回结果，非常 nice。 Browser Preview可以让我们在vscode里面打开浏览器，一边编码一边查看。 JavaScript Booster这款神器可以在我们代码写的不规范或者有待调整的地方，在光标聚焦后，会有一个小灯泡，只需跟随灯泡 💡，会提示对应的不合理原因和改进方案，极大的提高了我们的代码优雅度。 当在JavaScript（或TypeScript / Flow）中编辑代码时，此VS Code扩展提供了各种代码操作（快速修复）。只需注意左侧的灯泡 💡，然后按一下它即可了解如何在光标下转换代码。 Settings Sync让我们的vscode配置同步到云端，当我们跟换电脑或者再次安装vscode的时候，只需要登录账号即可同步配置了，而不用再次从头开始。（针对老版本的vscode） 预览版vscode自带配置同步功能，可以通过 Microsoft 账户或 GitHub 账户进行多机器同步。具体可参考官网 Vim如果你是vim重度用户，那么这款插件必不可少。 Live Share可以使您能够与他人实时进行协作式编辑和调试，无论您使用的是哪种编程语言或正在构建的应用程序类型。具体使用细节可查看官网 Remote Development远程开发必备扩展安装（划时代的产品）。会为你安装包括 Remote-SSH 等全部远程开发使用的扩展。具体搭建可参考VS Code Remote 环境搭建","link":"/articles/2021/03/15/vs-code-plugins/"},{"title":"webpack import() 动态加载模块踩坑","text":"本文是关于 webpack 中使用 import 时的踩坑记录。 webpack 根据 ES2015 loader 规范实现了用于动态加载的import()方法。 这个功能可以实现按需加载我们的代码，并且使用了promise式的回调，获取加载的包。 在代码中所有被import()的模块，都将打成一个单独的包，放在chunk存储的目录下。在浏览器运行到这一行代码时，就会自动请求这个资源，实现异步加载。 demo 如下： 1234 import('lodash').then((_) =&gt; { // Do something with lodash (a.k.a '_')... });} 可以看到，import()的语法十分简单。该函数只接受一个参数，就是引用包的地址，这个地址与 es6 的 import 以及 CommonJS 的 require 语法用到的地址完全一致。可以实现无缝切换。 然而在开发时为了偷懒省事，很喜欢封装部分插件：(这里使用了react-loadable来简化组件的懒加载封装) 12345678const LazyLoad = (path) =&gt; { return Loadable({ loader: () =&gt; import(path), loading: Loading, });};const B = LazyLoad('./b.js'); 然后开心的在代码中写上LazyLoad('./pages/xxx')。果不其然，挂了，收获了报错： 这是因为 webpack 编译的时候 import 预发，**不支持动态路径!!!**因为 webpack 需要先扫一遍 js 文件，找出里面按需加载的部分，进行按需打包，但不会关心内部的 js 执行上下文，也就是说，在 webpack 扫描的时候，js 中的变量并不会计算出结果，所以 import 不支持动态路径。 如： 1import('./app'+path+'/util') =&gt; /^\\.\\/app.*\\/util$/ import 参数中的所有变量，都会被替换为【.*】，而 webpack 就根据这个正则，查找所有符合条件的包，将其作为 package 进行打包。具体可查看官方 因此，如果我们直接传入一个变量，webpack 就会把 (整个电脑的包都打包进来) 认为你在逗他，并且抛出一个 WARNING: Critical dependency: the request of a dependency is an expression。 所以 import 的正确姿势，应该是尽可能静态化表达包所处的路径，最小化变量控制的区域。 如我们要引用一堆页面组件，可以使用import('./pages/'+ComponentName)，这样就可以实现引用的封装，同时也避免打包多余的内容。 另外一个影响功能封装的点，是import()中的相对路径，是import语句所在文件的相对路径，所以进一步封装 import 时会出现一些麻烦。 因为import语句中的路径会在编译后被处理成webpack命令执行目录的相对路径。 所以： 既然 import 不能搞，那只能封装非 import 的部分： 12345678const LazyLoad = (loader) =&gt; Loadable({ loader, loading: Loading, });const B = LazyLoad(() =&gt; import('./b.js'));const C = LazyLoad(() =&gt; import('./c.js')); 参考文档 webpack 脑阔疼的 webpack 按需加载 webpack import() 动态加载模块踩坑","link":"/articles/2021/06/23/webpack-import/"},{"title":"前端页面添加水印","text":"为防止信息泄露，给网页加水印是一种常见的方法。本篇文章将介绍一种添加明水印的方法。 给页面指定标签添加水印背景，原理是 canvas 画图，canvas.toDataURL()转成 base64 数据，动态添加到标签的 background。 特点： 不影响现有代码 可以任意给网页的不同部分添加水印 纯前端 js 实现 可简单防止用户通过浏览器开发者工具隐藏水印 生成水印生成水印单个图片水印的特点是，包含一段标识信息，同时需要覆盖足够的区域，很自然想到可以用 background，指定image，并让它在x,y 2 个方向上重复展示。 用canvas把信息画成图之后，调用toDataURL()方法就可以得到一个 url，该 url 实际包含了 Base64 过的图像信息，可以直接用在background上 代码示例如下： 123456789101112131415161718192021// 创建水印背景图片function createImageUrl(options) { const canvas = document.createElement('canvas'); const text = options.text; canvas.width = options.width; canvas.height = options.height; const ctx = canvas.getContext('2d'); ctx.shadowOffsetX = 2; // X轴阴影距离，负值表示往上，正值表示往下 ctx.shadowOffsetY = 2; // Y轴阴影距离，负值表示往左，正值表示往右 ctx.shadowBlur = 2; // 阴影的模糊程度 // ctx.shadowColor = 'rgba(0, 0, 0, 0.5)'; //阴影颜色 ctx.font = options.font; ctx.fillStyle = options.fontColor; ctx.rotate(options.rotateDegree); ctx.translate(options.translateX, options.translateY); ctx.textAlign = 'left'; // 在 (x, y)位置填充实体文本 ctx.fillText(text, 35, 32); return canvas.toDataURL('image/png');} 设置背景将上面得到的图片放在某个div的background上，这里需要注意的是： position: fixed: 这样可以保证不管内容如何滚动，水印都能显示； pointer-events: none: 阻止水印影响页面内容 动态计算出水印的位置 代码示例如下： 123456789101112131415161718192021222324252627282930// 将背景填充至指定水印位置处function createContainer(options, forceCreate) { const oldDiv = document.getElementById(options.id); if (!forceCreate &amp;&amp; oldDiv) return container; const url = createImageUrl(options); const div = oldDiv || document.createElement('div'); div.id = options.id; // 水印容器的父元素，默认document.body let parentEl = options.preventTamper ? document.body : options.parentEl || document.body; if (typeof parentEl === 'string') { if (parentEl.startsWith('#')) parentEl = parentEl.substring(1); parentEl = document.getElementById(parentEl); } // 返回元素的大小及其相对于视口的位置。 const rect = parentEl.getBoundingClientRect(); // 默认：按照父元素的偏移位置 options.style.left = (options.left || rect.left) + 'px'; options.style.top = (options.top || rect.top) + 'px'; div.style.cssText = getStyleText(options); div.setAttribute('class', ''); div.style.background = 'url(' + url + ') repeat top left'; !oldDiv &amp;&amp; parentEl.appendChild(div); return div;} 防止客户端篡改截止到上面为止，水印可以正常显示了，但这样只能防止小白用户，稍微有点技术的用户就知道，可以用浏览器的开发者工具来动态更改dom，比如display: none；就可以隐藏水印；所以还需要加一点机制防止用户进行篡改；当然，从本质上来说是没有绝对的办法在客户端去防用户的，所以这里只是增加了用户篡改的难度。 1. 不间断比较 div 的值监测水印 div 的变化，一旦发生变化，则重新生成水印。 记录刚生成的 div 的innerHTML，每隔几秒就取一次新的值，通过比较两者的md5，如果发生变化则重新生成。但这个方法有几个缺点： 滞后性，修改不能马上被监测后；而如果间隔时间过短，则可能影响性能； 生成md5也有不小的开销，特别是打开多个页面的时候； 所以这种方法不可行。 2. MutationObserver使用浏览器提供的一种监测元素变化的 API：MutationObserver 代码示例如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 监听元素function observe(options, observeBody) { observeWatermark(options); observeBody &amp;&amp; observeBodyElement(options);}// 监听水印function observeWatermark(options) { const target = container; const childCallBack = () =&gt; { // 关闭上个观察，重新创建元素，重新观察 observer.disconnect(); container = createContainer(options, true); observer.observe(target, observeConfig); }; observer = new MutationObserver(childCallBack); // 开始观察目标节点 observer.observe(target, observeConfig);}// 监听body元素，如果水印element被删除，则重新创建&amp;&amp;重新监听function observeBodyElement(options) { const callback = (mutations) =&gt; { mutations.forEach((m) =&gt; { if (m.type === 'childList' &amp;&amp; m.removedNodes.length &gt; 0) { let watermarkNodeRemoved = false; for (const n of m.removedNodes) { if (n.id === options.id) { watermarkNodeRemoved = true; } } if (watermarkNodeRemoved) { container = createContainer(options); observe(options, false); } } }); }; const pObserver = new MutationObserver(callback); pObserver.observe(document.body, { childList: true, subtree: true });} MutationObserver 只能监测到诸如属性改变、增删子结点等，对于自己本身被删除，是没有办法的；这里通过同时监测父结点，看 div 是否被删除来解决这个问题的。 最终代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156// 默认配置const defaultOption = { id: 'watermark-id', // parentEl: '', // 防止别人外界破坏 preventTamper: false, // 水印单个图片配置 width: 110, height: 80, text: 'watermark', font: '20px Times New Roman', fontColor: 'rgba(204,204,204,0.45)', // 顺时针旋转的弧度 rotateDegree: (30 * Math.PI) / 180, // 平移变换 translateX: 0, translateY: 0, // 水印容器的样式 style: { 'pointer-events': 'none', width: '100%', height: '100%', top: 0, left: 0, position: 'fixed', 'z-index': 1000, },};// 观察配置const observeConfig = { attributes: true, childList: true, characterData: true, subtree: true,};let container;let observer;// 创建水印背景图片function createImageUrl(options) { const canvas = document.createElement('canvas'); const text = options.text; canvas.width = options.width; canvas.height = options.height; const ctx = canvas.getContext('2d'); ctx.shadowOffsetX = 2; // X轴阴影距离，负值表示往上，正值表示往下 ctx.shadowOffsetY = 2; // Y轴阴影距离，负值表示往左，正值表示往右 ctx.shadowBlur = 2; // 阴影的模糊程度 // ctx.shadowColor = 'rgba(0, 0, 0, 0.5)'; //阴影颜色 ctx.font = options.font; ctx.fillStyle = options.fontColor; ctx.rotate(options.rotateDegree); ctx.translate(options.translateX, options.translateY); ctx.textAlign = 'left'; // 在 (x, y)位置填充实体文本 ctx.fillText(text, 35, 32); return canvas.toDataURL('image/png');}// 将背景填充至指定水印位置处function createContainer(options, forceCreate) { const oldDiv = document.getElementById(options.id); if (!forceCreate &amp;&amp; oldDiv) return container; const url = createImageUrl(options); const div = oldDiv || document.createElement('div'); div.id = options.id; // 水印容器的父元素，默认document.body let parentEl = options.preventTamper ? document.body : options.parentEl || document.body; if (typeof parentEl === 'string') { if (parentEl.startsWith('#')) parentEl = parentEl.substring(1); parentEl = document.getElementById(parentEl); } // 返回元素的大小及其相对于视口的位置。 const rect = parentEl.getBoundingClientRect(); // 默认：按照父元素的偏移位置 options.style.left = (options.left || rect.left) + 'px'; options.style.top = (options.top || rect.top) + 'px'; div.style.cssText = getStyleText(options); div.setAttribute('class', ''); div.style.background = 'url(' + url + ') repeat top left'; !oldDiv &amp;&amp; parentEl.appendChild(div); return div;}// 获取配置中的stylefunction getStyleText(options) { let ret = ''; const style = options.style; Object.keys(style).forEach((k) =&gt; { ret += k + ': ' + style[k] + ';'; }); return ret;}// 监听元素function observe(options, observeBody) { observeWatermark(options); observeBody &amp;&amp; observeBodyElement(options);}// 监听水印function observeWatermark(options) { const target = container; const childCallBack = () =&gt; { // 关闭上个观察，重新创建元素，重新观察 observer.disconnect(); container = createContainer(options, true); observer.observe(target, observeConfig); }; observer = new MutationObserver(childCallBack); // 开始观察目标节点 observer.observe(target, observeConfig);}// 监听body元素，如果水印element被删除，则重新创建&amp;&amp;重新监听function observeBodyElement(options) { const callback = (mutations) =&gt; { mutations.forEach((m) =&gt; { if (m.type === 'childList' &amp;&amp; m.removedNodes.length &gt; 0) { let watermarkNodeRemoved = false; for (const n of m.removedNodes) { if (n.id === options.id) { watermarkNodeRemoved = true; } } if (watermarkNodeRemoved) { container = createContainer(options); observe(options, false); } } }); }; const pObserver = new MutationObserver(callback); pObserver.observe(document.body, { childList: true, subtree: true });}// 入口函数function init(options) { options = !options ? defaultOption : { ...defaultOption, ...options }; container = createContainer(options); options.preventTamper &amp;&amp; observe(options, true);}init({ preventTamper: true }); 最终效果如下： 参考链接 前端页面动态添加水印 给网页加水印 Canvas API CanvasRenderingContext2D MutationObserver","link":"/articles/2021/07/09/watermark/"},{"title":"hexo new 生成新的文章","text":"介绍关于如何新建博客，官网已经有了明确的介绍： 你可以执行下列命令来创建一篇新文章或者新的页面。 命令行1$ hexo new [layout] &lt;title&gt; 您可以在命令中指定文章的布局（layout），默认为 post，可以通过修改 _config.yml 中的 default_layout 参数来指定默认布局。 这句话有几个地方需要解释一下： layout是什么？layout的意思是布局，hexo博客安装成功后，在默认的根部录下，有一个scaffolds文件夹，里面有个 3 个文件，分别是draft.md,page.md,post.md。这 3 个文件就是默认的 layout 。这三个布局分别会有什么样的作用和效果，我们会在后面的内容中进行详细说明。 如果不提供 layout 的话，也可以生成博客，不过默认的 layout 是在 _config.yml 中的配置。一般情况下，如果没有更改过任何 _config.yml 中的内容的话，默认的 layout 是 post 如果 title 包含空格的话， title 需要用引号包裹起来。也就是意味着，如果 title 没有空格的话，可以不使用引号。 假设我们想要写一篇名为 myBlog 的博客，如果输入完整的命令的话，应该是： hexo new post &quot;myBlog&quot;。但是因为默认情况下，我们的 layout 就是post，所以我们可以将 post 省略掉，写为 hexo new &quot;myBlog&quot; 。又因为我们的博客名字中没有空格，因此可以将省略号去掉，写为hexo new myBlog。这个命令已经是简化到不能再简化的命令了。而如果我们的博客名称是 my first blog，因为名称包含了空格，所以我们的命令就必须将博客名称包裹起来，也就是说最简化的命令就是 hexo new &quot;my first blog&quot; 。 这就是为什么很多网上的攻略说新生成一篇文章时用hexo new &lt;title&gt;的命令的原因，这个命令没错，但是只是大部分的情况，而不是完整的命令。 布局（Layout）Hexo 有三种默认布局：post、page 和 draft。在创建这三种不同类型的文件时，它们将会被保存到不同的路径；而您自定义的其他布局和 post 相同，都将储存到 source/_posts 文件夹。 布局 路径 post source/_posts page source draft source/_drafts layout 为 post 的情况以上面的情况为例，我们的命令是 hexo new post myBlog ，执行这个命令之后，你会发现命令行会有如下提示： 它告诉你，在根目录的下的 source 文件夹中创建了一个 _post 文件夹，并且在内生成了一个myBlog.md的文件。打开对应的文件夹，你会发现myBlog.md的文件，这就是你新生成的文件。你可以通过某种支持markdown的编辑器打开这个文件，然后使用markdown格式的方法书写这篇博客。 layout 为 draft 的情况Hexo 的一种特殊布局：draft，这种布局在建立时会被保存到 source/_drafts 文件夹。 接下来我们使用hexo new draft myDraftBlog，生成myDrafaBlog.md文件，这个 md 文件是草稿状态，也就是说，这篇文章仅仅是作为你的草稿而不是正式稿，所以不会发表在博客主页上。草稿就是需要你不断完善的文章，知道有一天你觉得这篇文章可以正式发表了，你可通过 publish 命令将草稿移动到 source/_posts 文件夹，该命令的使用方式与 new 十分类似，您也可在命令中指定layout 来指定布局。 publish1$ hexo publish [layout] &lt;title&gt; （草稿默认不会显示在页面中，您可在执行时加上 –draft 参数，或是把 render_drafts 参数设为 true 来预览草稿。） 执行hexo publish draft myDraftBlog，你就会发现，source/_draft文件夹下的myDraftBlog.md文件消失了，而在_post文件夹下你会找到myDraftBlog.md文件。 layout 为 page 的情况我们可以尝试一下下面这个命令hexo new page &quot;about&quot;，这个时候你打开source文件夹你会发现一个about的文件夹，里面会有一个index.md的文件。打开http://localhost:4000/about，这个时候你就会发现你刚才编辑的 index.md 的内容会出现在这里。 layout 为 page的时候，其实就是相当于生成一个新的路径，也就是我们说的url的path，或者也可以称作路由。通过这种方式，我们可以把我们的博客再进行细分各个内容版块，更有条理的组织我们的博客。 Front-matterFront-matter 是文件最上方以 --- 分隔的区域，用于指定个别文件的变量，举例来说： eg1234---title: Hello Worlddate: 2013/7/13 20:46:25--- 以下是预先定义的参数，您可在模板中使用这些参数值并加以利用。 参数 描述 默认值 layout 布局 config.default_layout title 标题 文章的文件名 date 建立日期 文件建立日期 updated 更新日期 文件更新日期 comments 开启文章的评论功能 true tags 标签 （不适用于分页） categories 分类 （不适用于分页） permalink 覆盖文章网址 分类和标签只有文章支持分类和标签，您可以在 Front-matter 中设置。在其他系统中，分类和标签听起来很接近，但是在 Hexo 中两者有着明显的差别：分类具有顺序性和层次性，也就是说 Foo, Bar 不等于 Bar, Foo；而标签没有顺序和层次。 eg12345categories: - Diarytags: - PS3 - Games 如果你需要为文章添加多个分类，可以尝试以下 list 中的方法。 分类Eg1234categories: - [Diary, PlayStation] - [Diary, Games] - [Life] 此时这篇文章同时包括三个分类： PlayStation 和 Games 分别都是父分类 Diary 的子分类，同时 Life 是一个没有子分类的分类。 标签插件具体内容参考官网 参考链接 hexo 写作","link":"/articles/2021/01/05/writing-hexo/"},{"title":"微信小程序云开发获取用户手机号","text":"在网上搜索时，大部分微信小程序云开发获取手机号码的例子还都是需要通过code获取session_key来解密信息取得手机号码，总感觉哪里不对，官网上都已经说过，云开发是自动鉴权的，不应该还要解密,因此下面介绍如何使用云开发获取用户信息数据。 具体步骤1，页面 cellphone.wxml cellphone.wxml1&lt;button open-type=&quot;getPhoneNumber&quot; bindgetphonenumber=&quot;getPhoneNumber&quot;&gt;&lt;/button&gt; 2，文件cellphone.js cellphone.js12345678910111213141516Page({ getPhoneNumber(e) { console.log(e.detail); wx.cloud .callFunction({ name: 'openapi', data: { action: 'getcellphone', id: e.detail.cloudID, }, }) .then((res) =&gt; { console.log('res: ', res); }); },}); 3，云函数 openapi 的index.js index.js123456789101112131415161718192021// 云函数入口文件const cloud = require('wx-server-sdk');cloud.init();// 云函数入口函数exports.main = async (event, context) =&gt; { switch (event.action) { case 'getcellphone': { return getCellphone(event); } default: { return; } }};async function getCellphone(event) { const res = await cloud.getOpenData({ list: [event.id], }); return { res, event };} 调用后res数据如下 res123456789101112131415161718{ &quot;list&quot;: [ { &quot;cloudID&quot;: &quot;***********&quot;, &quot;data&quot;: { &quot;phoneNumber&quot;: &quot;****&quot;, // 用户绑定的手机号（国外手机号会有区号） &quot;purePhoneNumber&quot;: &quot;******&quot;, // 没有区号的手机号 &quot;countryCode&quot;: &quot;86&quot;, // 区号 &quot;watermark&quot;: { &quot;timestamp&quot;: 1612332238, &quot;appid&quot;: &quot;********&quot; } } } ], &quot;errMsg&quot;: &quot;getOpenData:ok&quot;, &quot;errCode&quot;: 0} 全程不涉及code,session_key和加密解密啥事，即可获取到用户的手机号。 参考链接 微信小程序云开发获取手机号码 获取手机号| 微信开放文档 - 微信开放社区 - 腾讯 Cloud.getOpenData(list: string[]): Object","link":"/articles/2021/02/03/wx-get-cellphone/"},{"title":"从零安装必备软件","text":"今日打算重新组装系统，因此需要从零开始安装在 Mac 上的必备的一些软件。 Iterm从官网下载 iterm2 参考 learn-the-command-line-iterm-and-zsh 设定主题 iTerm2 Solarized 配色: https://github.com/altercation/solarized iTerm2 配色合集网站: http://iterm2colorschemes.com/ iTerm2 配色合集 GitHub 地址：https://github.com/mbadolato/iTerm2-Color-Schemes/tree/master/schemes 目前 Solarized 已集成进 Iterm2，可不必下载。 设定字体 Powerline 字体为了终端下能正确的显示 fancy 字符，需要安装 powerline 字体，这样，这些 fancy 字符不至于显示为乱码。 GitHub 上已经有制作好的 Powerline 字体，可以下载了直接安装到系统： Powerline 字体下载: https://github.com/powerline/fonts 安装好之后，就可以选择一款你喜欢的 Powerline 字体了：Preferences -&gt; Profiles -&gt; Text -&gt; Font -&gt; Change Font 导入配置文件配置文件：https://github.com/MrSeaWave/dotfiles/blob/main/iterm2.json Oh my zshhttps://ohmyz.sh/ 1$ sh -c &quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot; 配置导入https://github.com/MrSeaWave/dotfiles/blob/main/zshrc 更多使用参考 oh-my-zsh入门 Homebrewhttps://brew.sh/ 1/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; 如果遇到 Warning: /opt/homebrew/bin is not in your PATH. 报错，参考stackoverflow.com进行解决。 将下面一句写入 ~/.zshrc or ~/.bashrc export PATH=/opt/homebrew/bin:$PATH Githttps://git-scm.com/downloads 如何将命令行中的 git 提示语言改为英文https://blog.csdn.net/michael_wgy_/article/details/105858848 1$ vim ~/.zshrc 添加如下内容： 1alias git='LANG=en_GB git' 更新配置： 1$ source ~/.zshrc Nodehttps://nodejs.org/zh-cn/download/ nhttps://github.com/tj/n 1$ npm install -g n nrmhttps://github.com/Pana/nrm 1$ npm install -g nrm Pnpmhttps://www.pnpm.cn/installation 1$ npm install -g pnpm yarnhttps://yarnpkg.com/getting-started/install Node.js &gt;=16.10 Corepack is included by default with all Node.js installs, but is currently opt-in. To enable it, run the following command: 1corepack enable Node.js &lt;16.10 Corepack isn’t included with Node.js in versions before the 16.10; to address that, run: 1npm i -g corepack live-serverhttps://www.npmjs.com/package/live-server 1$ npm install -g live-server gitlab ssh-keyssh-key使用 fighttps://fig.io/ xniphttps://xnipapp.com/ Pastehttps://pasteapp.io/ Alfredhttps://www.alfredapp.com/ Bardenterhttps://www.macbartender.com/ LICEcaphttps://www.cockos.com/licecap/ Upichttps://github.com/gee1k/uPic uPic 图床配置教程 - Github Unarchiverhttps://theunarchiver.com/ Postmanhttps://www.postman.com/ Sourcetreehttps://www.sourcetreeapp.com/ 更多参考 Mac 上的 APP 推荐","link":"/articles/2022/06/28/begin-install/"},{"title":"用 Node 编写跨平台 spawn 语句","text":"本文将会讲述如何跨平台来使用spawn语句呢？（可以利用cross-spawn spawn当我们想要在js文件中想要调用系统上的命令时，可以利用 Node.js 的子进程（child_process）模块下的 spawn 函数，（与exec区别可以查看issue，本文不作介绍），如在 Linux, macOS 等系统上，我们可以执行： 12345const spawn = require('child_process').spawn;spawn('npm', { stdio: 'inherit',}); 来调用 npm 命令。 然而，同样的语句在 Windows 上执行则会报错： 123456789Error: spawn npm ENOENT at exports._errnoException (util.js:855:11) at Process.ChildProcess._handle.onexit (internal/child_process.js:178:32) at onErrorNT (internal/child_process.js:344:16) at nextTickCallbackWith2Args (node.js:455:9) at process._tickCallback (node.js:369:17) at Function.Module.runMain (module.js:432:11) at startup (node.js:141:18) at node.js:980:3 因为在 Windows 上，当我们执行 npm 时，实际执行的是 npm.cmd 批处理，而在 Windows 上，.cmd, .bat 批处理是无法脱离 cmd.exe 这一解释器而单独运行的。 因此，需要显式地调用 cmd 123spawn('cmd', ['/c', 'npm'], { stdio: 'inherit',}); 或者使用在调用 spawn 函数时，设置 shell 选项为 true 以隐式地调用 cmd （该选项添加自 Node.js v6 版本） 1234spawn('npm', { stdio: 'inherit', shell: true,}); 另外，虽然在 Linux, macOS 等系统上不需要设置 shell 选项，命令也能够正常执行；设置 shell 为 true 也不会妨碍命令的执行，只是会额外的产生一个本不必要的 shell 进程，影响性能。 因此，如果想要编写跨平台的 spawn 命令，而又不想增加额外的开销的话，可以加个判断： 12345678const process = require('process');const { spawn } = require('child_process');spawn('npm', { stdio: 'inherit', // 仅在当前运行环境为 Windows 时，才使用 shell shell: process.platform === 'win32',}); cross-spawn利用 cross-spawn 轻松编写跨平台命令，使用该模块，在调用 spawn 函数时，它会自动根据当前的运行平台，来决定是否生成一个 shell 来执行所给的命令。 如： 12345const spawn = require('cross-spawn');spawn('npm', { stdio: 'inherit',}); 参考链接 child_process.spawn cross-spawn Node.js 编写跨平台 spawn 语句","link":"/articles/2022/01/08/cross-spawn/"},{"title":"使用 depcheck 清理 package.json 中用不到的依赖","text":"背景随着时间的推移，项目中 package.json 中的依赖越来越臃肿，安装依赖的速度越来越慢，各种奇奇怪怪的包，不一定都会用到，因此我们可以为项目减负，使用 depcheck 检测项目中不用的依赖包，然后移除它们。 安装1$ npm install -g depcheck 需要 node.js &gt;= 10 使用在项目目录下直接执行命令 depcheck，或者 depcheck &lt;你的项目目录&gt; 然后会出来这样的结果： 1234567$&gt; depcheck /path/to/my/projectUnused dependencies* underscoreUnused devDependencies* jasmineMissing dependencies* lodash Unused 表示没有使用的依赖包，Missing 表示使用到了但是没有在 json 文件中声明的依赖包 需要注意特殊的包。如官网所述： 不过可以使用参数过滤掉不想被检测的文件或者不想检测出来的包 常用的参数： --skip-missing=[true | false]：默认 false，表示是否检测 Missing 的依赖包 --ignore-bin-package=[true | false]：默认 false，表示是否忽略包含 bin 条目的包 --json：表示所有包的检测结果以 json 格式输出，大概就是 XX 包在哪些文件使用了，{&quot;包名&quot;:[&quot;path1&quot;,&quot;path2&quot;]} --ignores=&quot;eslint,babel-*&quot;：表示要忽略的包名称（逗号分隔），比如 depcheck --ignores=&quot;eslint,@babel/*,babel-*&quot; --ignore-path：表示要忽略的文件的模式的文件的路径，比如 depcheck --ignore-path=.eslintignore --ignore-dirs：已经弃用，使用 --ignore-patterns 替代，表示要忽略的目录名，逗号分隔--ignore-dirs=dist,coverage --ignore-patterns：表示要忽略的用逗号分隔的模式描述文件，比如 depcheck --ignore-patterns=build/Release,dist,coverage,*.log --parsers, --detectors and --specials：高级的语法使用参考官方文档 --config=[filename]：外部配置文件 注意：也可以创建一个 .depcheckrc 文件（yml/json格式），然后直接配置 12ignores: ['eslint', 'babel-*', '@babel/*']skip-missing: true 注：结果仅供参考，移除相应依赖一定要小心！！！ 参考链接 depcheck 使用 depcheck 清理 package.json 中用不到的套件","link":"/articles/2022/02/10/depcheck/"},{"title":"定制 Github 主页","text":"Github 作为一个资源托管平台，我们有没有想过在主页锦上添花否？ 这不，你可以通过 yourUsername/yourUsername 来制作你的名片。 先跟大家展示下我最终实现的效果，在线体验地址：Github 主页。 创建仓库 首先，登录你的Github账号： 登录后，创建一个和你用户名相同的仓库，填写仓库介绍、设置公开权限、添加 README.md 文件，如下所示: ​ 最后点击 Create repository按钮，即可完成仓库创建。 界面美化我们创建完仓库后，进入自己的个人主页，即：github.com/你的用户名。 我们能看到的页面如下所示，红框部分就是我们刚才创建仓库的README.md文件里的内容。 因此，我们只需要修改我们刚才创建的仓库中的 README.md 文件中的内容，我们的主页内容就会跟着更新。 资源 awesome-github-profile-readme：里面收集了很多关于主页的模版，大家可以参考下别人的设计思路，稍微修改修改就是自己的了[旺柴] 个性化设计徽章(Badge)网站：https://shields.io/ 不仅提供而且可以定制很多有趣的徽章 动态访问量徽章 visitor-badge Moe-counter 二次元展示访问量 项目展示卡片github-readme-stats 利用 Github 官方提供的 API 接口，我们可以得到用户自己的项目情况。 统计代码时常利用 WakaTime 对事情的统计功能，并绑定到 Github 来实现展示。官网：WakaTime 总结一下简要的步骤 注册 wakatime 账号 在自己常用的 IDE 上下载 wakatime 插件，配置上自己的 API key 将自己的 API key 存到自己 GitHub 仓库的 secrets 在 README 文件上加上 12&lt;!--START_SECTION:waka--&gt;&lt;!--END_SECTION:waka--&gt; 配置 GitHub 仓库的 Action，这样就能每天自动运行了 Emojiemoji-cheat-sheet gitmoji Github 关注活跃图表由github-readme-activity-graph 提供的 api 实现: 获取最新博客文章blog-post-workflow 最后上述功能可以利用 github-profile-readme-generator，你会喜欢上它的~ 参考链接 定制你的 GitHub 主页 打造你 GITHUB 的名片 给自己弄一个酷酷的 Github 主页吧","link":"/articles/2022/01/27/github-profile-readme/"},{"title":"G2 多图形图例问题","text":"谨以此文记录下如何利用 G2 在同一个坐标系内绘制多图时使用图例问题。如无特殊说明，当前 G2 版本为：4.1.37 数据如下： 12345678910111213141516171819202122const data = [ { time: '9:00-10:00', value: 30, value2: 30, }, { time: '10:00-11:00', value: 90, value2: 20, }, { time: '11:00-12:00', value: 50, value2: 40, }, { time: '12:00-13:00', value: 30, value2: 50, },]; 利用上述数据绘制出： 利用 G2 Geometry 的 color 属性配置 color 通道映射规则。field 参与颜色映射的数据字段，具体查看官网 首先将源数据改为如下 12345678910111213141516171819202122232425262728293031323334353637383940414243const originData = [ { time: '9:00-10:00', value: 30, value2: 30, }, { time: '10:00-11:00', value: 90, value2: 20, }, { time: '11:00-12:00', value: 50, value2: 40, }, { time: '12:00-13:00', value: 30, value2: 50, },];const data1 = [];const data2 = [];originData.forEach((item) =&gt; { const { time, value, value2 } = item; data1.push({ time, value, type: '销售额Custom' }); data2.push({ time, value2, type2: '销售额Line' });});const data = [...data1, ...data2];// data [// { time: '9:00-10:00', value: 30, type: '销售额Custom' },// { time: '10:00-11:00', value: 90, type: '销售额Custom' },// { time: '11:00-12:00', value: 50, type: '销售额Custom' },// { time: '12:00-13:00', value: 30, type: '销售额Custom' },// { time: '9:00-10:00', value2: 30, type2: '销售额Line' },// { time: '10:00-11:00', value2: 20, type2: '销售额Line' },// { time: '11:00-12:00', value2: 40, type2: '销售额Line' },// { time: '12:00-13:00', value2: 50, type2: '销售额Line' }// ] 完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import { Chart } from '@antv/g2';const originData = [ { time: '9:00-10:00', value: 30, value2: 30, }, { time: '10:00-11:00', value: 90, value2: 20, }, { time: '11:00-12:00', value: 50, value2: 40, }, { time: '12:00-13:00', value: 30, value2: 50, },];const data1 = [];const data2 = [];originData.forEach((item) =&gt; { const { time, value, value2 } = item; data1.push({ time, value, type: '销售额Custom' }); data2.push({ time, value2, type2: '销售额Line' });});const data = [...data1, ...data2];const chart = new Chart({ container: 'container', autoFit: true, height: 500, padding: 'auto',});chart.data(data);chart.scale('value', { alias: '销售额(万)', nice: true,});chart.scale('value2', { alias: '销售额(万)', nice: true,});chart.axis('time', { tickLine: null,});chart.axis('value2', { // 坐标系网格不展示 grid: null,});chart.tooltip({ showMarkers: false,});// 有图例是因为按照type来画图，为了让图例在同一水平线上chart.legend('type', { position: 'bottom', maxWidth: 100, offsetY: -30, offsetX: 100,});chart.legend('type2', { position: 'bottom', maxWidth: 100,});chart.interaction('active-region');chart.removeInteraction('legend-filter');chart.interaction('legend-visible-filter');// color 使用不同的field的颜色chart.interval().position('time*value').color('type', '#2194ff');chart.line().position('time*value2').color('type2', '#fdae6b');chart.tooltip({ // 合并当前点对应的所有数据并展示 shared: true,});chart.render(); 使用自定义图例在利用上述方式时，图例在下面位置只能纵向排列，比较难受，因此产生如下方法，使用自定义图例 点击图例时利用 chart.filter点击图例后设置数据筛选规则，去过滤数据，相关文档查看官网 首先同样改造数据： 12345678910111213141516171819202122232425262728293031323334353637383940414243const originData = [ { time: '9:00-10:00', value: 30, value2: 30, }, { time: '10:00-11:00', value: 90, value2: 20, }, { time: '11:00-12:00', value: 50, value2: 40, }, { time: '12:00-13:00', value: 30, value2: 50, },];const data1 = [];const data2 = [];originData.forEach((item) =&gt; { const { time, value, value2 } = item; data1.push({ time, value, type: '销售额Custom' }); data2.push({ time, value2, type2: '销售额Line' });});const data = [...data1, ...data2];// data [// { time: '9:00-10:00', value: 30, type: '销售额Custom' },// { time: '10:00-11:00', value: 90, type: '销售额Custom' },// { time: '11:00-12:00', value: 50, type: '销售额Custom' },// { time: '12:00-13:00', value: 30, type: '销售额Custom' },// { time: '9:00-10:00', value2: 30, type2: '销售额Line' },// { time: '10:00-11:00', value2: 20, type2: '销售额Line' },// { time: '11:00-12:00', value2: 40, type2: '销售额Line' },// { time: '12:00-13:00', value2: 50, type2: '销售额Line' }// ] 完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126import { Chart } from '@antv/g2';const originData = [ { time: '9:00-10:00', value: 30, value2: 30, }, { time: '10:00-11:00', value: 90, value2: 20, }, { time: '11:00-12:00', value: 50, value2: 40, }, { time: '12:00-13:00', value: 30, value2: 50, },];const data1 = [];const data2 = [];originData.forEach((item) =&gt; { const { time, value, value2 } = item; data1.push({ time, value, type: '销售额Custom' }); data2.push({ time, value2, type2: '销售额Line' });});const data = [...data1, ...data2];const chart = new Chart({ container: 'container', autoFit: true, height: 500, padding: 'auto',});chart.data(data);chart.scale('value', { alias: '销售额(万)', nice: true,});chart.scale('value2', { alias: '销售额(万)', nice: true,});chart.axis('time', { tickLine: null,});chart.axis('value2', { // 坐标系网格不展示 grid: null,});chart.tooltip({ showMarkers: false,});// 自定义图例，为了让图例横向chart.legend({ custom: true, items: [ { value: 'value', name: '销售额Custom', marker: { symbol: 'square', style: { fill: '#3182bd', r: 5 } }, }, { value: 'value2', name: '销售额line', marker: { symbol: 'hyphen', style: { stroke: '#fdae6b', r: 5, lineWidth: 3 }, }, }, ],});// 监听图例点击事件chart.on('legend-item:click', (ev) =&gt; { const target = ev.target; const delegateObject = target.get('delegateObject'); // 当前图例的数据 const item = delegateObject.item; console.log('item', item); // 遍历所有图例，获取当前点击后依然展示的图例： let showLegend = []; for (let i = 0; i &lt; delegateObject.legend.get('items').length; i++) { if (!delegateObject.legend.get('items')[i].unchecked) { showLegend.push(delegateObject.legend.get('items')[i].value); } } showLegend = [...showLegend]; console.log('showLegend', showLegend); console.log('filed item.value', item.value); // 针对当前的filed,从原始数据data中过滤出有效数据 chart.filter(item.value, (value) =&gt; { if (value === undefined) { return true; } else { return showLegend.includes(item.value); } }); // 一下更新chart方法都可以 // console.log(&quot;data&quot;, data); // chart.changeData(data); chart.render(true);});chart.interaction('active-region');// 使用自带的过滤交互，unchecked会被设定为true// chart.removeInteraction(&quot;legend-filter&quot;);// chart.interaction(&quot;legend-visible-filter&quot;);chart.interval().position('time*value').color('type', '#2194ff');chart.line().position('time*value2').color('type2', '#fdae6b');chart.tooltip({ // 合并当前点对应的所有数据并展示 shared: true,});chart.render(); 点击图例时利用 chart.changeVisible()上述都是要先改造数据利用 color，那能否直接使用原生数据呢？ 答案是可以的，我们可以利用chart.changeVisible()来显示或隐藏图表。具体查看官网 完整代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import { Chart } from '@antv/g2';const data = [ { time: '9:00-10:00', value: 30, value2: 30, }, { time: '10:00-11:00', value: 90, value2: 20, }, { time: '11:00-12:00', value: 50, value2: 40, }, { time: '12:00-13:00', value: 30, value2: 50, },];const chart = new Chart({ container: 'container', autoFit: true, height: 500, padding: 'auto',});chart.data(data);chart.scale('value', { alias: '销售额(万)', nice: true,});chart.scale('value2', { alias: '销售额(万)', nice: true,});chart.axis('time', { tickLine: null,});chart.tooltip({ showMarkers: false,});// 自定义图例chart.legend({ custom: true, items: [ { value: 'value', name: '销售额Custom', marker: { symbol: 'square', style: { fill: '#3182bd', r: 5 } }, }, { value: 'value2', name: '销售额line', marker: { symbol: 'hyphen', style: { stroke: '#fdae6b', r: 5, lineWidth: 3 }, }, }, ],});chart.on('legend-item:click', (ev) =&gt; { const target = ev.target; const delegateObject = target.get('delegateObject'); const item = delegateObject.item; console.log('item', item); console.log('filed item.value', item.value); // 获取当前图表 const currentGeometry = chart.geometries.find((w: any) =&gt; { return w.getAttribute('position').getFields()[1] === item.value; }); if (currentGeometry) { // 更改图展示状态 currentGeometry.changeVisible(!currentGeometry.visible); }});chart.interaction('active-region');// 使用自带的过滤交互，unchecked会被设定为true// chart.removeInteraction(&quot;legend-filter&quot;);// chart.interaction(&quot;legend-visible-filter&quot;);chart.interval().position('time*value').color('#2194ff');chart.line().position('time*value2').color('#fdae6b');chart.tooltip({ // 合并当前点对应的所有数据并展示 shared: true,});chart.render(); 全部手控，包括图例的点击状态在上几个代码中我们可以发现在图例交互时都是使用原生的legend-filter交互，每次点击后delegateObject.item.unchecked都已经被修改。在此我们可以自定义交互，靠我们自己去手动修改unchecked的状态，依此可以干出很多事（例如最后一个图例时点击无效等 首先我们需要注册下自己的交互： 12345678910111213import { Chart, registerInteraction } from '@antv/g2';// 白嫖图例点击时的手势registerInteraction('chart-custom-legend-filter', { showEnable: [ { trigger: 'legend-item:mouseenter', action: 'cursor:pointer' }, { trigger: 'legend-item:mouseleave', action: 'cursor:default' }, ], start: [ // { trigger: 'legend-item:click', action: 'list-unchecked:toggle' }, // { trigger: 'legend-item:click', action: 'data-filter:filter' }, ],}); 完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119import { Chart, registerInteraction } from '@antv/g2';// 白嫖图例点击时的手势registerInteraction('chart-custom-legend-filter', { showEnable: [ { trigger: 'legend-item:mouseenter', action: 'cursor:pointer' }, { trigger: 'legend-item:mouseleave', action: 'cursor:default' }, ], start: [ // { trigger: 'legend-item:click', action: 'list-unchecked:toggle' }, // { trigger: 'legend-item:click', action: 'data-filter:filter' }, ],});const data = [ { time: '9:00-10:00', value: 30, value2: 30, }, { time: '10:00-11:00', value: 90, value2: 20, }, { time: '11:00-12:00', value: 50, value2: 40, }, { time: '12:00-13:00', value: 30, value2: 50, },];const chart = new Chart({ container: 'container', autoFit: true, height: 500, padding: 'auto',});chart.data(data);chart.scale('value', { alias: '销售额(万)', nice: true,});chart.scale('value2', { alias: '销售额(万)', nice: true,});chart.axis('time', { tickLine: null,});chart.axis('value2', { // 坐标系网格不展示 grid: null,});chart.tooltip({ showMarkers: false,});// 自定义图例，为了让图例横向chart.legend({ custom: true, items: [ { value: 'value', name: '销售额Custom', marker: { symbol: 'square', style: { fill: '#3182bd', r: 5 } }, }, { value: 'value2', name: '销售额line', marker: { symbol: 'hyphen', style: { stroke: '#fdae6b', r: 5, lineWidth: 3 }, }, }, ],});chart.on('legend-item:click', (ev) =&gt; { const target = ev.target; const delegateObject = target.get('delegateObject'); const item = delegateObject.item; const originUnchecked = item.unchecked; console.log('originUnchecked', originUnchecked); console.log('item', item); console.log('filed item.value', item.value); // 获取当前图表 const currentGeometry = chart.geometries.find((w: any) =&gt; { return w.getAttribute('position').getFields()[1] === item.value; }); if (currentGeometry) { // 更改图展示状态 currentGeometry.changeVisible(!currentGeometry.visible); } // 更改图例状态 delegateObject.item.unchecked = !originUnchecked; // 触发更新流程 chart.render(true);});chart.interaction('active-region');// 自定义图例，移除默认的分类图例筛选交互，使用自定义图例chart.removeInteraction('legend-filter');chart.interaction('chart-custom-legend-filter');chart.interval().position('time*value').color('#2194ff');chart.line().position('time*value2').color('#fdae6b');chart.tooltip({ // 合并当前点对应的所有数据并展示 shared: true,});chart.render(); 以下是上述代码运行实际状态：（如果想要看不同文件的绘制，请更换 package.json 中的 main 对应的值） 参考链接 G2 legend G2 Geometry G2 Interaction","link":"/articles/2022/01/07/g2-multiple-geometry-legend/"},{"title":"阅读 install-pkg 源码","text":"本文是在看到 《Vue 团队核心成员开发的 39 行小工具 install-pkg 安装包，值得一学！》 文章后，对 @antfu/install-pkg 进行的一次源码阅读。 install-pkg 介绍 Install package programmatically. Detect package managers automatically (npm, yarn and pnpm). 自动检测包管理器（npm、yarn 和 pnpm）来编程式安装包依赖。 1npm i @antfu/install-pkg 123import { installPackage } from '@antfu/install-pkg';await installPackage('vite', { silent: true }); 源码入口文件 src/index.ts导出所有 12export * from './detect';export * from './install'; install.ts installPackage 安装包支持指定包管理器，支持安装多个依赖，支持额外的参数。 12345678910111213141516171819202122232425262728293031import execa from 'execa';import { detectPackageManager } from '.';export interface InstallPackageOptions { cwd?: string; dev?: boolean; silent?: boolean; packageManager?: string; preferOffline?: boolean; additionalArgs?: string[];}export async function installPackage(names: string | string[], options: InstallPackageOptions = {}) { // 包管理器 const agent = options.packageManager || (await detectPackageManager(options.cwd)) || 'npm'; if (!Array.isArray(names)) names = [names]; // 额外的依赖 const args = options.additionalArgs || []; if (options.preferOffline) args.unshift('--prefer-offline'); return execa( agent, [agent === 'yarn' ? 'add' : 'install', options.dev ? '-D' : '', ...args, ...names].filter(Boolean), { stdio: options.silent ? 'ignore' : 'inherit', cwd: options.cwd, } );} 上述代码最终执行类似如下脚本： 1yarn add -D react react-dom detect.ts detectPackageManager 包探测器根据当前的锁文件(yarn.lock or package-lock.json or pnpm-lock.yaml )判断是哪个包管理器 123456789101112131415161718import path from 'path';import findUp from 'find-up';export type PackageManager = 'pnpm' | 'yarn' | 'npm';const LOCKS: Record&lt;string, PackageManager&gt; = { 'pnpm-lock.yaml': 'pnpm', 'yarn.lock': 'yarn', 'package-lock.json': 'npm',};// process.cwd()是 返回当前工作目录。如：调用node命令执行脚本时的目录。export async function detectPackageManager(cwd = process.cwd()) { // 通过findUp 获取当前目录lock文件 const result = await findUp(Object.keys(LOCKS), { cwd }); const agent = result ? LOCKS[path.basename(result)] : null; return agent;} 其中需要注意的一些 node 相关的知识： process.cwd(): 返回当前工作目录。如：调用 node 命令执行脚本时的目录。 __dirname: 返回源代码所在的目录。 path.basename(): 返回 path 的最后一部分 12345path.basename('/foo/bar/baz/asdf/quux.html');// 返回: 'quux.html'path.basename('/foo/bar/baz/asdf/quux.html', '.html');// 返回: 'quux' 其中findUp为查找文件路径： 12345678/└── Users └── sindresorhus ├── unicorn.png └── foo └── bar ├── baz └── example.js 12345678910111213141516171819import path from 'node:path';import { findUp, pathExists } from 'find-up';console.log(await findUp('unicorn.png'));//=&gt; '/Users/sindresorhus/unicorn.png'console.log(await findUp(['rainbow.png', 'unicorn.png']));//=&gt; '/Users/sindresorhus/unicorn.png'console.log( await findUp( async (directory) =&gt; { const hasUnicorns = await pathExists(path.join(directory, 'unicorn.png')); return hasUnicorns &amp;&amp; directory; }, { type: 'directory' } ));//=&gt; '/Users/sindresorhus' 所以在有yarn.lock文件的项目中，detectPackageManager 函数最终返回 agent 的是yarn。 至此，install-pkg的源码已经看完，可以总结原理为： 通过 lock 文件自动检测，确定使用哪一个包管理器（npm、yarn、pnpm），最终用 execa 执行类似如下的命令。 1yarn add -D react react-dom 看完源码，我们也可以看下 package.json 中的 scripts 命令，学习一下。 package.json script 解析123456789&quot;scripts&quot;: { &quot;prepublishOnly&quot;: &quot;nr build&quot;, &quot;dev&quot;: &quot;nr build --watch&quot;, &quot;start&quot;: &quot;esno src/index.ts&quot;, &quot;build&quot;: &quot;tsup src/index.ts --format cjs,esm --dts --no-splitting&quot;, &quot;release&quot;: &quot;bumpp --commit --push --tag &amp;&amp; pnpm publish&quot;, &quot;lint&quot;: &quot;eslint \\&quot;{src,test}/**/*.ts\\&quot;&quot;, &quot;lint:fix&quot;: &quot;nr lint -- --fix&quot; } nr? —-&gt; ni 神器github ni 推荐看尤雨溪推荐神器 ni ，能替代 npm/yarn/pnpm ？简单好用！源码揭秘！ 可以自动根据锁文件 yarn.lock / pnpm-lock.yaml / package-lock.json 检测使用 yarn / pnpm / npm 的包管理器。 例子： nr 交互式选择脚本 12345678910nr# 交互式选择脚本# interactively select the script to run# supports https://www.npmjs.com/package/npm-scripts-info conventionnr dev --port=3000# npm run dev -- --port=3000# yarn run dev --port=3000# pnpm run dev -- --port=3000 nci - clean install 12345nci# npm ci# 简单说就是不更新锁文件# yarn install --frozen-lockfile# pnpm install --frozen-lockfile 等 esnogithub esno 源码不多，如下所示： 12345678910#!/usr/bin/env nodeconst spawn = require('cross-spawn');const spawnSync = spawn.sync;const register = require.resolve('esbuild-register');const argv = process.argv.slice(2);process.exit(spawnSync('node', ['-r', register, ...argv], { stdio: 'inherit' }).status); esbuild-register 简单说：使用 esbuild 即时传输 JSX、TypeScript 和 esnext 功能 cross-spawn：编写跨平台 spawn 语句，可参考《用 Node 编写跨平台 spawn 语句》 tsup打包 TypeScript 库的最简单、最快的方法。 tsup bumpp 交互式提升版本号bumpp version-bump-prompt 交互式 CLI 可增加您的版本号等 总结最后，在 install-pkg 上可查看本篇源码文章~ 参考链接 [Vue 团队核心成员开发的 39 行小工具 install-pkg 安装包，值得一学！](","link":"/articles/2022/01/08/install-pkg/"},{"title":"使用 np 快速发布 npm 包","text":"在之前的文章中 《怎么发布 NPM 包》中，已经介绍了如何使用 npm 进行发包，本文将会介绍一款发包工具 np ，它是由 sindresorhus 大神所创造的一套 npm published 工具，比 npm 原生的 npm publish 多了更多方便的功能！ 前言你了解业内是如何发布 npm 包的吗？ 参考一个流行的框架，比如 React。如果你仔细研究，你会注意到一些事情： 首先，React 有一个Github仓库； 其次，React 被发布在NPM上； 第三，React 遵循 Semantic versioning（语义化版本） 第四，每一次的更新都有一个git tag关联它，这个tag也遵循语义化版本。 第五，release notes 记录着 React 的每一次更新。 这意味着发布包涉及很多步骤。至少，你需要： 运行测试用例（如果有的话） 根据Semantic versioning修改package.json更新版本号 根据Semantic versioning创建 git tag 发布包到 Github 发布包到 NPM 为每次更新创建 release notes 当我们准备发布包的时候，忘记其中一件事是很常见的。 有一个更简单的方式帮我们完成以上步骤，利用工具 np。 npnp 一款 比 npm 原生的 npm publish 多了更多方便的功能的工具 优点： 互动界面 确保从 master branch 发布 package 确保工作工作目录是干净且沒有任何的修改 根据 dependency tree 重新安裝依赖确保目前的 project 是最新的 自动执行测试 更多请参考 README。 安装1npm install np or 全局安装 np，使我们可以在任何地方运行 np。 1npm install --global np 在使用 np 前，你需要确定： 你的项目是一个 Git 仓库（repository） 需要添加远端仓库（remote）的地址 你必须至少已经push到 remote 一次 你也需要确定你的工作目录是干净的 发布package.json如下： 123456789101112131415161718192021222324{ &quot;name&quot;: &quot;np-pub-test&quot;, &quot;version&quot;: &quot;1.0.2&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;files&quot;: [&quot;index.js&quot;], &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot; -------run test---------- \\&quot;&quot;, &quot;release&quot;: &quot;np --no-yarn --no-2fa&quot; }, &quot;repository&quot;: { &quot;type&quot;: &quot;git&quot;, &quot;url&quot;: &quot;git+https://github.com/MrSeaWave/np-pub-test.git&quot; }, &quot;author&quot;: &quot;Sea &lt;MrDaemon@outlook.com&gt;&quot;, &quot;license&quot;: &quot;MIT&quot;, &quot;bugs&quot;: { &quot;url&quot;: &quot;https://github.com/MrSeaWave/np-pub-test/issues&quot; }, &quot;homepage&quot;: &quot;https://github.com/MrSeaWave/np-pub-test#readme&quot;, &quot;devDependencies&quot;: { &quot;np&quot;: &quot;^7.6.0&quot; }} 运行npm run release进行发包 根据提示选择版本： 之后，np 会帮你完成其余的发布工作。 在流程的最后。np 会启动浏览器窗口，在这写你的 release notes。 总之，np 使得 npm 发包过程变得非常简单！ 问题问题 1通常我们做一个规范点的组件包，都会使用commitizen。当然还要结合.commitlintrc，来规范和约束我们的commit message。 那么问题来了： 怎么修改np的commit message 阅读官方文档后发现，增加--message即可 123456{ &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot; -------run test---------- \\&quot;&quot;, &quot;release&quot;: &quot;np --no-yarn --no-2fa --message \\&quot;chore(release): v%s \\&quot;&quot; }} 问题 2因为 np 发布要有干净的工作区。因此 如果我们有修改的文件没有提交。如下： 或 如果我们有新建的文件未提交，如下： 然后我们去发布时，会发现发布失败 这是因为 np 源码是依照下图判断工作区是否干净 123$ git status --porcelain M index.js?? doc.md 如果改为这个可能会更好，但也未必。： 只监听想要提交到暂存区的数据 12$ git status --short | grep '^[MARCD]'M index.js 场景：修改 CHANGELOG.md 文件后，和 package.json 一起发布 问题 3发包会默认选择用 yarn，可以在 package.json 中使用publishConfig.registry设定发布地址 如下： 12345{ &quot;publishConfig&quot;: { &quot;registry&quot;: &quot;https://registry.npmjs.org/&quot; }} 也可以关闭 yarn (--no-yarn)，使用 npm 123456{ &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot; -------run test---------- \\&quot;&quot;, &quot;release&quot;: &quot;np --no-yarn --no-2fa --message \\&quot;chore(release): v%s \\&quot;&quot; }} 后续待记录。。。 参考链接 np 怎么发布 NPM 包（业内的做法） 透過 np 快速發佈你的 package 到 npm.js 你真的懂 npm publish？","link":"/articles/2022/01/27/np-publish/"},{"title":"怎么发布 NPM 包","text":"将包发布到 NPM（node package manager）上很简单，只需要 2 步： 创建包 发布包 前置动作 你需要一个 NPM 账号。如果没有的话，点此创建。 通过命令行登录你的 npm 账号。 添加用户添加注册表用户账户 1234$ npm adduserUsername:Password:Email: 登录npm login 是 add user 的别名，并且行为完全相同。 1234$ npm loginUsername:Password:Emial: 创建包像这样创建一个文件夹，之后进入到该文件夹内。 123$ mkdir pub-test$ cd pub-test 下一步，通过运行 npm init命令生成 package.json 1$ npm init 发布最后一步，在要发布的文件目录下，用 npm publish发布该项目 仅仅当 package.json 文件中的 version 变化时才能发布，不然 npm 会认为当前版本没有变动 1$ npm publish 如果发布的包和别人同名，则可能会出现以下报错： 可以通过 1$ npm search pub-test 查看是否被占用 修改包名重新发布，如下修改为： 1234567891011{ &quot;name&quot;: &quot;pub-test-demo-1&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot; }, &quot;author&quot;: &quot;Sea &lt;MrDaemon@outlook.com&gt;&quot;, &quot;license&quot;: &quot;MIT&quot;} 发布成功如下： 取消发布有了发布，那么必然有取消发布 1$ npm unpublish 12npm unpublish [&lt;@scope&gt;/]&lt;pkg&gt;@&lt;version&gt;npm unpublish [&lt;@scope&gt;/]&lt;pkg&gt; --force 对于取消发布，仅仅能在发布后的 24 小时内取消。 npm 测试包开发阶段测试 当本地写完 npm 包的代码时，如果是业务依赖或者有服务依赖想简单跑个主流程，很简单我们就在本地项目引入这个本地 npm 包，比如 B 项目 依赖 本地开发的 npm 包 A，那我们开始安装一下： 方法一 1$ npm install --save ../A/packages/modules 或者 1$ yarn add ../A/packages/modules 即可，安装成功后会 发现 B 项目的 package.json 中显示依赖如下 “A”: “file:../A/packages/modules” 注意：modules 文件夹下需要包含 package.json 文件并在文件夹中申明 包名和入口文件如下： 12345678910{ &quot;name&quot;: &quot;A&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;description&quot;: &quot;基础库&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot; }, &quot;license&quot;: &quot;MIT&quot;} 方法二在这里，我们有两个项目，一个是npm-link-module，是我们要开发的npm模块，另一个是npm-link-example，是我们要运行npm模块的项目首先，进入npm-link-module项目，执行npm link（yarn也是一样） 12$ cd npm-link-module$ npm link 然后，进入npm-link-example项目，执行npm link npm-link-module 12$ cd npm-link-example$ npm link npm-link-module 卸载 1$ npm unlink npm-link-module 开发的自动化测试 使用 jest 测试 人工测试 npm 部分命令npm view 查看包的信息 1npm view 包名 npm info 在当前包下查看包的信息 1npm info npm dist-tag 显示所有的 tag 信息 1npm dist-tag ls [&lt;pkg&gt;] 即npm dist-tag获取到所有的最新的版本，包括prerelease与稳定版本 切换 tag 1npm dist-tag add &lt;pkg&gt;@&lt;version&gt; latest 其他发布一个带 tag 的版本1npm publish --tag next 增加--tag参数和后面的tag名字即可 版本号npm 使用的是一种叫做 semantic version 的规范，它的规则很简单，总结起来就是下面几条： 使用 semver 的软件必须定义公开、严谨、易于理解的 API。也就是模块要提供功能给用户。 版本号格式为：X.Y.Z，并且 X、Y、Z 均为正整数并且不断递增。X 表示大版本（major）、Y 表示小版本（minor）、Z 表示补丁版本（patch）。 一个版本发布后，此版本内容不能再变更，变更必须再发布一个新版本。也就是不能覆盖发布。 0.Y.Z 表示初始版本，这种版本下的 API 不能保证稳定，随时可能变更。 当进行了向后兼容的 bug 修复时，补丁版本 Z 必须增加。 当引入了向后兼容的新功能时，小版本 Y 必须增加，同时 Z 必须重置为 0（小版本里面可能会包含 bug 修复）。 当引入了不兼容的变更时，大版本 X 必须增加，同时 Y、Z 必须重置为 0（大版本里面可能会包含小版本或者补丁版本的改动）。 X.Y.Z 后面还可以加预发布版本号、构建信息，格式为：X.Y.Z-pre_lease+build_meta，比如：1.0.0-alpha+20151226、1.0.0-beta.2+20151230。 进行版本号比较时，遵循下面的规则： 1）依次按数值比较 X、Y、Z 的值，直到第一个不同的位置； 2）如果两个版本的 X、Y、Z 都相等，含有 pre-release 版本号的较小； 3）如果两个版本的 X、Y、Z 都相等并且都含有 pre-release 版本号，要单独比较 pre-release 版本。比如：1.0.0 &lt; 2.0.0 &lt; 2.1.0 &lt; 2.1.1，1.0.0-alpha &lt; 1.0.0，1.0.0-alpha &lt; 1.0.0-alpha.1 &lt; 1.0.0-alpha.beta &lt; 1.0.0-beta &lt; 1.0.0-beta.2 直接使用 npm version 命令自动搞定版本号的更改 npm version 功能 major - 如果没有预发布号，则直接升级一位大号，其他位都置为 0 - 如果有预发布号： – 中号和小号都为 0，则不升级大号，而将预发布号删掉。即 2.0.0-1 变成 2.0.0，这就是预发布的作用 – 如果中号和小号有任意一个不是 0，那边会升级一位大号，其他位都置为 0，清空预发布号。即 2.0.1-0 变成 3.0.0 minor - 如果没有预发布号，则升级一位中号，大号不动，小号置为空 - 如果有预发布号: – 如果小号为 0，则不升级中号，将预发布号去掉 – 如果小号不为 0，同理没有预发布号 patch - 如果没有预发布号：直接升级小号，去掉预发布号 - 如果有预发布号：去掉预发布号，其他不动 premajor - 直接升级大号，中号和小号置为 0，增加预发布号为 0 preminor - 直接升级中号，小号置为 0，增加预发布号为 0 prepatch - 直接升级小号，增加预发布号为 0 prerelease - 如果没有预发布号：增加小号，增加预发布号为 0 - 如果有预发布号，则升级预发布号 版本号的三位分别是 大号.中号.小号-预发布号如果执行了prerelease，版本号会从1.1.1-0变成 1.1.1-1或者1.0.5-alpha.1–&gt;1.0.5-alpha.2v1.0.6-alpha—&gt;v1.0.6-alpha.0 123npm version patch =&gt; z+1npm version minor =&gt; y+1 &amp;&amp; z=0npm version major =&gt; x+1 &amp;&amp; y=0 &amp;&amp; z=0 如果项目是 GIT 1npm version patch -m &quot;Upgrade to %s for reasons&quot; package.json 文件一般通过npm init 小图标可以使用 shields.io 生成小图标使用，比如： 参考链接 yarn npm 发包小记","link":"/articles/2022/01/27/npm-publish/"},{"title":"Npm Script","text":"本文将介绍如何使用 npm 脚本（npm scripts）。 介绍NPM 脚本是 package.json 中定义的一组内置脚本和自定义脚本。他们的目标是提供一种简单的方法来执行重复的任务，比如： 启动项目 打包项目 执行单元测试，生成测试报告之类 …… 那如何定义一个 NPM 脚本？需要做的就是设置它的名称，并在 package.json 文件的 script 属性中编写该脚本, 如下： 123456{ // ... &quot;scripts&quot;: { &quot;build&quot;: &quot;node build.js&quot; }} 上面代码是package.json文件的一个片段，里面的scripts字段是一个对象。它的每一个属性，对应一段脚本。比如，build命令对应的脚本是node build.js。 命令行下使用npm run命令，就可以执行这段脚本。 123$ npm run build# 等同于执行$ node build.js 这些定义在package.json里面的脚本，就称为 npm 脚本。它的优点有很多。 查看当前项目的所有 npm 脚本命令，可以使用不带任何参数的npm run命令。 1$ npm run 原理npm 脚本的原理非常简单。每当执行npm run，就会自动新建一个 Shell，在这个 Shell 里面执行指定的脚本命令。因此，只要是 Shell（一般是 Bash）可以运行的命令，就可以写在 npm 脚本里面。 比较特别的是，npm run新建的这个 Shell，会将当前目录的node_modules/.bin子目录加入PATH变量，执行结束后，再将PATH变量恢复原样。 这意味着，当前目录的node_modules/.bin子目录里面的所有脚本，都可以直接用脚本名调用，而不必加上路径。 比如： 1234567891011{ &quot;scripts&quot;: { &quot;lint&quot;: &quot;./node_modules/.bin/eslint --ext .js&quot; }}// 此写法与上面效果相同{ &quot;scripts&quot;: { &quot;lint&quot;: &quot;eslint --ext .js&quot; }} 由于 npm 脚本的唯一要求就是可以在 Shell 执行，因此它不一定是 Node 脚本，任何可执行文件都可以写在里面。 npm 脚本的退出码，也遵守 Shell 脚本规则。如果退出码不是0，npm 就认为这个脚本执行失败。 传参向 npm 脚本传入参数，要使用--标明。 例如向上面的npm run lint命令传入参数--cache，必须写成下面这样。 1$ npm run lint -- --cache 运行如下： 12345$ npm run lint -- --cache&gt; @ lint /Users/sea/workspace/personal/tem/np-pub-test&gt; eslint --ext .js &quot;--cache&quot; 执行顺序如果 npm 脚本里面需要执行多个任务，那么需要明确它们的执行顺序。 如果是继发执行（即只有前一个任务成功，才执行下一个任务），可以使用&amp;&amp;符号。 1$ npm run lint &amp;&amp; npm run build 如果是并行执行（即同时的平行执行），可以使用&amp;符号。 1$ npm run lint &amp; npm run build 这两个符号是 Bash 的功能。此外，还可以使用 node 的任务管理模块：script-runner、npm-run-all、redrun。 钩子 pre &amp; postnpm 脚本有pre和post两个钩子，我们可以为任何脚本创建 pre 和 post 钩子，NPM 会自动按顺序运行它们。唯一的要求是脚本的名称(后跟pre或post前缀)与主脚本匹配。例如： 需要注意：双重的pre和post无效，比如prepretest和postposttest是无效的。 1234567{ &quot;scripts&quot;: { &quot;prehello&quot;: &quot;echo \\&quot; ---------- Run Pre Hello World ---------- \\&quot;&quot;, &quot;hello&quot;: &quot;echo \\&quot; ---------- Run Hello World ---------- \\&quot;&quot;, &quot;posthello&quot;: &quot;echo \\&quot; ---------- Run Post Hello World ---------- \\&quot;&quot; }} 如果我们执行 npm run hello，npm 会按以下顺序执行脚本: prehello, hello, posthello。输出如下： 12345678910111213141516$ npm run hello&gt; np-pub-test@1.0.5 prehello /Users/sea/workspace/personal/tem/np-pub-test&gt; echo &quot; ---------- Run Pre Hello World ---------- &quot; ---------- Run Pre Hello World ----------&gt; np-pub-test@1.0.5 hello /Users/sea/workspace/personal/tem/np-pub-test&gt; echo &quot; ---------- Run Hello World ---------- &quot; ---------- Run Hello World ----------&gt; np-pub-test@1.0.5 posthello /Users/sea/workspace/personal/tem/np-pub-test&gt; echo &quot; ---------- Run Post Hello World ---------- &quot; ---------- Run Post Hello World ---------- npm 默认提供下面这些钩子。 prepublish，postpublish preinstall，postinstall preuninstall，postuninstall preversion，postversion pretest，posttest prestop，poststop prestart，poststart prerestart，postrestart 注意，从npm@1.1.71开始 prepublish这个钩子不仅会在npm publish命令之前运行，还会在npm install（不带任何参数）命令之前运行，这种行为很容易让用户感到困惑，所以 npm 4 引入了一个新的钩子prepare，行为等同于prepublish，来替代上述功能，另外一种新钩子prepublishOnly作为替代策略，让用户避免以往 npm 版本的混乱行为，prepublishOnly 只在npm publish前执行，而从 npm 5 开始，prepublish将只在npm publish命令之前运行，即取代prepublishOnly，所以 npm6 即以后的版本会放弃prepublishOnly。 prepare: 在两种情况前运行，一是npm publish命令前，二是不带参数的npm install命令；它会在prepublish之后、prepublishOnly之前执行 prepublishOnly: 在npm publish命令前执行 漫长的历史争论：https://github.com/npm/npm/issues/10074 npm 提供一个npm_lifecycle_event变量，返回当前正在运行的脚本名称，比如pretest、test、posttest等等。所以，可以利用这个变量，在同一个脚本文件里面，为不同的npm scripts命令编写代码。请看下面的例子。 1234567{ &quot;scripts&quot;: { &quot;pretest&quot;: &quot;node index.js&quot;, &quot;test&quot;: &quot;node index.js&quot;, &quot;posttest&quot;: &quot;node index.js&quot; }} 12345678910111213const TARGET = process.env.npm_lifecycle_event;if (TARGET === 'test') { console.log(`Running the test task!`);}if (TARGET === 'pretest') { console.log(`Running the pretest task!`);}if (TARGET === 'posttest') { console.log(`Running the posttest task!`);} 运行如下： 12345678910111213141516$ npm run test&gt; np-pub-test@1.0.5 pretest /Users/sea/workspace/personal/tem/np-pub-test&gt; node index.jsRunning the pretest task!&gt; np-pub-test@1.0.5 test /Users/sea/workspace/personal/tem/np-pub-test&gt; node index.jsRunning the test task!&gt; np-pub-test@1.0.5 posttest /Users/sea/workspace/personal/tem/np-pub-test&gt; node index.jsRunning the posttest task! 简写形式四个常用的 npm 脚本有简写形式。 npm start是npm run start npm stop是npm run stop的简写 npm test是npm run test的简写 npm restart是npm run stop &amp;&amp; npm run restart &amp;&amp; npm run start的简写 npm start、npm stop和npm restart都比较好理解，而npm restart是一个复合命令，实际上会执行三个脚本命令：stop、restart、start。具体的执行顺序如下。 prerestart prestop stop poststop restart prestart start poststart postrestart 变量在执行 NPM 脚本时，NPM 提供了一组我们可以使用的环境变量。 我们可以使用 1npm_config_&lt;val&gt; 或者 npm_package_&lt;val&gt; 通过npm_config_前缀，拿到 npm 的配置变量，即npm config get xxx命令返回的值 通过npm_package_前缀，npm 脚本可以拿到package.json里面的字段。 env命令可以列出所有环境变量 例如： 12345678910{ &quot;name&quot;: &quot;xxx&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;files&quot;: [&quot;index.js&quot;], &quot;scripts&quot;: { &quot;test&quot;: &quot;node index.js&quot; }} 12345// index.jsconsole.log(process.env.npm_package_name); // xxxconsole.log(process.env.npm_package_version); // 0.0.1console.log(process.env.npm_config_node_version); // 14.18.1console.log(process.env); // env {....}，列出所有环境变量 上面代码中，我们通过环境变量process.env对象，拿到package.json的字段值。如果是 Bash 脚本，可以用$npm_package_name和$npm_package_version取到这两个值。 npm_package_前缀也支持嵌套的package.json字段。 1234567891011121314{ &quot;name&quot;: &quot;xxx&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;files&quot;: [&quot;index.js&quot;], &quot;scripts&quot;: { &quot;test&quot;: &quot;node index.js&quot;, &quot;echo:test&quot;: &quot;echo name: $npm_package_name &amp;&amp; echo np version: $npm_package_devDependencies_np&quot; }, &quot;devDependencies&quot;: { &quot;np&quot;: &quot;^7.6.0&quot; }} 运行如下： 1234567$ npm run echo:test&gt; xxx@0.0.1 echo:test /Users/sea/workspace/personal/tem/np-pub-test&gt; echo name: $npm_package_name &amp;&amp; echo np version: $npm_package_devDependencies_npname: xxxnp version: ^7.6.0 最后，env命令可以列出所有环境变量。 12345{ &quot;scripts&quot;: { &quot;env&quot;: &quot;env&quot; }} 命名规则前缀有些开源项目我们可以看到，他的 script 脚本是带有前缀的， 这也是一个好的命名规则， 通过:dev， :prod 来区分环境， 如下： 123456{ &quot;scripts&quot;: { &quot;build:dev&quot;: &quot;...&quot;, // 开发环境 &quot;build:prod&quot;: &quot;...&quot; // 生产环境 }} 更多详情请查看官网 npm scripts 参考链接 scripts 你要知道的 Npm Script 都在这里 npm scripts 使用指南 npm scripts 官方文档（译）","link":"/articles/2022/01/27/npm-script/"},{"title":"阅读 only-allow","text":"一行代码统一规范包管理器: only-allow，强制在项目上使用特定的包管理器 场景在实际开发时，往往需要限定包管理器，来保证同样的开发。但是这种通常都是口头相传，并没有强制约束，因此就有了本文的only-allow only-allow 介绍 Force a specific package manager to be used on a project 强制在项目上使用特定的包管理器。 如：强制使用 yarn 12345{ &quot;scripts&quot;: { &quot;preinstall&quot;: &quot;npx only-allow yarn&quot; }} 注：npm 命令钩子 preinstall: 在npm install命令前执行 install,postinstall： 在npm install命令后执行 源码我们通过查看 package.json 文件。 123{ &quot;bin&quot;: &quot;bin.js&quot;} 确定入口文件：bin.js 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#!/usr/bin/env nodeconst whichPMRuns = require('which-pm-runs');const boxen = require('boxen');const argv = process.argv.slice(2);if (argv.length === 0) { console.log('Please specify the wanted package manager: only-allow &lt;npm|pnpm|yarn&gt;'); process.exit(1);}// 用户规定的包管理器，例如 npx only-allow yarn ，那么wantedPM 为 yarnconst wantedPM = argv[0];if (wantedPM !== 'npm' &amp;&amp; wantedPM !== 'pnpm' &amp;&amp; wantedPM !== 'yarn') { console.log(`&quot;${wantedPM}&quot; is not a valid package manager. Available package managers are: npm, pnpm, or yarn.`); process.exit(1);}// 用户当前安装时 使用的包管理器const usedPM = whichPMRuns();// 希望使用的包管理器 不相等，则报错。// - npm 提示使用 npm install// - pnpm 提示使用 pnpm install// - yarn 提示使用 yarn install// 最后退出进程if (usedPM &amp;&amp; usedPM.name !== wantedPM) { // boxenOPts: boxen 的配置 // boxen 能让terminal的输出展示盒装的样式,让终端提示更明显 const boxenOpts = { borderColor: 'red', borderStyle: 'double', padding: 1 }; switch (wantedPM) { case 'npm': console.log(boxen('Use &quot;npm install&quot; for installation in this project', boxenOpts)); break; case 'pnpm': console.log( boxen( `Use &quot;pnpm install&quot; for installation in this project.If you don't have pnpm, install it via &quot;npm i -g pnpm&quot;.For more details, go to https://pnpm.js.org/`, boxenOpts ) ); break; case 'yarn': console.log( boxen( `Use &quot;yarn&quot; for installation in this project.If you don't have Yarn, install it via &quot;npm i -g yarn&quot;.For more details, go to https://yarnpkg.com/`, boxenOpts ) ); break; } process.exit(1);} 其中使用到 boxen: 让 terminal的输出展示盒装的样式，让终端提示更明显 which-pm-runs: 当前运行的是哪一个包管理器 which-pm-runs 源码源码比较简单，这里一起讲下： 12345678910111213141516171819'use strict';module.exports = function () { if (!process.env.npm_config_user_agent) { return undefined; } return pmFromUserAgent(process.env.npm_config_user_agent);};// process.env.npm_config_user_agent: pnpm/6.22.2 npm/? node/v14.18.1 darwin x64// 获取到当前运行脚本的包管理器和版本号function pmFromUserAgent(userAgent) { const pmSpec = userAgent.split(' ')[0]; const separatorPos = pmSpec.lastIndexOf('/'); return { name: pmSpec.substr(0, separatorPos), version: pmSpec.substr(separatorPos + 1), };} 总结最后，在 only-allow 上可查看本篇源码文章~ 参考链接 only-allow scripts 从 vue3 和 vite 源码中，我学到了一行代码统一规范团队包管理器的神器","link":"/articles/2022/01/25/only-allow/"},{"title":"使用 renovate 监控第三方依赖更新","text":"背景当一个公共依赖包的使用者数量逐渐庞大的时候，如何保证当此包发布新版本时，所有使用者都能尽可能快地得到更新？或者如何保证自己仓库的使用的第三方库一直保持安全情况下的最新状态呢？ 传统的解决方案： 手工对所有项目逐个升级。这种办法相当繁琐，且容易产生遗漏，当项目数量足够庞大的时候，发布一次将会是相当痛苦的体验，而且对于 lerna + monorepo 而言，yarn 的 upgrade-interactive 对 monorepo 没有很好的支持； 在依赖安装时指定版本为 latest，这种办法虽然能保证每次安装时都能得到最新版本，但是却有诸多弊端，如： 无法保证依赖的安全性，有可能一次更新不慎造成大面积的瘫痪； 对「依赖锁」不友好，如 yarn.lock 等。 因此，如何使这个过程变得优雅，是一个亟待解决的问题。 经过调研发现有如下几种方式可以确保第三方包更新到最新版本。 Dependabot Renovate 本篇文章将会介绍如何使用 Renovate ，关于他俩的使用区别可以参考此文章《Try to update your dependencies with Renovate or Dependabot》 RenovateRenovate 是一个专注于解决依赖问题的库，自动化的依赖项更新，多平台和多语言。目前在 Github 上以 Github Apps 的形式，可以为接入此 Apps 的项目提供依赖更新监控相关的服务。 Renovate 使用体验安装 renovate在此网站 https://github.com/apps/renovate 点击安装即可。 Configure Renovate Pr安装 renovate 之后无须手动操作，等待即可。 此时 renovate 将会扫描你授予权限的仓库，做一些简要分析，分析你的各个项目主力语言、依赖管理方式，之后将会对哪些可以被通过 renovate 管控更新依赖的仓库，分别提交一份 Pull Request。 这个 Pull Request 的标题叫做 Configure Renovate，中间附带了一个文件更变，便是他会在项目的更目录下添加 renovate 的配置文件，名为 renovate.json 。 这个配置文件描述了一些 renovate 管理此仓库依赖的相关选项，默认生成的 config:base 已经能够满足日常需要。 如果开发者很不爽在项目根目录增添这样一个 json 配置文件，可以按照他们官方配置发现的目录查找顺序，移入到 .github 目录下。(具体查找规则，官方有较为详细的说明文档) Pin Pr (Pr: Pin Dependencies。)在 Configure Renovate Pr 被合并后，发起一个 Pin Pr，将项目中用到的依赖的版本锁定，对于 package.json 来说，即去除任何模糊的通配符，如 ^ / ~ 等，改用精确的版本号。在这个 PR 被合并前，不会有任何后续操作。 Update Dependencies日常的监控依赖更新。 Pin Pr 被合并后，开始周期性地检索依赖。当发现有更新时，为每个依赖（或依赖群）更新发起一个 Pr（示例），内容包含依赖定义文件（如 package.json） 与依赖锁文件（如 yarn.lock） 如果用户想要做本次升级，将其合并即可。将来如果该依赖再次有更新可用，会再次生成新的 PR； 如果用户不想做本次升级，不理会或将其关闭即可： 若不理会，在将来该依赖再次升级时，Renovate 会更新该 PR 至新版本； 若关闭，Renovate 将忽略该版本，不再发起 PR。 以上只是大致流程，实际上 Renovate 还有非常多的配置项可以发掘，可以提供高度定制化的使用体验。 参考链接 Renovate Renovate Doc 使用 renovate 监控第三方依赖更新 Integrate Renovate with GitLab Try to update your dependencies with Renovate or Dependabot","link":"/articles/2022/02/09/renovate/"},{"title":"Git 仓库瘦身","text":"随着时间的推移，Git 存储库变得越来越大，或者自己误操作，把 node_moduoles、.yarn、.DS_Sore 这种大文件上传到远程仓库中，虽然后期把他们移除了，但还是会使仓库体积变大，获取仓库变得更慢，每个人都必须下载文件，因此我们需要缩减 Git 仓库体积。 （虽然我们可以使用 git clone --depth=1 --single-branch https://gitlab.example.com/&lt;namespace&gt;/&lt;project_name&gt;.git ，快速拉取代码，但依然减少不了远程仓库体积） 前置条件 安装 git-filter-repo (重写仓库删除不需要的历史记录以缩小仓库，更多用法参考Examples) 1$ brew install git-filter-repo 分析现有仓库 top 100 大文件 1$ git rev-list --objects --all | grep &quot;$(git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -100 | awk '{print $1}')&quot; 示例如下，运行du -sh可以看到当前仓库大小为 82M。 .git文件夹为81M ​ 当前仓库 top 100 的大文件: 可以看出，大文件多数集中在.yarn文件夹内。 而这个文件夹对于我们来说，是不需要使用 git 管理的。 应该是早期不规范或者误操作给上传到了仓库里。 虽然这个文件夹现在已经被删除了，但是提交记录还在。 瘦身操作前期准备工作我们已经完成了，目的很明确，清楚历史中的.yarn文件，接下来开始瘦身工作。 Export project 生成一个新的项目导出并下载它。此项目导出包含你的存储库和 refs 的备份副本，我们用于从你的仓库中清除文件。 ​ 使用 tar 解压刚才的导出项目 1$ tar xzf project-backup.tar.gz 使用 --bare 和 --mirror 选项从包中克隆一个新的仓库副本： 1$ git clone --bare --mirror /path/to/project.bundle 导航到 project.git 目录 使用 git filter-repo ，分析您的仓库并查看结果，确定您要清除哪些项目：(可以忽略，前面已确定要删除的文件为.yarn) 1$ git filter-repo --analyze 使用 git filter-repo 清除仓库历史记录中的文件。因为我们试图删除内部 refs，所以我们依靠每次运行产生的 commit-map 来告诉我们要删除哪些内部 refs。 清除特定文件：.yarn(更多用法参考Examples) 1$ git filter-repo --path-glob '.yarn/*' --invert-paths --force 移除文件之后，可以发现本地仓库大小已缩减至 1M，瘦身很明显 git filter-repo 每次运行都会创建一个新的 commit-map 文件，并覆盖上一次运行中的 commit-map。每次运行都需要此文件。每次运行 git filter-repo 时都执行下一步。 变更远程仓库前面操作的都是本地文件，需要提交变更记录到远程。 因为从包文件克隆会将 origin 远端设置为本地包文件，删除这个 origin 远端，并将其设置为您的仓库的 URL： 12$ git remote remove origin$ git remote add origin https://gitlab.example.com/&lt;namespace&gt;/&lt;project_name&gt;.git 强制推送你的更改以覆盖 GitLab 上的所有分支： 1$ git push origin --force 'refs/heads/*' 受保护的分支 会导致失败。要继续，您必须移除分支保护、推送，然后重新启用受保护的分支。 要从标签版本中删除大文件，请强制将您的更改推送到 GitLab 上的所有标签： 1$ git push origin --force 'refs/tags/*' 受保护的标签 会导致失败。要继续，您必须移除标签保护、推送，然后重新启用受保护的标签。 为了防止不再存在的提交的死链接，推送由 git filter-repo 创建的 refs/replace。 1$ git push origin --force 'refs/replace/*' 📢 等待至少 30 分钟，因为仓库清理流程只处理超过 30 分钟的对象。 运行仓库清理 仓库清理上传 commit-map 文件，这个文件是git filter-repo执行过程中生成的，点击开始清理。 如果您的 commit-map 文件大于 250KB 或 3000 行，则可以将文件拆分并逐个上传： 1$ split -l 3000 filter-repo/commit-map filter-repo/commit-map- 最后等待远程仓库清理完成之后，我们再重新 clone 一份代码，可以很明显的发现克隆速度变快了许多，仓库体积减小了 瘦身前： 瘦身后： 注意 📢： 操作前通知所有人将手头代码提交到远程 开始操作后，禁止大家提交代码 操作完通知大家重新 clone 记得补充 .gitignore &amp; 还原设置。（受保护的分支、tags 继续保护起来） 参考链接 减少仓库大小 Reduce repository size Git 瘦身","link":"/articles/2022/11/16/reduce-git-repo/"},{"title":"软删除和唯一索引","text":"背景目前基本上在使用数据库时，都会使用到软删除（逻辑删除），但当软删除与唯一索引（unique-key）一起存在时可能会导致一些问题。 举个例子 🌰： 当表结构为： 123456789CREATE TABLE `users` ( `id` int NOT NULL AUTO_INCREMENT, `name` varchar(45) NOT NULL, `created_at` datetime NOT NULL, `updated_at` datetime NOT NULL, `deleted_at` datetime DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `name` (`name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci 其中 name 字段为 唯一索引，deleted_at 为软删除时间。 首先我们先插入一条数据： 1INSERT INTO `rocket_test`.`users` (`name`, `created_at`, `updated_at`) VALUES ('myName', '2022-01-10 16:30:10', '2022-01-10 16:30:10'); 然后我们再将这条数据以软删除的方式删掉： 1UPDATE `rocket_test`.`users` SET `deleted_at` = '2022-01-10 16:40:10' WHERE (`id` = '1'); 数据库此时状态： 当我们想再次插入 name 为 myName 的数据时就会发生唯一索引冲突： 1INSERT INTO `rocket_test`.`users` (`name`, `created_at`, `updated_at`) VALUES ('myName', '2022-01-10 16:30:10', '2022-01-10 16:30:10'); Error Code: 1062. Duplicate entry ‘myName’ for key ‘users.name’ 原因相信大家都很清楚，这是由于软删除时并未真正的删除表中的数据，哪怕此时我们在业务层做了唯一性校验依然会出现这种问题。因为唯一性校验的 SQL 默认会拼接上deleted_at索引字段，导致无法查出相应数据，最终引发了Duplicate entry 'myName' for key 'users.name' 唯一校验 SQL： 1SELECT * FROM rocket_test.users WHERE deleted_at IS NULL AND name=&quot;myName&quot;; 如何处理？ 去除唯一索引，业务层做完善校验（不推荐） 原因：业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。（阿里巴巴 Java 开发规范） 除非现有表结构中已经积累了大量数据，导致做全库 DDL（DDL 语句会锁整张表，不要轻易在线上做 DDL 操作）及数据迁移困难，否则不推荐采取该方案。 说明：不要以为唯一索引影响了 insert 速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。 建立联合索引，(将 name 和 删除标识 建立联合索引），软删除数据可以有以下几种方案来表示（推荐） 将删除标识的删除状态设为 id（推荐，使用主键确保不会发生索引冲突，并且实现简单） 若使用的是mybatis-plus框架可将logic-delete-value设置为如下： 1logic-delete-value: id 将删除标识设为当前时间戳（时间戳在极端情况下依旧有索引冲突的风险） 若使用的是mybatis-plus框架可将logic-delete-value设置为如下： 1logic-delete-value: REPLACE(unix_timestamp(current_timestamp(3)),'.','') 若采用该方案我们需对表结构进行一定的修改（bigint(20)），因为原来的软删除字段为tinyint(4)类型，长度不足以支撑该解决方案 Node 端在使用 sequelize 时可以在 hooks 中增加软删除逻辑： 123456789101112131415161718192021222324252627282930313233const Users = sequelize.define( 'users', { id: { type: DataTypes.INTEGER(11), allowNull: false, primaryKey: true, autoIncrement: true, }, name: { type: DataTypes.STRING(45), allowNull: false, unique: 'uniqueCompositeIndex', }, logicDeleteValue: { type: DataTypes.INTEGER, defaultValue: 0, unique: 'uniqueCompositeIndex', }, }, { hooks: { beforeBulkDestroy: (options) =&gt; { // 触发单个 hook 删除 options.individualHooks = true; }, beforeDestroy: async (instance) =&gt; { // 将删除标识的删除状态设为id（推荐，使用主键确保不会发生索引冲突，并且实现简单） await instance.update({ logicDeleteValue: instance.id }); }, }, }); 参考链接 逻辑删除和唯一索引 Sequelize","link":"/articles/2022/01/10/soft-deleted-and-unique-index/"},{"title":"Sequelize 入门使用指南","text":"Sequelize 是一个基于 promise 的 Node.js ORM, 目前支持 Postgres, MySQL, MariaDB, SQLite 以及 Microsoft SQL Server. 它具有强大的事务支持, 关联关系, 预读和延迟加载,读取复制等功能。 ORM（Object Relational Mapping），称为对象关系映射，用于实现面向对象编程语言里不同类型系统的数据之间的转换。 对象关系映射（Object Relational Mapping，简称 ORM，或 O/RM，或 O/R mapping），是一种程序设计技术，用于实现面向对象编程语言里不同类型系统的数据之间的转换。 Sequelize 是一个基于 Promise 的 NodeJs ORM 库，相当与一个中间人负责两者，js 和 mysql 之间的交流。 实例化 Sequelize 连接到 Database： 通过实例化 Sequelize 类，连接到数据库程序指定的数据库。 定义 Model 映射 Table： 通过模型映射数据表的定义并代理操作方法 指定 DataTypes 声明 Data Types： 把数据库的数据类型变成在 js 上下文中更合适的用法。 使用 Op 生成 Where 子句 Operators： 为选项对象提供强大的解耦和安全检测。 关联 Association 替代复杂的 Foreign Key 和 多表查询： 用一套简单的方法管理复杂的多表查询。 调用 Transcation 封装 Transation ： 对事务一层简单而必要的封装。 安装1npm install --save sequelize 必须手动为所选数据库安装驱动程序：（这里选择 mysql2 123456# 选择以下之一:$ npm install --save pg pg-hstore # Postgres$ npm install --save mysql2$ npm install --save mariadb$ npm install --save sqlite3$ npm install --save tedious # Microsoft SQL Server 连接到数据库Sequelize 是库的入口类，可做两件事情： 连接到数据库 设置数据表的全局配置。 所以暂且可把 Sequelize 的实例 看做 Mysql 中的 Database（数据库） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// config/database-config/database.dev.js// dev 环境下的数据库连接配置const databaseConfig = { // 使用哪个数据库程序 dialect: 'mysql', // mysql2 参数 dialectOptions: { // useUTC: false, // for reading from database // timezone: '+08:00', typeCast(field, next) { // for reading from database if (field.type === 'DATETIME') { return field.string(); } return next(); }, }, // 写入数据库时间为中国时间 timezone: '+08:00', database: 'rocket_test', username: 'root', password: '12345678', host: 'localhost', port: 3306, // 连接池 pool: { max: 5, min: 0, acquire: 30000, idle: 10000, }, // 数据表相关的全局配置 define: { // 是否冻结表名，停止 Sequelize 执行自动复数化. 这样,Sequelize 将推断表名称等于模型名称,而无需进行任何修改 // 默认情况下，表名会转换为复数形式 freezeTableName: true, // 默认情况下,Sequelize 使用数据类型 DataTypes.DATE 自动向每个模型添加 createdAt 和 updatedAt 字段. // createdAt 记录表的创建时间 // updatedAt 记录字段更新时间 // 时间戳 timestamps: true, // 是否为表添加 deletedAt 字段 // 默认情况下, destroy() 方法会删除数据， // 设置 paranoid 为 true 时，将会更新 deletedAt 字段，并不会真实删除数据。 paranoid: true, // 为 createdAt,updatedAt,deletedAt 列指定自定义名称,可以不用单独设定 // createdAt: 'created_at', // updatedAt: 'updated_at', // deletedAt: 'deleted_at' // 将所有属性的 field 参数设置为其名称的 snake_case 版本 underscored: true, },};export default databaseConfig; 导入配置文件，并实例化 Sequelize，并测试连接。 123456// src/models/utils.js// 实例化，并指定配置import { Sequelize } from 'sequelize';import config from '../../config/database-config/database.dev';export const sequelize = new Sequelize(config); 12345678910111213// src/models/test.js// 测试连接import { sequelize } from './utils';sequelize .authenticate() .then(() =&gt; { console.log('Connection has been established successfully.'); }) .catch((err) =&gt; { console.error('Unable to connect to the database:', err); }); 注： 个人习惯，models 目录用于存放 Sequelize 库相关文件，除个别 js 外，其余 js 文件对应当前 Database 中的一张 Table。 默认情况下,Sequelize 将保持连接打开状态,并对所有查询使用相同的连接. 如果你需要关闭连接,请调用 sequelize.close()(这是异步的并返回一个 Promise). 建立模型模型是 Sequelize 的本质. 模型是代表数据库中表的抽象. 在 Sequelize 中,它是一个 Model 的扩展类. 该模型告诉 Sequelize 有关它代表的实体的几件事,例如数据库中表的名称以及它具有的列(及其数据类型). 如下，新建一个文件 User.js 存放用户表的模型定义： 123456789101112131415161718192021222324252627282930// src/models/Users.jsimport { DataTypes } from 'sequelize';import { sequelize } from './utils';// define() 方法接受三个参数// 表名，表字段的定义和表的配置信息const Users = sequelize.define('users', { id: { // Sequelize 库由 DataTypes 对象为字段定义类型 type: DataTypes.INTEGER(11), // 允许为空 allowNull: false, // 主键，primary key=unique+not null primaryKey: true, // 自增 autoIncrement: true, }, name: { type: DataTypes.STRING(45), allowNull: false, // 唯一键 unique: true, }, secret: { type: DataTypes.STRING, allowNull: false, },});export default Users; 然后，导入并同步到 Mysql 中。 123456789101112131415161718192021// src/models/init.js// 导入import { sequelize } from './utils';import Users from './Users';// 同步到 Mysql 中// 也就是将我们用 js 对象声明的模型通过 sequelize 转换成 mysql 中真正的一张数据表(async function init() { // 标准同步 // 只有当数据库中不存在与模型同名的数据表时，才会同步 await sequelize.sync(); // 动态同步 // 修改同名数据表结构，以适用模型。 // await sequelize.sync({ alter: true }); // 强制同步 // 删除同名数据表后同步，谨慎使用，会导致数据丢失 // await sequelize.sync({ force: true }); // 另外，当你指定表与表之间的关联后，修改被关联的表结构时会抛出异常。 // 需要先注释掉关联代码，然后更新同步模型后，再取消掉注释即可。 // 再另外，当你有新的关联时必须使用动态同步才会生效。})(); 更多可查看模型基础 数据类型DataTypes 对象为模型的字段指定数据类型。 以下列出了部分 DataTypes 类型 对应的 Mysql 数据类型，更多可查看数据类型&amp;其他数据类型 1234567891011121314151617181920212223// 字符串STRING(N=255) // varchar(0~65535)CHAR(N=255) // char(0~255)TEXT(S=tiny/medium/long) // s + text// 数字// 整数TINYINT(N?) // tinyint(1-byte)SMALLINT(N?) // smallint(2-byte)MEDIUMINT(N?) // mediumint(3-byte)INTEGER(N=255?) // integer(6-byte)BIGINT(N?) // bigint(8-byte)// 浮点数FLOAT(n, n) // float(4-byte)DOUBLE(n, n) // double(8-byte)// 布尔值BOOLEAN // tinyint(1)// 日期DATE(n?) // datetime(8-byte)TIME // timestamp(4-byte)NOW // 默认值为 current timestamp// 其他ENUM( any，...) // ENUM('value1', ...) length &gt; 65535JSON // JSON 模型方法简单 SELECT 查询 你可以使用 findAll 方法从数据库中读取整个表： 1234// 查询所有用户const users = await User.findAll();console.log(users.every((user) =&gt; user instanceof User)); // trueconsole.log('All users:', JSON.stringify(users, null, 2)); 1SELECT * FROM ... 这里列出了模型上一些操作数据库常用的方法，更多查看模型查询(基础) &amp; 模型查询(查找器) &amp; Static Method Summary 1234567891011121314151617findOne()findAll()findById()findOrCreate()findOrBuild()findAndCountAll()create()bulkCreate()update()upsert()destroy()increment()decrement()count()max()min()sun() 验证器使用模型验证器，可以为模型的每个属性指定 格式/内容/继承 验证，验证会自动在 create, update 和 save 时运行，你还可以调用 validate() 来手动验证实例。当验证未通过时，会抛出一个 SequelizeValidationError 异常对象（这也是为什么，需要在数据库操作的地方用 try catch 语句捕获错误，防止 nodeJs 进程退出）。 例子： 12345678910const Users = sequelize.define('users', { // ... email: { type: DataTypes.STRING(255), allowNull: true, validate: { isEmail: true, }, },}); 另外，可指定 args 和 msg 自定义参数和错误消息。 1234isEmail: { args: true, // 可省略，默认为 true msg: &quot;邮箱格式不合法！&quot;} 你可以定义你的自定义验证器，也可以使用由 validator.js (10.11.0) 实现的多个内置验证器，更多查看官网，如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152sequelize.define('foo', { bar: { type: DataTypes.STRING, validate: { is: /^[a-z]+$/i, // 匹配这个 RegExp is: [&quot;^[a-z]+$&quot;,'i'], // 与上面相同,但是以字符串构造 RegExp not: /^[a-z]+$/i, // 不匹配 RegExp not: [&quot;^[a-z]+$&quot;,'i'], // 与上面相同,但是以字符串构造 RegExp isEmail: true, // 检查 email 格式 (foo@bar.com) isUrl: true, // 检查 url 格式 (http://foo.com) isIP: true, // 检查 IPv4 (129.89.23.1) 或 IPv6 格式 isIPv4: true, // 检查 IPv4 格式 (129.89.23.1) isIPv6: true, // 检查 IPv6 格式 isAlpha: true, // 只允许字母 isAlphanumeric: true, // 将仅允许使用字母数字,因此 '_abc' 将失败 isNumeric: true, // 只允许数字 isInt: true, // 检查有效的整数 isFloat: true, // 检查有效的浮点数 isDecimal: true, // 检查任何数字 isLowercase: true, // 检查小写 isUppercase: true, // 检查大写 notNull: true, // 不允许为空 isNull: true, // 只允许为空 notEmpty: true, // 不允许空字符串 equals: 'specific value', // 仅允许 'specific value' contains: 'foo', // 强制特定子字符串 notIn: [['foo', 'bar']], // 检查值不是这些之一 isIn: [['foo', 'bar']], // 检查值是其中之一 notContains: 'bar', // 不允许特定的子字符串 len: [2,10], // 仅允许长度在2到10之间的值 isUUID: 4, // 只允许 uuid isDate: true, // 只允许日期字符串 isAfter: &quot;2011-11-05&quot;, // 仅允许特定日期之后的日期字符串 isBefore: &quot;2011-11-05&quot;, // 仅允许特定日期之前的日期字符串 max: 23, // 仅允许值 &lt;= 23 min: 23, // 仅允许值 &gt;= 23 isCreditCard: true, // 检查有效的信用卡号 // 自定义验证器的示例: isEven(value) { if (parseInt(value) % 2 !== 0) { throw new Error('Only even values are allowed!'); } } isGreaterThanOtherField(value) { if (parseInt(value) &lt;= parseInt(this.otherField)) { throw new Error('Bar must be greater than otherField.'); } } } }}); Getters &amp; SettersGetters 和 Setters 可以让你在获取和设置模型数据时做一些处理。 1234567891011121314151617181920212223242526272829303132333435const Users = sequelize.define('users', { // ... // 假设我们想要以大写形式查看每个用户名, // 即使它们在数据库本身中不一定是大写的 username: { type: DataTypes.STRING, get() { const rawValue = this.getDataValue('username'); return rawValue ? rawValue.toUpperCase() : null; }, }, password: { type: DataTypes.STRING, set(value) { // 在数据库中以明文形式存储密码是很糟糕的. // 使用适当的哈希函数来加密哈希值更好. this.setDataValue('password', hash(value)); }, }, content: { type: DataTypes.TEXT, get() { // 取出真实内容 const storedValue = this.getDataValue('content'); const gzippedBuffer = Buffer.from(storedValue, 'base64'); const unzippedBuffer = gunzipSync(gzippedBuffer); return unzippedBuffer.toString(); }, set(value) { // 内容作为 gzip 压缩的 base64 字符串存储 const gzippedBuffer = gzipSync(value); this.setDataValue('content', gzippedBuffer.toString('base64')); }, },}); 注： deletedAt 字段目前不走 setter，很疑惑。。。（”sequelize”: “6.12.4” Op（查询条件）Op 对象集内置了一系列适用于 where 子句 查询的操作符（查询条件）。 举个例子： 12345678910const { Op } = require('sequelize');User.findAll({ // 查询所有 id &gt; 2 的用户 where: { id: { [Op.gt]: 2, }, },}); 以下列出了所有内置的 Op 操作符，更多解释查看官网 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253const { Op } = require(&quot;sequelize&quot;);Post.findAll({ where: { [Op.and]: [{ a: 5 }, { b: 6 }], // (a = 5) AND (b = 6) [Op.or]: [{ a: 5 }, { b: 6 }], // (a = 5) OR (b = 6) someAttribute: { // 基本 [Op.eq]: 3, // = 3 [Op.ne]: 20, // != 20 [Op.is]: null, // IS NULL [Op.not]: true, // IS NOT TRUE [Op.or]: [5, 6], // (someAttribute = 5) OR (someAttribute = 6) // 使用方言特定的列标识符 (以下示例中使用 PG): [Op.col]: 'user.organization_id', // = &quot;user&quot;.&quot;organization_id&quot; // 数字比较 [Op.gt]: 6, // &gt; 6 [Op.gte]: 6, // &gt;= 6 [Op.lt]: 10, // &lt; 10 [Op.lte]: 10, // &lt;= 10 [Op.between]: [6, 10], // BETWEEN 6 AND 10 [Op.notBetween]: [11, 15], // NOT BETWEEN 11 AND 15 // 其它操作符 [Op.all]: sequelize.literal('SELECT 1'), // &gt; ALL (SELECT 1) [Op.in]: [1, 2], // IN [1, 2] [Op.notIn]: [1, 2], // NOT IN [1, 2] [Op.like]: '%hat', // LIKE '%hat' [Op.notLike]: '%hat', // NOT LIKE '%hat' [Op.startsWith]: 'hat', // LIKE 'hat%' [Op.endsWith]: 'hat', // LIKE '%hat' [Op.substring]: 'hat', // LIKE '%hat%' [Op.iLike]: '%hat', // ILIKE '%hat' (不区分大小写) (仅 PG) [Op.notILike]: '%hat', // NOT ILIKE '%hat' (仅 PG) [Op.regexp]: '^[h|a|t]', // REGEXP/~ '^[h|a|t]' (仅 MySQL/PG) [Op.notRegexp]: '^[h|a|t]', // NOT REGEXP/!~ '^[h|a|t]' (仅 MySQL/PG) [Op.iRegexp]: '^[h|a|t]', // ~* '^[h|a|t]' (仅 PG) [Op.notIRegexp]: '^[h|a|t]', // !~* '^[h|a|t]' (仅 PG) [Op.any]: [2, 3], // ANY ARRAY[2, 3]::INTEGER (仅 PG) [Op.match]: Sequelize.fn('to_tsquery', 'fat &amp; rat') // 匹配文本搜索字符串 'fat' 和 'rat' (仅 PG) // 在 Postgres 中, Op.like/Op.iLike/Op.notLike 可以结合 Op.any 使用: [Op.like]: { [Op.any]: ['cat', 'hat'] } // LIKE ANY ARRAY['cat', 'hat'] // 还有更多的仅限 postgres 的范围运算符,请参见下文 } }}); 为什么不直接使用符号而是使用额外的封装层 Op，据官方说法是为了防止 SQL 注入和其他一些安全检测。另外，Op 对象集其实是一系列 Symbol 的集合。 关联关联定义比较难以理解，留在下一篇文章着重介绍。 参考链接 Sequelize 命名策略 Koa + Sequelize","link":"/articles/2022/01/11/sequelize-start/"},{"title":"阅读 remote-git-tags 源码","text":"前言时隔很久，重新开始阅读源码的过程，因此找个相对比较简单的包remote-git-tags进行阅读，并熟悉整套阅读流程（git subtree,vscode 中 nodejs 调试） 介绍remote-git-tags 是一个只有 22 行的相对比较简单的包，他的主要作用就是获取仓库中的所有 tags 源码Entry老规矩，先看入口文件，index.js，（从 package.json 中的exports字段中可以找到） 123// package.json...&quot;exports&quot;: &quot;./index.js&quot;, 源码比较简单，原理是通过运行 bash 命令：git ls-remote --tags repoUrl 获取 tags （可点击git ls-remote使用细节） 1234567891011121314➜ git ls-remote --tags https://github.com/sindresorhus/got67316ee37f0028d660f530970ab74a571247ff10 refs/tags/v0.1.01e7746d8c44a75ee9ec8ed94356dd5e8ba9c3bc2 refs/tags/v0.1.0^{}1ec67ee5906c8b8e8fb849b925479a31707a404d refs/tags/v0.1.198d1263b1331573dbc6c3110addb038dc5804bb8 refs/tags/v0.1.1^{}44c54b1b66f53d58c422c68c55c024827706a4b5 refs/tags/v0.2.032b0c033e26594a36b16ab7305e4ec5e54972cc1 refs/tags/v0.2.0^{}6baafc7a29aa7a6a00bc818b0d100eb11268b943 refs/tags/v0.3.0bc6987517edb1dfe54fc495f9b84a9df4b9f1f7c refs/tags/v0.3.0^{}4274ba19113edb51f64fe5ab278b5d823b83155c refs/tags/v1.0.09a593acd8412f5e412f0e7e6044a88a5ea93ca90 refs/tags/v1.0.0^{}c0b6804510ac9105591ee338ff5ad0b0e395ac71 refs/tags/v1.0.137322366c7e85c898fbc9bf92bd32afa9a228aae refs/tags/v1.0.1^{}4e736f374d7af685646b1184c06933c71c07ff99 refs/tags/v1.1.0 让我们来直接看代码： 12345678910111213141516171819202122232425import { promisify } from 'node:util';import childProcess from 'node:child_process';const execFile = promisify(childProcess.execFile);export default async function remoteGitTags(repoUrl) { // 把所有 tags 和对应的 hash值 存在 Map 对象中。 const { stdout } = await execFile('git', ['ls-remote', '--tags', repoUrl]); const tags = new Map(); for (const line of stdout.trim().split('\\n')) { const [hash, tagReference] = line.split('\\t'); // Strip off the indicator of dereferenced tags so we can override the // previous entry which points at the tag hash and not the commit hash // `refs/tags/v9.6.0^{}` → `v9.6.0` const tagName = tagReference .replace(/^refs\\/tags\\//, '') .replace(/\\^{}$/, ''); tags.set(tagName, hash); } return tags;} 调试如图，我们可以看到相关代码对应的 debug 信息 Dependenciesnode:util可以使用 node: 前缀来识别核心模块，在这种情况下它会绕过 require 缓存。例如，require('node:http') 将始终返回内置的 HTTP 模块，即使有该名称的 require.cache 条目。细节可查看官网 promisify将常见的错误优先的回调风格的函数（也就是将 (err, value) =&gt; ... 回调作为最后一个参数），并返回一个返回 promise 的版本。 1234567891011const util = require('node:util');const fs = require('node:fs');const stat = util.promisify(fs.stat);stat('.') .then((stats) =&gt; { // Do something with `stats` }) .catch((error) =&gt; { // Handle the error. }); 帮助理解，伪代码实现如下，真实源码可自行参考node 官网 123456789101112function promisify(fn) { return function (...args) { return new Promise((resolve, reject) =&gt; { fn(...args, (error, value) =&gt; { if (error) { return reject(error); } resolve(value); }); }); };} node:child_processexecFile child_process.exec(): 衍生 shell 并在该 shell 中运行命令，完成后将 stdout 和 stderr 传给回调函数。 child_process.execFile(): 与 child_process.exec() 类似，不同之处在于，默认情况下，它直接衍生命令，而不先衍生 shell。 child_process.fork(): 衍生新的 Node.js 进程并使用建立的 IPC 通信通道（其允许在父子进程之间发送消息）调用指定的模块。 child_process.execSync(): child_process.exec() 的同步版本，其将阻塞 Node.js 事件循环。 child_process.execFileSync(): child_process.execFile() 的同步版本，其将阻塞 Node.js 事件循环。 总结多看源码，多思考 🤔~ 参考链接 从 22 行有趣的源码库中，我学到了 callback promisify 化的 Node.js 源码实现 - 掘金 util 实用工具 | Node.js v18 文档","link":"/articles/2023/11/18/remote-git-tags/"},{"title":"状态机","text":"什么是状态机 定义状态机是有限状态自动机（Finite State Machine，FSM）的简称，是现实事物运行规则抽象而成的一个数学模型。表示有限个状态以及在这些状态之间的转移和动作；说白了，就是指一张状态变换图。 如下图，就定义了一个只有 opened 和 closed 两种状态的状态机。当系统处于 opened 状态，在收到输入「关闭事件」，达到了状态机转移条件，系统则会执行相应的动作（close door），并转移到了 closed 状态。 疑惑既然状态机是有限状态机的简称，那有没有无限状态机呢？ 这个问题其实和永动机的答案是一样的，属于只有理论意义但不存在的模型； 状态机的实质就是确定的输入和状态可以得到确定的输出，按照定义需要首先收集所有状态，而无限状态机在这个步骤就已经不满足了； 关于无限状态机的更多 可以了解：图灵机、下推自动机等。。。 为什么要使用状态机？根据上面状态机的基本概念的介绍，想必大家对状态机应该有个大致了解，我们可以继续思考下，为什么我们需要使用状态机？ 世间的一切，都可以看成是各种状态的集合。比如一块石头，今天可能是干的，明天可能是湿的。再比如一个人，年龄会逐渐增长，可以从结婚变成未结婚，可以从男人变成女人，等等等…… 而状态改变的时候，我们可能要做某种事情来应对这种改变，比如结婚了想喊一嗓子，让所有人都恭喜我…… 而且状态机在游戏开发中大放异彩，已经成为了一种常用的设计模式，比如大家小时候都会玩马里奥 在游戏中，马里奥可以变身为多种形态，比如小马里奥（Small Mario）、超级马里奥（Super Mario）、火焰马里奥（Fire Mario）、斗篷马里奥（Cape Mario）等等。在不同的游戏情节下，各个形态会互相转化，并相应的增减积分。比如，初始形态是小马里奥，吃了蘑菇之后就会变成超级马里奥，并且增加 100 积分。 马里奥形态的转变就是一个状态机。其中，马里奥的不同形态就是状态机中的「状态」，游戏情节（比如吃了蘑菇）就是状态机中的「事件」，加减积分就是状态机中的「动作」。比如，吃蘑菇这个事件，会触发状态的转移：从小马里奥转移到超级马里奥，以及触发动作的执行（增加 100 积分） 与前端的联系至于在前端开发中，用到状态机的场合更是比比皆是。比如一个前端组件的状态，可能从「隐藏」到「显示」，从「左边」到「右边」，背景从「白」到「黑」，里面的图片从「10」张到「20 张」等等…… 当组件从隐藏到显示的时候，你可能需要调用另一个组件来填充它的位置，这时候就需要在「隐藏、显示」这个状态改变的时候做相应的操作。而促使这个组件改变可能有很多种情况（比如点击，或者过五秒隐藏），这时如果用状态机的话，只需要给它绑定一个状态改变事件而已…… 使用状态机，能让你的代码变得更直观、更整洁，减少了耦合,提升了代码的健壮性…… 当然，状态机能带来的好处远远不止这么多。 如何使用状态机首先我们需要了解下状态机的本质：确定的输入 + 某一个状态 =&gt; 另一个状态； （状态机的工作原理所示，发生事件 (event) 后，根据当前状态 (cur_state) ，决定执行的动作 (action)，并设置下一个状态号 (nxt_state)） 状态机有四大概念还有三大特征 四大概念下面来给出状态机的四大概念。现态（Current State）、次态（Next State）、事件（Event）、动作（Action） 现态（Current State）：状态机当前所处的状态，也称为当前状态。它表示状态机当前的状态，也是状态转移的起始状态。 次态（Next State）：状态机转移后的状态，也称为下一个状态。它表示状态机经过某个事件或条件转移后，即将要进入的状态。 事件（Event）：事件就是执行某个操作的触发条件或者口令。当一个条件被满足，可能将会触发一个动作，或者执行一次状态的迁移。 动作（Action）事件发生以后要执行动作。动作不是必需的，当条件满足后，也可以不执行任何动作，直接迁移到新状态。 三大特征状态机并不是一个复杂的概念，简单说，它有三个特征： 状态总数（state）是有限的。 任一时刻，只处在一种状态之中。 某种条件下，会从一种状态转变（transition）到另一种状态。 表示法通常我们会用 状态转换图 或者 状态转移表 来表示状态机 状态转换图 状态转移表 Demo了解了状态机的基本概念后，接下来看一个简单的前端例子， 比方说网页上存在一个按钮元素。当鼠标点击按钮时会出现弹窗，同样当鼠标再次点击按钮时候弹窗消失。 简单分析下，可以发现 Button 组件有两种状态，一个为 On 一个为 Off，它要么处于 on 状态，要么处于 off 状态，初始状态为 off，它有 2 例行为：turnOff 和 turnOn，前者能使组件从 on 状态变化到 off 状态，后者能使组件从 off 状态变为 on 状态，它的行为绑定到了某个 DOM 元素的点击事件上，可以先看下伪代码实现 1234567891011121314151617181920212223242526// 伪代码const buttonMachine = { // 状态机当前状态 currentState: 'off', // 每次输入会调用 transition 方法根据输入判断更改当前状态 transition: function (event) { // do something 根据用户行为(event)更改currentState switch (this.currentState) { case 'on': // do something 更改为 关闭 状态， 取消高亮同时隐藏菜单 this.currentState = 'off'; doSomething(); break; case 'off': // do something 更改状态为 打开 状态 高亮按钮、显示菜单 this.currentState = 'on'; doSomething(); break; default: console.log('Invalid State'); break; } },}; 接下来可以看到真实代码 实现方式 See the Pen JS - machine -1 by MrSeaWave (@mrseawave) on CodePen. 可以看到当调用 machine.init() 之后打印的是这个组件的初始状态，当点击一次之后，组件从 off 状态转换到了 on 状态，点击第二次之后从 on 状态转换到了 off 状态，点击第三次又恢复到了 on 状态。这个例子虽然是一个极其简单的状态机实现，但还是能够比较恰当地说明状态机的思想以及它的优点（逻辑思维清晰， 表达能力强）。在实际工作中，我们可以借助 javascript-state-machine 来实现基于状态机的组件，它是有限状态机这种模型的一个 js 的实现库，利用它可以快速定义一个状态机对象，相比我前面举例写出的那种实现，这个库虽然源码只有 200 多行，但是功能非常完整，API 简单好用，值得学习跟实践。 使用 javascript-state-machine 库实现状态机只要引入该库的 js 之后就能通过该库提供的一个全局对象 StateMachine，并使用 new StateMachine()，则可以生成有限状态机的实例. Demo1 1234567891011121314151617181920212223var fsm = new StateMachine({ init: 'solid', transitions: [ { name: 'melt', from: 'solid', to: 'liquid' }, { name: 'freeze', from: 'liquid', to: 'solid' }, { name: 'vaporize', from: 'liquid', to: 'gas' }, { name: 'condense', from: 'gas', to: 'liquid' }, ], methods: { onMelt: function () { console.log('I melted'); }, onFreeze: function () { console.log('I froze'); }, onVaporize: function () { console.log('I vaporized'); }, onCondense: function () { console.log('I condensed'); }, },}); 在这个例子中：inil 选项用来表示 fsm 对象的初始状态，transitions 选项用来描述 fsm 对象所有状态的变化规则，每一种变化规则对应一种行为（不过有可能多个规则会对应同一个行为，在后面你会看到这样的例子）。我们在使用 new StateMachine 时则会为实例的每一种行为都添加了一个方法，调用这个方法就相当于触发对象的某种行为，当对象行为发生时，对象的状态就可以发生变化。如以上例子创建的实例将拥有如下行为方法： 1234fsm.melt() - 调用该方法，实例状态将从'solid'变为'liquid'fsm.freeze() - 调用该方法，实例状态将从'liquid'变为'solid'fsm.vaporize() - 调用该方法，实例状态将从'liquid'变为'gas'fsm.condense() - 调用该方法，实例状态将从'gas'变为'liquid' 这些方法是 StateMachine 根据配置的 transitions 规则自动创建的，方法名跟 transitions 规则里面的 name 属性对应，transitions 规则里面有几个不重复的 name，就会添加几个行为方法。同时为了方便使用，它还添加了如下成员来判断和控制实例的状态和行为： 123456fsm.state - 返回实例当前的状态fsm.is(state) - 如果传入的state是实例当前状态就返回truefsm.can(transitionName) - 如果传入的transitionName在实例当前状态能够被触发就返回truefsm.cannot(transitionName) - 如果传入的transitionName在实例当前状态不能被触发就返回truefsm.transitions() - 以数组的形式返回实例当前状态下能够被触发的行为列表... 还记得前面列出的可以用有限状态机模型的事物特点吧，接下来就用 Demo1 来说明 javascript-state-machine 创建的对象是如何满足状态机模型的要求的： 1）事物拥有的状态总数是有限的 这个实例最多只有三个状态。 2）可以用状态来描述事物，并且任一时刻，事物总是处于一种状态 这个例子中创建的固液气的实例转换规则中，要么处于 solid 状态，要么处于 liquid 状态，要么处于 gas 状态，所以它是满足第 2 点的。 3）在某种条件下，可以导致事物从一种状态过渡到另一种状态 fsm.melt，fsm.freeze，fsm.vaporize，fsm.condense 这几个行为方法都能改变实例的状态。 4）另外其实事物状态变化是有规则的，A 状态可以变换到 B，B 可以变换到 C，A 却不一定能变换到 C 这个实例的初始状态为 solid，根据 transitions 配置的状态变化规则，solid 可以变换到 liquid, liquid 可以变换到 gas，但是实例初始化之后，却不能调用 fsm.freeze 这个行为方法，因为这个方法只有实例状态为 liquid 的时候才能调用，而初始化时实例的状态为 solid，所以一开始只能调用 melt 方法：（注意，这里只是具体例子，实际上 solid 可以直接变成 gas，这种现象叫做升华，只是在例子中没定义 5）同一种行为，可以将事物从多种状态变成同种状态，但是不能从同种状态变成多种状态 从理论上也很好理解这一点，为什么不能从同种状态变成多种状态，因为第二点说了事物任一时刻只能处于一种状态，如果某一个行为使得事物的状态变成了多种，事物的状态机制就有问题了。 下来来看个例子,来说明同一个行为，可以从多种状态变换到一种状态的场景： 123456789let fsm = new StateMachine({ init: 'A', transitions: [ { name: 'step', from: 'A', to: 'B' }, { name: 'step', from: 'B', to: 'C' }, { name: 'step', from: 'C', to: 'D' }, { name: 'reset', from: ['B', 'C', 'D'], to: 'A' }, ],}); 可以发现 1）虽然它配置了多个变化规则，但是它只有 2 个行为，我们可以从 A 状态调用 step 依次到 D 状态，中间可以随时使用 reset 方法返回 A 状态 2）它的 step 行为发生后的状态跟当前状态有关系，当前状态不同，行为发生后的状态也不同，所以 step 行为对应了多条配置规则； 3）它的 reset 行为发生后的状态跟当前状态没关系，只要当前状态在 reset 行为的状态条件范围内，行为发生后的结果都是一样的，所以 reset 行为用一个 from 数组配置了该行为发生的当前状态的条件范围，整个行为仅定义了一条配置规则。 在实际使用状态机实例的过程中，我们通过调用实例的行为方法来触发实例状态的改变，比如 Demo1 中： fsm.melt()，这样 fsm 的状态就会由 solid 变为 liquid，像这种简单的状态机实例，这个程度的使用也许就足够了，但是对于实际项目而言，我们定义的组件，往往要用它们生成的实例来完成很多复杂的逻辑功能，如果用状态机来定义组件，那么这些逻辑代码该写在哪里？因为 javascript-state-machine 创建的状态机实例，它的行为方法都是自动添加的，你不可能去重写这些行为方法，否则就失去状态机的意义了（将状态变化的逻辑与业务逻辑拆分）。答案是回调，可以发现 Demo1 中的 methods。javascript-state-machine 为每个实例的每种状态的变换前后和每种行为的变换前后都定义了相关的回调，我们的逻辑都可以写在这些回调里面，这样就达到了状态逻辑与业务逻辑拆分的目的。下面先看看这些回调的用法，接着我会用 javascript-state-machine 改写一下前面那个 Button 组件的例子。 javascript-state-machine 根据 transition 的配置，可以为实例定义 4 种类型的回调： 1234onBefore&lt;TRANSITION&gt; - 在TRANSITION对应的行为发生之前触发onLeave&lt;STATE&gt; - 在要改变STATE对应的状态时触发onEnter&lt;STATE&gt; - 在把当前状态设置为了STATE对应的状态时触发，简写为on&lt;STATE&gt;onAfter&lt;TRANSITION&gt; - 在TRANSITION对应的行为发生之后触发，简写为on&lt;TRANSITION&gt; 其中每个回调都接受一个参数 lifecycle，其中包含 123transition - 行为名称from - 行为发生前的状态to - 行为发生后的状态 状态机每个行为触发，或者状态改变都一定会触发上面的回调（只要这些回调都有定义的话），并且回调顺序跟前面列出的顺序一致。 如 Demo3 123456789101112131415161718let fsm = new StateMachine({ init: 'A', transitions: [{ name: 'step', from: 'A', to: 'B' }], methods: { onBeforeStep: function () { console.log('onBeforeStep'); }, onLeaveA: function () { console.log('onLeaveA'); }, onB: function () { console.log('onEnterB'); }, onStep: function () { console.log('onStep'); }, },}); 另外 javascript-state-machine 还定义了五个通用回调，这五个回调跟 transition,state 没有关系，在任何行为触发，任何状态变化的时候，相关的回调都会触发，这五个回调是： 12345onBeforeTransition - 在任何行为发生之前触发onLeaveState - 在要改变对象状态时触发onTransition - 在行为发生中触发onEnterState - 在把当前状态设置为新状态时触发onAfterTransition - 在任何行为发生之后触发 这五个回调名称是固定的，跟触发的行为和要改变的状态没有关系，相当于是全局回调，也就是说，如果某个状态变化规则相关的四个类型的回调有定义并且这五个全局回调也有定义的话，那么触发该规则对应的行为，就一共会触发 9 个回调，顺序如下： 1234567891011121314151617181920212223//注意，STATE是当前状态机所处的状态，TRANSITION是即将发生的动作onBeforeTransition 任何动作触发前触发onBefore&lt;TRANSITION&gt; 在特定动作TRANSITION前触发onLeaveState 离开任何一个状态的时候触发onLeave&lt;STATE&gt; 在离开特定状态STATE时触发onTransition 在任何动作发生期间触发onEnterState 当进入任何状态时触发onEnter&lt;STATE&gt; 进入一个特定的状态STATE时触发on&lt;STATE&gt; onEnter&lt;STATE&gt;的简写onAfterTransition 任何动作触发后触发onAfter&lt;TRANSITION&gt; 在特定动作TRANSITION后触发on&lt;TRANSITION&gt; onAfter&lt;TRANSITION&gt;的简写 了解到前面这些内容后，我们就可以用 javascript-state-machine 来改写前面的 Button 组件了： 12345678910111213141516171819202122232425262728293031323334353637383940let ButtonMachine = function (btnEle, ulEle) { fsm = new StateMachine({ init: 'off', transitions: [ { name: 'turnOn', from: 'off', to: 'on' }, { name: 'turnOff', from: 'on', to: 'off' }, ], methods: { onTurnOn: function (lifecycle) { const { transition, from, to } = lifecycle; btnEle.classList.add('on'); ulEle.classList.add('ul-visible'); log(to, from); }, onTurnOff: function (lifecycle) { const { transition, from, to } = lifecycle; btnEle.classList.remove('on'); ulEle.classList.remove('ul-visible'); log(to, from); }, }, }); btnEle.addEventListener('click', (event) =&gt; { console.log('fsm', fsm, fsm.transitions()); fsm[fsm.transitions()[0]](); }); log(fsm.state); return fsm;};function log(currentState, previousState) { if (!previousState) { console.log(`[INIT] currentState is : ${currentState}`); } else { console.log(`[TRANSFORM] currentState is : ${currentState}, and previous state is : ${previousState}`); }} 效果如下： 在实际工作中，肯定会碰到在行为触发期间，因为某些条件不允许需要取消该行为的情况， 以免对象状态被错误的更改，在 javascript-state-machine 的回调中，只需要 return false 即可取消当前触发， 有时，我们在实际工作中，也需要在状态转换期间执行一些异步代码，并确保在代码完成之前不会进入新状态，这时我们可以在回调中返回 Promise，以此来取消或者继续回调。 12345678910111213141516171819202122232425262728293031323334var fsm = new StateMachine({ init: 'menu', transitions: [ { name: 'play', from: 'menu', to: 'game' }, { name: 'quit', from: 'game', to: 'menu' }, ], methods: { onEnterMenu: function () { return new Promise(function (resolve, reject) { $('#menu').fadeIn('fast', resolve); }); }, onEnterGame: function () { return new Promise(function (resolve, reject) { $('#game').fadeIn('fast', resolve); }); }, onLeaveMenu: function () { return new Promise(function (resolve, reject) { $('#menu').fadeOut('fast', resolve); }); }, onLeaveGame: function () { return new Promise(function (resolve, reject) { $('#game').fadeOut('fast', resolve); }); }, },}); 这个例子中创建的实例，包含 play 和 quit 两个行为，这两个行为触发之后，不会立即去更改对象的状态，而是开启一个异步的动画任务，然后在动画结束之后，通过调用 resolve，通知实例去改变自己的状态。如果想取消则使用 reject 小结1）有限状态机是定义组件的一种好用的模式，能够让组件的代码看起来更加清晰，而且易于理解 2）javascript-state-machine 也是一个优秀的实现库，源码简洁，提供的 API 用法简单，同时还突出了状态机的特点，值得在定义组件的时候去试一试，大家有兴趣可以看看源码实现 3）有限状态机这种模式适合有明显状态特点的组件 因此我们可以写代码之前，思考一下： 页面有几种状态（初始化状态？成功状态？失败状态？出错状态？）。 描述这些状态需要什么参数。 在什么时候转变状态，需要改变哪些部分。 然后跟着思路，完成数据与 UI 部分。 卖个关子，本篇只是打个小样，介绍一种思考模式，如果遇到大量判断条件的场景，记得想想状态机，在未来，将会介绍如何将状态机与 react 结合使用，具体可参考 XState 前端:从状态管理到有限状态机的思考 - 掘金 https://soshace.com/an-introduction-to-finite-state-machines-simplifying-react-state-management-with-state-machines/ https://www.telerik.com/blogs/how-to-use-finite-state-machines-react https://tsh.io/blog/finite-state-machines-in-react/ https://xstate.js.org/docs/recipes/react.html#local-state 本篇所涉及到的代码可去 js-state-machine-demo 进行查看 参考链接 有限状态机 - 维基百科，自由的百科全书 什么是状态机？一篇文章就够了-面包板社区 状态转移表 - 维基百科，自由的百科全书 ccqgithub/StateMachine: Javascript 有限状态机 XState：都 1202 年了，不会真有人还在用假的状态管理库吧？ - 知乎 JavaScript 状态模式及状态机模型 - 掘金 超级马力欧兄弟 3 - 维基百科，自由的百科全书 状态机_百度百科 有限状态机 FSM(Finite State Machine)及实现方式介绍 - BarryW - 博客园 试试用有限状态机的思路来定义 javascript 组件 - 流云诸葛 - 博客园 前端开发中的状态机 - 作业部落 Cmd Markdown 编辑阅读器 如何把业务逻辑这个故事讲好@张克军ReactConf CN 2018开发 如何把业务逻辑这个故事讲好 - 有限状态机与 React 开发@ReactConf2018哔哩哔哩_bilibili Selecting a finite state machine library for React | Rainforest QA jakesgordon/javascript-state-machine: A javascript finite state machine library","link":"/articles/2023/03/23/state-machine-1/"},{"title":"第 01 菜谱：周刊一锅端","text":"Hi，我是 Sea，欢迎打开新一期的「每周菜谱」，这是第「01」期，发表于 2023-01-16，今天我们不讲菜谱，先来介绍下有哪些优秀的前端周刊 前端周刊 周刊 - 阮一峰的网络日志: 科技爱好者周刊. 记录每周值得分享的科技内容 云谦和他的朋友们：Umi、Dva 等库作者 前端食堂：你的前端食堂，吃好每一顿饭 早早鸟日刊：前端早早聊日刊 潮流最前端·周刊：阿里团队的前端周刊 前端早读课: 每天凌晨 5 点的早读时间 字节前端 ByteFE: 字节前端技术周报 小结如果你喜欢每周菜谱，请转发给你的朋友，告诉他们来这里进行订阅~ 订阅地址：https://mrseawave.github.io/blogs/ 每周菜谱，让你做饭更开心~","link":"/articles/2023/01/16/weekly-01/"},{"title":"第 00 菜谱：自我介绍","text":"Hi，我是 Sea，欢迎打开新一期的「每周菜谱」，这是第「00」期，发表于 2023-01-16，今天我们不讲菜谱，先来介绍下「每周菜谱」 About「每周菜谱」是用来分享每周下来我所看到有趣，有意思的技术文章，以及一些有用的资源 为什么要写？长久以来，我都是把相关的资源收藏进我的收藏夹中，收藏等于已看（狗头），这也就导致了我在不知不觉间收集了差不多有 3.3K 以上的网址，资源很分散，也没有进行归档，最近想到，把它写成文章，共享出来，也许效果更好。 用两个词语来形容，差不多就是沉淀与分享 小结如果你喜欢「每周菜谱」，请转发给你的朋友，告诉他们来这里进行订阅~ 订阅地址：https://mrseawave.github.io/blogs/ 每周菜谱，让你做饭更开心~","link":"/articles/2023/01/16/weekly-00/"},{"title":"第 02 菜谱：菜谱开动了！","text":"Hi，我是 Sea，欢迎打开新一期的「每周菜谱」，这是第「02」期，发表于 2023-01-16，今天开始每周菜谱的第一期内容，我们先来看看每周有什么值得推荐的 每周推荐2022 年前端大事记https://mp.weixin.qq.com/s/HfgifbdzBSOZkDb0ru0XsA Web、网络等前端需要关注的领域中发生的一些大事 JavaScript 将新增两个原始数据类型https://github.com/tc39/proposal-record-tuple JavaScript 即将推出两个新的数据类型：Record 和 Tuple ，该提案目前已经到达 Stage: 2。 Record 和 Tuple 在用法上和对象、数据保持一致只不过他们是只读的： 123456789101112// Record, 一个非常不可变的类对象结构const myRecord = #{ name: 'ConardLi', age: 23,};myRecord.name = 'xxx'; // TypeError &quot;Cannot assign to read only property 'name' of object '[object Object]'&quot;// Tuple, 一个非常不可变的类数组结构const myTuple = #['1', '2', '3'];myTuple[0] = '4'; // TypeError &quot;Cannot assign to read only property '0' of object '[object Tuple]'&quot; 另外还有一个很重要的点，当我们去比较 Record 和 Tuple 的值时，只会对比它们的值，而不再对比引用。 123console.log(#{ a: 1, b: 2 } === #{ b: 2, a: 1 });// true Change Array by copy 提案进入 stage3https://github.com/tc39/proposal-change-array-by-copy 该提案为数组新增了四个非破坏性（不改变原数组）方法： toSorted()：.sort() 的非破坏性版本； toReversed()：.reverse() 的非破坏性版本； with()：对数组的某个元素赋值操作的非破坏性版本； toSpliced()：.splice() 的非破坏性版本。 Chrome 支持 Priority Hints，可控制网页资源加载优先级https://mp.weixin.qq.com/s/CJQ1NB1V8vi1Y8mmw2InYw Chrome 101 正式发布了 Priority Hints，用于指定页面资源的加载优先级，即 fetchpriority 属性，帮助浏览器根据优先级优化加载顺序，从而优化页面加载体验。 当浏览器开始解析网页，并开始下载图片、Script 以及 CSS 等资源的时候，浏览器会为每个资源分配一个代表资源下载优先级的 fetch priority 标志，而默认的资源下载顺序就取决于这个优先级标志。 低代码多分支协同开发的建设与实践https://mp.weixin.qq.com/s/DmwxL67htHfTUP1U966N-Q 随着低代码的普及，在低代码平台上构建企业级应用逐渐成为生产趋势。同时，随着低代码技术的提升，越来越多的复杂应用在低代码平台中完成。在其研发生命周期中，低代码开发者就会面临多人协作、并行开发、维护多版本的场景。而现有的低代码平台普遍缺乏这一能力或支持较弱，导致对协同开发的成本较高，限制了迭代的效率。 对于“前端状态”相关问题，如何思考比较全面https://mp.weixin.qq.com/s/y7JzwBcbOobjWQdYEQ7KqA 不管是 ClassComponent 还是 FunctionComponent、Options API 还是 Composition API，他们的本质都是 「状态与 UI 的松散耦合单元」。 当组件数量增多，逻辑变复杂时，一种常见的解耦方式是 —— 将可复用的逻辑从组件中抽离出来，放到单独的 Model 层。UI 直接调用 Model 层的方法。 对 Model 层的管理，也就是所谓的 「状态管理」。 Pull Requests 的艺术https://blog.openacid.com/culture/pr/ https://hackernoon.com/the-art-of-pull-requests-6f0f099850f9 提 PR 的一些艺术，保持 PR 够小，提过 PR 后及时通知，不要太严肃，不要太害怕。 我的信息流 2023.1https://mp.weixin.qq.com/s/AJ4IBgYJ-Mq9OSICG0hRCA 极力推荐，云谦大佬介绍的自己获取信息的方法 技术实践虚拟列表，我真的会了https://juejin.cn/post/7085941958228574215 提供了如何实现虚拟列表的思路 二十张图片彻底讲明白 Webpack 设计理念https://juejin.cn/post/7170852747749621791 从思想和架构两方面深度剖析了 Webpack 的设计理念。最后在代码实现阶段，通过百来行代码手写了 Webpack 的整体流程，尽管它只能对文件进行打包，还缺少很多功能，但麻雀虽小，却也五脏俱全。 一文弄懂 React refhttps://juejin.cn/post/7175174485534834749 通过本篇文章的学习，你将收获 React ref 的基本和进阶用法，并且能够明白 React 内部是如何处理 ref 的，并通过一个小 Demo + 提问的方式带你更加深刻地理解 ref 的底层原理 miniReact_v17https://github.com/changcheng1/miniReact_v17 精简版 React 实现，包含逐行注释 资源分享Awesome Machttps://github.com/jaywcjlove/awesome-mac 收集各种类别非常好用的 Mac 应用程序、软件以及工具。 Carbonhttps://carbon.now.sh/ 代码图片生成 tinypnghttps://tinypng.com/ 图片压缩 CodeTourhttps://marketplace.visualstudio.com/items?itemName=vsls-contrib.codetour VSCode 插件，CodeTour 可以在多人协同开发时，给项目添加 新手指引 方便快速熟悉上手新项目，也可以用于 code review，现在更可以用来记录源码，该工具由 Microsoft 开源团队 提供，github 仓库地址 microsoft/codetour DownloadFullInstallerhttps://github.com/scriptingosx/DownloadFullInstaller macOS application written in SwiftUI that downloads installer pkgs for the Install macOS Big Sur application. 小结如果你喜欢每周菜谱，请转发给你的朋友，告诉他们来这里进行订阅~ 订阅地址：https://mrseawave.github.io/blogs/ 每周菜谱，让你做饭更开心~","link":"/articles/2023/01/16/weekly-02/"},{"title":"第 03 菜谱：Web Development Trends in 2023","text":"Hi，我是 Sea，欢迎打开新一期的「每周菜谱」，这是第「03」期，发表于 2023-01-30，我们先来看看每周有什么值得推荐的 每周推荐10 Web Development Trends in 2023https://www.robinwieruch.de/web-development-trends/ ROBIN WIERUCH 分析了 2023 年 Web 开发的 10 个趋势，推荐一读。10 个领域包括元框架、应用和渲染模式、Edge ServerLess、数据库复兴、JavaScript Runtime、MonoRepo、Utility-First CSS、类型安全、构建工具、AI 驱动开发。 20 Things I’ve Learned in my 20 Years as a Software Engineerhttps://www.simplethread.com/20-things-ive-learned-in-my-20-years-as-a-software-engineer/ 讲述 20 年工作经验工程师的 20 条 Tips，我读完很有收获，推荐一读 GIF vs PNG, JPEG, and WEBP - The Complete Guide to Image Formatshttps://www.svgator.com/blog/gif-vs-png-jpeg-webp-image-formats-guide/ 一篇关于图像格式的科普文 CLI tools you won’t be able to live without 🔧https://dev.to/lissy93/cli-tools-you-cant-live-without-57f6 50 个开发必备的 CLI 工具 技术实践完爆 ant design 的定位组件！floating-uihttps://juejin.cn/post/7171054283591254029 现代 JS 库打包指南https://github.com/frehner/modern-guide-to-packaging-js-library/blob/main/README-zh_CN.md 本指南旨在提供一些大多数库都应该遵循的一目了然的建议。以及一些额外的信息，用来帮助你了解这些建议被提出的原因，或帮助你判断是否不需要遵循某些建议。这个指南仅适用于 「库（libraries）」，不适用于应用（app 我让虚拟 DOM 的 diff 算法过程动起来了https://juejin.cn/post/7160281215940067336 Dom Diff 可视化 手摸手带你实现一个时间轴组件https://juejin.cn/post/7157917487953084429 Five Challenges to Building an Isomorphic JavaScript Libraryhttps://doordash.engineering/2022/12/06/five-challenges-to-building-an-isomorphic-javascript-library/ Several challenges arose in even this very simple, fictitious isomorphic library, including: Choosing the right dependencies Designing a unified API between environments Ensuring dependencies only affect intended environments Testing every environment Observability — metrics, and logging 前端 mock 数据的几种方式https://mp.weixin.qq.com/s/kTG2a8T6T2hEJEwDrjfwSw 具体需求开发前，后端往往只提供接口文档，对于前端，最简单的方式就是把想要的数据写死在代码里进行开发，但这样的坏处就是和后端联调前还需要再把写死的数据从代码里删除，最好的方式是无侵入的 mock 。下边介绍几种常用的方式，大家可以结合自己的项目来选取。 拓展边界如何高效管理一万条浏览器书签？让效率提高足足 14 倍！https://www.bilibili.com/video/BV16s4y1x7Ha/?vd_source=340c3fc924b0c4be6baa9bb2af1224a9 什么是 Evergreen Note (长青笔记)？https://medium.com/pm%E7%9A%84%E7%94%9F%E7%94%A2%E5%8A%9B%E5%B7%A5%E5%85%B7%E7%AE%B1/%E4%BB%80%E9%BA%BC%E6%98%AF-evergreen-note-%E9%95%B7%E9%9D%92%E7%AD%86%E8%A8%98-5f0b2c7b6547 Evergreen Note 是一套筆記概念，目標是將碎片化的筆記資訊，逐漸發展成知識主題，最終成為個人知識體系的一部分。 Evergreen Note 並非是全新的筆記概念，它奠基於 Zettelkasten 卡片盒筆記法之上，甚至可以說是因應現代人資訊爆炸的現況，優化了 Zettelkasten 卡片盒筆記法 干眼症https://ask.dxy.com/index?entrysource=APPiOS#/item/disease/4164?dxa_adplatform=appfxwxhy 工作游玩的时候，不要忘记保护好你的眼睛，干眼是指各种因素引起的泪液质和量异常或动力学异常，导致泪膜稳定性下降，造成眼部不适、视力损害与眼球表面损害的一种眼科疾病 我是如何艰难地克服「效率成瘾」的？https://blog.jimmylv.info/2022-02-18-Efficiency-Thinking-01-How-Did-I-Struggle-To-Overcome-Efficiency-Addiction/ 所有的效率工具都有两个属性，第一个是它的玩具属性，第二个是工具属性。那么找到的第一个克服效率成瘾的办法，就是一定要区分当前自己是在「玩玩具」还是在「用工具」 10 分钟信箱https://10minutemail.com/ 只有 10min 的信箱，用完就丢，避免收到垃圾邮件的最好方式 小结如果你喜欢每周菜谱，请转发给你的朋友，告诉他们来这里进行订阅~ 订阅地址：https://mrseawave.github.io/blogs/ 每周菜谱，让你做饭更开心~","link":"/articles/2023/01/29/weekly-03/"},{"title":"第 04 菜谱：在浏览器控制台安装npm包是什么操作？","text":"Hi，我是 Sea，欢迎打开新一期的「每周菜谱」，这是第「04」期，发表于 2023-02-05，我们先来看看每周有什么值得推荐的 每周推荐在浏览器控制台安装 npm 包是什么操作？https://king-hcj.github.io/2021/10/27/console-npm-install/ 我们都知道，npm 是 JavaScript 世界的包管理工具,并且是 Node.js 平台的默认包管理工具。通过 npm 可以安装、共享、分发代码,管理项目依赖关系。虽然作为命令行工具的 npm 近年来逐渐式微，但是作为广泛使用的存储库的 npm，却依然如日中天，还是世界上最大的软件注册表。 通常，我们通过npm install xxx在 React、Vue、Angular 等现代前端项目中安装依赖，但是前端项目在本质上还是运行在浏览器端的 HTML、JavaScript 和 CSS，那么，我们有办法在浏览器控制台直接安装 npm 包并使用吗? A Cure for React useState Hell?https://www.builder.io/blog/use-reducer 拯救 useState 地狱？ —– 使用 useReducer。 Preact 开始采用 Vue3 的响应式设计https://juejin.cn/post/7163528906539008030 抛弃 moment.js，基于 date-fns 封装日期相关 utilshttps://juejin.cn/post/7151050708094189582 日期处理库：官方停止维护的 moment.js，无缝代替 moment.js 的 day.js，逐渐流行的 date-fns，最后基于date-fns封装常用日期处理的utils。 2023 年了，如果项目中有用moment.js的可以用day.js代替减少体积做优化，新项目可以选择考虑date-fns。 javascript-testing-best-practiceshttps://github.com/goldbergyoni/javascript-testing-best-practices 本指南可以助你将测试能力提升到下一层级 技术实践把 puppeteer 融入调试流程，调试体验爽翻了！https://mp.weixin.qq.com/s/lAKomnFaMoff1lV_9VqcCg 可以思考下这种调试方式的可行性 这样封装列表 hooks,一天可以开发 20 个页面https://juejin.cn/post/7165467345648320520 在做移动端的需求时，我们经常会开发一些列表页，这些列表页大多数有着相似的功能：分页获取列表、上拉加载、下拉刷新··· 在 Vue 出来 compositionAPI 之前，我们想要复用这样的逻辑还是比较麻烦的，好在现在 Vue2.7+都支持 compositionAPI语法了，这篇文章将 手把手带你用 compositionAPI 封装一个名为 useList 的 hooks来实现列表页的逻辑复用 手撕 babel 插件-消灭 console！https://juejin.cn/post/7155765227986878494 写一个 babel 插件来去除生产环境的 console.log 前端性能-首次加载优化 70%https://juejin.cn/post/7153527700286603300 拓展边界别再问我 WiFi 密码了：这两个 GitHub 帮你解决https://juejin.cn/post/6985183527973158942 这个场景在你生活中是不是经常出现？ 自己设置的 WiFi 的密码却忘记了，而且来一个客人都需要说一次密码，年纪大一点的还得需要你帮他连上 WiFi。 如果你也觉得这事儿有点麻烦，可以从这个文章中找一个简单高效的办法。 DeliberatePracticeVimIn30Dayshttps://github.com/itgoyo/DeliberatePracticeVimIn30Days 刻意练习 Vim30 天能达到什么效果，是麻瓜，还是成神？ ARCHIVEBOXhttps://archivebox.io/ 🗃 Open source self-hosted web archiving. Takes URLs/browser history/bookmarks/Pocket/Pinboard/etc., saves HTML, JS, PDFs, media, and more… 久坐后想让身体休息一下，不如试试这 9 款 Mac 应用https://sspai.com/post/54648 对着电脑屏幕端坐一个下午，终于完成了手头的工作。合上屏幕起身之时，感觉腰背一阵酸疼；两眼更是疲惫不堪。于是不禁感叹：多少次了……下次中间要记得暂停休息一下。感叹久了，就会想要设法解决这个问题。这 9 款 MAC 应用总有一款适合你，他们都是运行在后台，定时跳出来提醒你「该休息一下了」 小结如果你喜欢每周菜谱，请转发给你的朋友，告诉他们来这里进行订阅~ 订阅地址：https://mrseawave.github.io/blogs/ 每周菜谱，让你做饭更开心~","link":"/articles/2023/02/05/weekly-04/"},{"title":"第 05 菜谱：多学习点 CSS~","text":"Hi，我是 Sea，欢迎打开新一期的「每周菜谱」，这是第「05」期，发表于 2023-02-12，我们先来看看每周有什么值得推荐的 每周推荐ECMAScript Async Context 提案介绍https://mp.weixin.qq.com/s/WOSMr6VWbmY3cOUoZRqJDg 由阿里巴巴 TC39 代表主导的 Async Context 提案 刚在 2023 年 2 月初的 TC39 会议中成为了 TC39 Stage 1 提案。提案的目标是定义在 JavaScript 的异步任务中传递数据的方案。 面试必问的异步顺序问题，用 Performance 轻松理清https://mp.weixin.qq.com/s/T8T89IVhDEsHBuawG0KpGA 异步代码的执行顺序是前端面试必问的面试题，它主要考察对 Event Loop、宏微任务以及它们执行顺序的理解。 为 iframe 正名，你可能并不需要微前端https://juejin.cn/post/7185070739064619068 任何新技术、新产品都是有一定适用场景的，它可能在当下很流行，但它不一定在任何时候都是最优解。 qiankun 的作者有一篇《Why Not Iframe》 介绍了 iframe 的优缺点（不过作者还有一篇《你可能并不需要微前端》给微前端降降火），诚然 iframe 确实存在很多缺点，但是在选择一个方案的时候还是要具体场景具体分析，它可能在当下很流行，但它不一定在任何时候都是最优解：iframe 的这些缺点对我来说是否能够接受？它的缺点是否有其它方法可以弥补？使用它到底是利大于弊还是弊大于利？我们需要在优缺点之间找到一个平衡。 看完 Svelte 纪录片才知道它为什么在国外比国内火https://juejin.cn/post/7195401394692554812 Svelte 纪录片 React.js 官网纪录片 2023-The Documentaryhttps://www.bilibili.com/video/BV1qT411R7M3/ React纪录片 技术实践CSS transition 小技巧！如何保留 hover 的状态？https://mp.weixin.qq.com/s/F9uVoV0PbYDLJ6dNZvrQqA 如何在不借助 JS，保留住 hover 状态 居中 toast 最佳 CSS 实现https://www.bilibili.com/video/BV19Y411q7kH/ 如何用 css，实现 toast，省流： 12345678.toast { position：fixed； width：fit-content； left：1rem； right：1rem； margin-left：auto； margin-right：auto；} 还在用 JS 做节流吗？CSS 也可以防止按钮重复点击https://mp.weixin.qq.com/s/sXXvro-n5RH9eFJ9UPw3qQ 众所周知，函数节流（throttle）是 JS 中一个非常常见的优化手段，可以有效避免函数过于频繁的执行。其实除了 JS 方式， CSS 也可以非常轻易实现这样一个功能，无需任何框架库，一起看看吧 1234567891011121314button { animation: throttle 2s step-end forwards;}button:active { animation: none;}@keyframes throttle { from { pointer-events: none; } to { pointer-events: all; }} vh 存在问题？试试动态视口单位之 dvh、svh、lvhhttps://mp.weixin.qq.com/s/wUn0bZ2qJjJ2FCwbWEQvWQ vh 在移动端存在问题！（在移动端，100vh 不总是等于一屏幕的高度**。有的时候，100vh 高度会出现滚动条）根因在于： 很多浏览器，在计算 100vh 的高度的时候，会把地址栏等相关控件的高度计算在内 同时，很多时候，由于会弹出软键盘等操作，在弹出的过程中，100vh 的计算值并不会实时发生变化！ 因此有了新视口相关单位 lvh、svh、dvh 45 个 GIT 经典操作场景，专治不会合代码https://mp.weixin.qq.com/s/2p4m63JdsCjBpVku-WaZyA 整理了 45 个日常用 git 合代码的经典操作场景，基本覆盖了工作中的需求。 拓展边界眼睛干涩发胀别硬熬，快试试这两个方法https://mp.weixin.qq.com/s/Qb2aCY8Fl3GpO_tki-On7w 虽然里面是广告，但还是有有效的护眼小妙招 热敷 40 ℃，持续十分钟 按摩眼眶周围，缓解肌肉疲劳 为什么云盘的上传速度那么快？https://www.zhihu.com/question/512137759 因为网盘（云盘）基本都有秒传模块，这个文件符合秒传规则（云端数据里已经有一摸一样的文件存在了），被秒传了，秒传的原理其实相当简单，就是我们上传文件时，系统去扫描文件的哈希码并保存在数据库中，每个文件（包括其副本）的哈希码都是独一无二的，就是说，如果哈希码相同，我们可以定义为是同一个文件。还有一点需要明确，所以所谓“限速”的网盘，限制的也是下载速度。不管什么平台，上传都是能跑满网速的（上行带宽） Rediscovering RSShttps://deqc.xyz/posts/why-i-went-back-to-rss/ 小结如果你喜欢每周菜谱，请转发给你的朋友，告诉他们来这里进行订阅~ 订阅地址：https://mrseawave.github.io/blogs/ 每周菜谱，让你做饭更开心~","link":"/articles/2023/02/11/weekly-05/"},{"title":"第 06 菜谱：Signal：更多前端框架的选择","text":"Hi，我是 Sea，欢迎打开新一期的「每周菜谱」，这是第「06」期，发表于 2023-02-26，我们先来看看每周有什么值得推荐的~ 每周推荐Signal：更多前端框架的选择https://mp.weixin.qq.com/s/UDv4loT8iaTgkeFjeq-T-w Signal：更多前端框架的选择，最近，Angular、Qwik 的作者「MIŠKO HEVERY」发文表示 Signal 是前端框架的未来，并考虑在 Angular 中实现它。在此之前，Vue、Solid.js、Preact、Svelte 都已实现 Signal。实际上，signal 并不是一个新概念，他还有很多别名，比如： 响应式更新 细粒度更新 How to handle errors in React: full guidehttps://www.developerway.com/posts/how-to-handle-errors-in-react Looking into how to catch and handle errors in React. Usages, patterns and caveats of try/catch and ErrorBoundary, what’s possible, what’s not, and how to catch all errors, including async and errors from event handlers, with ErrorBoundary. Modularizing React Applications with Established UI Patternshttps://martinfowler.com/articles/modularizing-react-apps.html Established UI patterns are often underutilized in the frontend development world, despite their proven effectiveness in solving complex problems in UI design. This article explores the application of established UI building patterns to the React world, with a refactoring journey code example to showcase the benefits. The emphasis is placed on how layering architecture can help organize the React application for improved responsiveness and future changes. React Component Compositionhttps://punits.dev/jargon-free-intros/react-component-composition/ 图解 Composition Multi-threaded React App using useWorkerhttps://dev.to/nilanth/multi-threaded-react-app-using-useworker-gf8 Web Worker allows using multi-threading in react apps for performing expensive tasks without blocking the UI. Whereas useWorker allows using the web worker APIs in a simplified hooks approach in react apps. Workers shouldn’t be overused, we should use it only if necessary or it will increase the complexity of managing the workers. 腾讯文档智能表格渲染层 Feature 设计https://mp.weixin.qq.com/s/cLoE_RydYueo7OeYp4_56A 根据例子讲解与交互相关的 canvas Feature 设计 技术实践通过发布订阅，实现多功能，多方向的 Messagehttps://juejin.cn/post/7198041700555079735 如何实现一个 Message 组件 一个企业级的文件上传组件应该是什么样的https://mp.weixin.qq.com/s/fo8go6i507dAyOpHCGB2ng 我们来看一下,各个版本的文件上传组件大概都长什么样 等级 功能 青铜-垃圾玩意 原生+axios.post 白银-体验升级 粘贴,拖拽,进度条 黄金-功能升级 断点续传,秒传,类型判断 铂金-速度升级 web-worker,时间切片,抽样 hash 钻石-网络升级 异步并发数控制,切片报错重试 王者-精雕细琢 慢启动控制,碎片清理等等 搭一套“ react-cli ”https://juejin.cn/post/7033959447017816077 研究vue-cli搭一套react-cli 出来 原生 CSS Custom Highlight 终于来了~https://mp.weixin.qq.com/s/8GXWG1JHIOHVWlsK-NxY1Q 介绍一个比较前沿但是非常有用的新特性：一个浏览器原生支持的 CSS 文本高亮功能，官方名称叫做 CSS Custom Highlight API[1]，有了它，可以在不改变 dom 结构的情况下自定义任意文本的样式 React Context 实现原理：它在 antd 源码里简直用的太多了https://mp.weixin.qq.com/s/l6-DWRzUwDoWzwrM7uZlPQ 探究一下 antd 组件库是怎么用 context 的？context 又是怎么实现的呢？ 拓展边界2023 年最新最全 VSCode 插件推荐！https://mp.weixin.qq.com/s/3XT3Wv5stDAd27lmw_uvXg 分享 2023 年前端必备的 VS Code 插件 一个程序员决定写代码到 60 岁https://mp.weixin.qq.com/s/-91Z76WGF6O0uxyyGEcHMg 九道下班超省事一锅出料理https://b23.tv/Ae5VLPZ 九道懒人做菜，吃饭还是懒点的好 简单描述工作内容 帮你生成完整周报https://github.com/guaguaguaxia/weekly_report 只需几句，帮你生成完整周报~ 小结如果你喜欢每周菜谱，请转发给你的朋友，告诉他们来这里进行订阅~ 订阅地址：https://mrseawave.github.io/blogs/ 每周菜谱，让你做饭更开心~","link":"/articles/2023/02/26/weekly-06/"},{"title":"第 07 菜谱：How to Name your Types","text":"抱歉，很久没有更新，我是 Sea，欢迎打开新一期的「每周菜谱」，这是第「07」期，发表于 2023-04-15，我们先来看看每周有什么值得推荐的~ 每周推荐How to Name your Typeshttps://www.youtube.com/watch?v=qA65QjWCl60&amp;ab_channel=MattPocock TS 中的一些定义规范 - 不要使用 `I` 做为接口名前缀 - 泛型中的 `&lt;&gt;` 参数类型以 `T` 开头 - ...... 基于 Git 的开发工作流——主干开发特性总结https://mp.weixin.qq.com/s/BvP6d8SJNFEt67BvCHJDLA 基于 Git 的两种最流行的开发工作流是基于主干的开发和基于特性的开发，本文主要总结了基于主干开发的特性 现代图片性能优化及体验优化指南https://mp.weixin.qq.com/s/YfJSqUYsJvlTXH6gRHhrmw 图片资源，在业务中可谓是占据了非常大头，对图片的性能优化及体验优化在今天就显得尤为重要。这篇文章将介绍如何尽可能的对我们的图片资源，进行性能优化及体验优化 How to use useEffect on server-side?https://medium.com/swlh/how-to-use-useeffect-on-server-side-654932c51b13 在 SSR 应用下，通常都是需要在服务端获取数据，那么我们应该如何在服务端下使用 useEffect 呢？ 异步数据的状态管理：React-Queryhttps://segmentfault.com/a/1190000042788578 react-query 是一位数据获取专家，能够基于 Hooks 智能管理请求的一切内容，包括数据、状态、缓存，更新等 一文看透 Module Federationhttps://mp.weixin.qq.com/s/WCQvPbd_w8P-Tn36Sc0SXQ 文章探索 Module Federation 与微前端方案结合起来的可能性，深入了解了它的底层原理 技术实践对于页面的”返回”操作，这样处理比较合适https://mp.weixin.qq.com/s/LL5UlDnFhJClZdFOdliPHw 如何处理页面的返回操作 如何用 JS 实现瀑布流布局https://mp.weixin.qq.com/s/pLZxgZDX6m03uEK1aV9jTg 瀑布流布局，是现在比较流行的一种页面布局方式，即多行等宽元素排列，等宽不等高，后面的元素依次添加到前一行最矮的元素下方。本文介绍如何用 JS 实现瀑布流布局 fixed 元素一定是相对视口定位的吗？https://juejin.cn/post/6844904046663303181 fixed 元素一定是相对视口定位的吗？如果你对此有疑问，可以查看该文章 纯 CSS 实现十个还不错的 Loading 效果https://mp.weixin.qq.com/s/g5Uh86Z4EDlmM4JZwWM2yQ 纯 CSS 实现十个还不错的 Loading 效果 拓展边界React 语境下前端 DDD 的长年探索经验https://juejin.cn/post/7187584683478089787 如果你对如何在如此复杂的系统中，比较合理地掌握每一个技术细节背后的业务逻辑，确保业务实现的准确性有兴趣的话，可以看看此篇文章 旧手机干翻旗舰？https://www.bilibili.com/video/BV1D24y157SD/?vd_source=340c3fc924b0c4be6baa9bb2af1224a9 视频中教你利用安卓系统特性秒开任意软件，让旧手机重回旗舰！ {JSON} Placeholderhttps://jsonplaceholder.typicode.com/ Free fake API for testing and prototyping. 预测 2024 年的前端开发模式https://mp.weixin.qq.com/s/IDJ3cPddefsaGa1gTFq1qQ 最近 AIGC（AI Generated Content，利用 AI 生成内容）非常热，技术圈也受到了很大冲击。目前来看，利用 LLM（Large Language Model，大语言模型）辅助开发还停留在非常早期的阶段，主要应用是「辅助编码」，即「用自然语言输入需求，模型输出代码」。更近一步的探索也仅仅是在此基础上的一层封装（比如 copilot X、cursor）。 但即使在如此早期阶段，也对开发者的心智产生极大震撼，「AI 让程序员失业」这样的论调甚嚣尘上。 LLM 的爆发对前端意味着什么？本文尝试预测一波 2024 年之后的前端开发模式， 网道（WangDoc.com）https://wangdoc.com/ 网道（WangDoc.com）是一个文档网站，提供互联网开发文档，正在建设中。 小结如果你喜欢每周菜谱，请转发给你的朋友，告诉他们来这里进行订阅~ 订阅地址：https://mrseawave.github.io/blogs/ 每周菜谱，让你做饭更开心~","link":"/articles/2023/04/15/weekly-07/"},{"title":"第 08 菜谱：React SSR 实现原理：从 renderToString 到 hydrate","text":"Hi，我是 Sea，欢迎打开新一期的「每周菜谱」，这是第「08」期，发表于 2023-04-23，我们先来看看每周有什么值得推荐的~ 每周推荐React SSR 实现原理：从 renderToString 到 hydratehttps://mp.weixin.qq.com/s/MA6onW57f5LsntgF5mrSHQ React SSR 是服务端通过 renderToString 把组件树渲染成 html 字符串，浏览器通过 hydrate 把 dom 关联到 fiber 树，加上交互逻辑和再次渲染。 服务端 renderToString 就是递归拼接字符串的过程，遇到组件会传入参数执行，遇到标签会拼接对应的字符串，最终返回一段 html 给浏览器。 浏览器端 hydrate 是在 reconcile 的 beginWork 阶段，依次判断 dom 是否可以复用到当前 fiber，可以的话就设置到 fiber.stateNode，然后在 completeWork 阶段就可以跳过节点的创建。 编程中最难的就是命名？这几招教你快速上手https://mp.weixin.qq.com/s/q0yZPEcOhsNUqdYaBsLm8g 本文通过案例的讲解强调了命名的重要性及养成良好的命名习惯一些建议。 What Is require.resolve And How Does It Work?https://dev.to/stephencweiss/what-is-require-resolve-and-how-does-it-work-1ho4 获取当前文件路径 123console.log(path.join(__dirname, 'data.txt'));// 用 require.resolve 代替console.log(require.resolve('./data.txt')); React.lazy without a default exporthttps://dev.to/iamandrewluca/react-lazy-without-default-export-4b65 https://legacy.reactjs.org/docs/code-splitting.html#named-exports React.lazy目前仅支持默认导出。如果您要导入的模块使用命名导出，您可以创建一个中间模块，将其重新导出为默认模块。 对于质量保障，前端职能该做些什么？https://mp.weixin.qq.com/s/TpISxLeaYmL3OhDvhNVXZw 对于前端项目交付的质量，各团队往往会建设众多的交付标准，希望以此来约束项目的开发，从而保障最终的交付物质量。 技术实践如何检查前端项目中未使用的依赖包？https://mp.weixin.qq.com/s/Z-sDe2fGuRm2GiKfyOJXJA 随着前端项目中使用的依赖包越来越多，而其中一部分依赖包可能并未被项目所使用，手动查找这些依赖包既耗时又繁琐。那么，有没有工具能够快速地帮助我们识别和清理项目中未使用的依赖包呢？下面就来介绍两个用于检查未使用依赖包的常用工具！ depcheck - npm npm-check - npm 你是如何获取文本宽度的？https://juejin.cn/post/7091990279565082655 日常开发中，经常会需要获取文本显示宽度来做一些特殊布局， 比如： 文本超过多长时候截断展示省略号… canvas 布局时候在某段文本之后展示特殊标记等 如何才能准确高效的实现获取文本实际的渲染宽度呢？ 揭示 useCallback 的问题和隐患并给出解决方案https://github.com/huyaocode/webKnowledge/issues/12 揭示 useCallback 的问题和隐患，如有需要 useCallback，个人建议直接使用 ahooks 中 useMemoizedFn，持久化函数，但变量是使用最新值 如何实现多个颜色叠加效果？https://segmentfault.com/q/1010000000398005 https://stackoverflow.com/questions/12143544/how-to-multiply-two-colors-in-javascript JS 实现如何颜色叠加 叠加公式 1Formula: Result Color = (Top Color) * (Bottom Color) /255 12345678function multiply(rgb1, rgb2) { var result = [], i = 0; for (; i &lt; rgb1.length; i++) { result.push(Math.floor((rgb1[i] * rgb2[i]) / 255)); } return result;} 拓展边界别再往眼球上滴眼药水了https://mp.weixin.qq.com/s/Xkcg9NAUO560zAB74eu7kg 轻松滴眼药水最关键的地方在于：不要直接瞄准眼球。更好的方式是瞄准结膜囊，也就是眼皮与眼球之间的空间。用手捏住下眼皮，轻轻往下拉，这样下眼睑和眼球之间就会形成一个“小口袋”——只要把眼药水滴在这里就行了。 道家绝活“解龙环”https://www.bilibili.com/video/BV1Lh411u7BL/?vd_source=340c3fc924b0c4be6baa9bb2af1224a9 道家绝活“解龙环”，松解肩颈只需 10 秒钟 如何在 Gitlab 中使用 ChatGPT 进行 CodeReviewhttps://mp.weixin.qq.com/s/Dyk1cYg63oOs13f9_gf9ug 本篇文章介绍如何在 Gitlab 中使用 ChatGPT 进行 CodeReview: 如想查看如何与 Github 一起使用，可查看 ChatGPT-CodeReview：https://github.com/anc95/ChatGPT-CodeReview codereview.gpt：https://github.com/sturdy-dev/codereview.gpt ChatGPT 提示模式：提高代码质量、重构、需求获取和软件设计https://mp.weixin.qq.com/s/smbsScFbCT3Ci7mGF5uxPA https://arxiv.org/pdf/2303.07839.pdf 总结了帮助工程师应用 ChatGPT 改进需求获取、快速原型制作、代码质量、重构和系统设计的提示模式的核心思想和 100 个提示要点 小结如果你喜欢每周菜谱，请转发给你的朋友，告诉他们来这里进行订阅~ 订阅地址：https://mrseawave.github.io/blogs/ 每周菜谱，让你做饭更开心~","link":"/articles/2023/04/23/weekly-08/"},{"title":"第 10 菜谱：前端性能优化","text":"Hi，我是 Sea，欢迎打开新一期的「每周菜谱」，这是第「10」期，发表于 2023-06-17 ，我们先来看看每周有什么值得推荐的~ 每周推荐24 个强大的 HTML 属性https://juejin.cn/post/7219669309537845285HTML 属性非常多，除了基本的一些属性外，还有很多很有用的功能性特别强大的属性； 前端性能优化https://juejin.cn/post/7188894691356573754提升首屏的加载速度，是前端性能优化中最重要的环节，本篇文章 通过对比优化前后的性能变化，来验证方案的有效性，了解并掌握其原理 Node v20.3.0（Current）发布https://nodejs.org/en/blog/release/v20.3.0 版本在升级 libuv（提供 Node 异步 I/O 功能的库）后带来了显著的 Linux 性能提升。此外，还引入了 **AbortSignal.any()**，并且开始正式认可 Ruy Adorno 在 Node.js TSC 中的地位。 React Server Component 从理念到原理https://mp.weixin.qq.com/s/TFxQSwOLQJWBC-ErWaHS9Q 本文会从以下几个角度介绍RSC： RSC是用来做啥的？ RSC和其他服务端渲染方案（SSR、SSG）的区别 RSC的工作原理 技术实践CSS 中 calc(100%-100px)不加空格不生效的问题https://juejin.cn/post/7220939977245737018 （为了避免负数 为啥 CSS 不会支持双斜杠( // )注释？https://mp.weixin.qq.com/s/zqBZV2XW_BHeAgwZ68fcdg 众所周知，CSS 仅支持多行注释，也就是/**/注释，那为什么不能用 //注释呢？ 语法冲突: CSS 支持border-image: 0//0;写法 如何使用 nodejs 对项目压力测试https://juejin.cn/post/7224341322612621369 压力测试可以模拟大量用户访问, 来测试我们应用的承载能力， 可以帮助我们提前发现问题和瓶颈，早早制定应对措施。 关于 Node 调试工具和方法的介绍https://blog.openreplay.com/an-introduction-to-debugging-in-nodejs/ 文章从简单内容开始进行介绍，如使用 IDE 扩展程序突出潜在问题、使用控制台日志，再到使用 V8 检查器并通过 Chrome 进行调试。 完美搭配，微前端与 Monorepo 的架构设计https://mp.weixin.qq.com/s/9jciGcyLkbxQIGrBqvbUsA 本文主要介绍如何使 Monorepo 与微前端结合使用，篇幅较长，请结合目录酌情阅读。 微前端/Monorepo 方案都存在很多争议，争论无意义，选择适合自己团队的方案即可。 技术实战以 Micro App + pnpm 技术栈，讲解了从零搭建到项目部署的一个完整微前端项目。 十个超级好用的 Javascript 技巧https://mp.weixin.qq.com/s/pFDjSWWqT5QdCkEvsVSNTA 常见又超级好用的 Javascript 技巧和代码片段 拓展边界如何成为架构师？https://mp.weixin.qq.com/s/AkNuuHjguqm9aT4U4IXDFA成长，是认知的升级，所谓架构师就是有着架构师的认知，和一些通用技术能力。 什么情况下使用，弹窗、浮层、抽屉、新页签？https://www.bilibili.com/video/BV16k4y1n7VL/?vd_source=340c3fc924b0c4be6baa9bb2af1224a9什么情况下使用，弹窗、浮层、抽屉、新页签 超全拔智齿后食谱https://www.xiaohongshu.com/explore/63b93ab9000000001f00dae5拔牙后别再光喝粥了 🥣，很多好吃的其实都能吃！ 小结如果你喜欢每周菜谱，请转发给你的朋友，告诉他们来这里进行订阅~ 订阅地址：https://mrseawave.github.io/blogs/ 每周菜谱，让你做饭更开心~","link":"/articles/2023/06/17/weekly-10/"},{"title":"第 09 菜谱：Service Worker 使用 Workbox 预缓存实践","text":"Hi，我是 Sea，欢迎打开新一期的「每周菜谱」，这是第「09」期，发表于 2023-06-10，我们先来看看每周有什么值得推荐的~ 每周推荐ES2023 即将发布，快来看看有哪些更新https://mp.weixin.qq.com/s?__biz=MzA4NjI1OTM5OQ==&amp;mid=2455887416&amp;idx=1&amp;sn=1ef4e5eb95f61d6e4c00a93430bfc6dd&amp;scene=21#wechat_redirect CSS 原生支持三角函数https://mp.weixin.qq.com/s?__biz=Mzg2MDU4MzU3Nw==&amp;mid=2247495701&amp;idx=1&amp;sn=8779fa1de1a196bc28c78fadb375d336&amp;scene=21#wechat_redirect 12345678910.box { /* 设置元素的宽度为 sin(30deg) 的值 */ width: calc(sin(30deg) * 100px); /* 设置元素的高度为 cos(45deg) 的值 */ height: calc(cos(45deg) * 100%); /* 设置元素的透明度为 tan(60deg) 的值 */ opacity: calc(tan(60deg));} 为什么都用 PM2 来跑 Node 应用？https://mp.weixin.qq.com/s/GyKx5tcvVjUCNgbe9Jl05w 在服务器上，我们不会直接跑 node，而会用 pm2 来跑。 为什么要用 pm2 呢？它解决了什么问题？ 探索主流前端框架的响应式原理https://mp.weixin.qq.com/s/Fe_SbQE1fWU_j2vSgSSttA 在前端框架中，一般有三种处理响应式的方法： Values: 通过比较当前值和之前的值来检测数据变化。Angular 使用表达式进行比较，React 使用虚拟 DOM 进行比较，Svelte 使用编译器进行脏数据标记。 Observables：在 Angular 中使用 RxJS，在 Svelte 中使用 Stores 来处理响应式数据。 Signals：在 Vue、Qwik 和 Solid 框架中使用 Signals。它与 Vue 相连的是组件，Qwik 与 DOM 连接，Solid 使用 DOM 作为更细粒度的方法。 每种方法都有其特点和适用场景，开发者需要根据具体情况选择合适的方法来处理响应式数据。 现代图片性能优化及体验优化指南https://mp.weixin.qq.com/s?__biz=Mzg2MDU4MzU3Nw==&amp;mid=2247495418&amp;idx=1&amp;sn=379e7ad612de120e4d327e42aa4b9064&amp;scene=21#wechat_redirect 图片资源，在我们的业务中可谓是占据了非常大头的一环，尤其是其对带宽的消耗是十分巨大的。 对图片的性能优化及体验优化在今天就显得尤为重要。本文，就将从各个方面阐述，在各种新特性满头飞的今天，我们可以如何尽可能的对我们的图片资源，进行性能优化及体验优化。 技术实践Service Worker 使用 Workbox 预缓存实践https://juejin.cn/post/7083656336705060871 SW ： 服务器与浏览器之间的中间人，如果网站中注册了Service Worker那么它可以拦截当前网站所有的请求，进行判断（需要编写相应的判断程序），如果需要向服务器发起请求的就转给服务器，如果可以直接使用缓存的就直接返回缓存不再转给服务器,我们在Service Worker 中可以做拦截客户端的请求、向客户端发送消息、向服务器发起请求等相关关操作，其中最重要且广泛的的作用就是离线资源缓存 其中 Service Worker 调试 可查看此篇文章 如何设计一个支持并发的前端缓存接口？https://mp.weixin.qq.com/s/OdjqLxhG26X4of0cPAWMtA 缓存池不过就是一个map，存储接口数据的地方，将接口的路径和参数拼到一块作为key，数据作为value存起来，本文主要是实践 console 样式增强库https://juejin.cn/post/7216182763237916729 1234567891011121314// 只有一个 %c 时console.info( '%c this is me ', 'background-color: #2196f3; padding: 6px 12px; border-radius: 2px; font-size: 14px; color: #fff; text-transform: uppercase; font-weight: 600;', window);// 两个 %c 时console.info( '%c this is first %c this is second ', 'background-color: #2196f3; padding: 6px 12px; border-radius: 2px; font-size: 14px; color: #fff; text-transform: uppercase; font-weight: 600;', 'background-color: #00BCD4; padding: 6px 12px; border-radius: 2px; font-size: 14px; color: #fff; text-transform: uppercase; font-weight: 600;', window); async/await 异常捕获你还在用 try-catchhttps://juejin.cn/post/7224391827654180922 不知道大家项目里面是怎么处理 async/await 的异常，我在我们项目里翻了一下，发现大量使用 try-catch 来处理 async/await 异常，首先说明一下， try-catch 处理并没有什么问题，我只是觉得这么写代码会有点乱，感觉代码逻辑像是断层了一样，不易理解； 其次是代码冗余问题，单个 try-catch 就占了好几行代码，如果每个请求的地方都添加 try-catch，就会显得代码很臃肿。 而对于这种大量相同的冗余代码，完全可以用一种通用的函数来替代。 拓展边界去过很多地方，看过很多美景，旅行的意义在哪里？https://www.bilibili.com/video/BV1Fk4y1j79c/ joshutohttps://github.com/kamiyaa/joshuto https://www.bilibili.com/video/BV1Zo4y1G7QZ/?vd_source=340c3fc924b0c4be6baa9bb2af1224a9 它是 ranger 的 Rust 替代品，终端下的 vim-inspired 文件管理器。 lazygithttps://github.com/jesseduffield/lazygit 用最高效的工具，学会 Git 最强的功能 —— 命令行神器 Lazygit 小结如果你喜欢每周菜谱，请转发给你的朋友，告诉他们来这里进行订阅~ 订阅地址：https://mrseawave.github.io/blogs/ 每周菜谱，让你做饭更开心~","link":"/articles/2023/06/10/weekly-09/"},{"title":"为什么更换图床","text":"今天来讲讲我为什么会想到更换图床，GiuHub —&gt; 阿里云 OSS 结论先说结论： 第一，白嫖总归是不好的， 第二主要是怕被封号，或者某一天增加了反盗链，那岂不是凉凉，（参考微博与 Gitee 因此我打算目前先使用阿里云来当做个人图床，同时配合 uPic 来进行图片的上传 当然必不可少的是图床缺点：各类厂商图床可能存在的问题包括但不限于：存储空间和流量免费付费问题。稳定性、安全性 接下来介绍下各种图床的优劣吧 图床选择 国内大厂的对象存储服务：腾讯云阿里云七牛云都有自己的对象存储服务。用户可以创建自己的存储桶，上传文件后自动生成外链访问。 优点：存储费十分便宜，0.01 元/GB 左右。当作图床基本无需担忧费用。 缺点（风险）：流量费用很高，这里流量指的是用户通过外链访问或者下载资源时会生成流量。以腾讯云为例，0.5 元/GB 流量费用，如果是个人当博客图床小范围使用还好。当访问量上升，或者外链被他人分享使用，就有可能导致费用暴涨，更不用提如果被恶意下载刷流量。目前个人已知的存储桶只能设置上限预警，在欠费几小时后被动关闭。（七牛云各种免费额度很高，不过需要备案域名） 解决：使用 cdn 加速来大幅度减少流量费，同时 cdn 设置上限阈值。隐藏文件原链接，设置防盗链等方法。这样已经能很大程度降低天价账单的可能性，同时正常使用也不容易碰到恶意攻击的情况。 使用国外大厂的对象存储服务：本质上和国内对象存储服务类似，只不过有些优惠力度很大，如果不考虑中国大陆的访问性的话，backblaze + cloudflare免费的 cdn 加速还是很香的 使用现成图床：例如 SMMS 图床服务。优点是有免费额度，也有付费选项，无需担心上述费用过高问题。缺点：需自行选择稳定图床厂商，因为有跑路风险。 白嫖(不推荐) ：使用github、gitee、甚至是 csdn、新浪微博等。 优点：完全免费，可以把图片上传到任意能上传的位置。 缺点：目前不推荐，例如 github、gitee 被当作图床有可能遭到封禁。同时一旦白嫖网站加入了防盗链规则，那么博客图片直接全部报废，例子有 gitee 和微博。 后续计划 原有的 GitHub 的图床迁移 域名申请与备案 搭配 CDN 进行加速 思考图片备份 参考链接 零成本搭建个人博客之图床和 cdn 加速 国内自建图床指南","link":"/articles/2023/01/18/why-change-image-hosting/"},{"title":"GitHub Pages 绑定个人域名","text":"首先需要有一个自己的域名，让大家更好的认识你。 配置 DNS在域名服务商那里，添加 4 个 A 记录和 1 个 CNAME：(github) 类型 名称 值 A @ 185.199.108.153 A @ 185.199.109.153 A @ 185.199.110.153 A @ 185.199.111.153 CNAME www mrseawave.github.io 添加完成后如下： 怎么查看域名是否已经解析成功了呢？ 12345➜ dig +noall +answer hailangya.comhailangya.com. 600 IN A 185.199.109.153hailangya.com. 600 IN A 185.199.110.153hailangya.com. 600 IN A 185.199.108.153hailangya.com. 600 IN A 185.199.111.153 终端输入以上命令，得到以上结果即表明域名解析成功，可以进入下一步了。 自定义域在 GitHub 配置 在边栏的“代码和自动化”部分中，单击“ Pages”。 在“自定义域”下，键入自定义域，然后单击“保存”。 博客相关配置创建 CNAME 文件在等待证书生成的时候就可以配置下 Hexo 博客 首先添加 CNAME 文件： 1hailangya.com 文件位置：~/blog/source/CNAME 修改相关链接Hexo 中，然后修改站点配置文件： 12345# 文件位置：~/blog/_config.yml- url: https://mrseawave.github.io/blogs+ url: https://hailangya.com 因使用自定义域名，所以去除 pathname 路径（/blogs ），具体细节可查看 文章 [!TIP] 提示 💡 由于 github 的所有项目只能有一个 github pages 域名（如我的项目：mrseawave/mrseawave.github.io，域名为 mrseawave.github.io，其他开启 github pages 的项目都是这个域名的子目录（如项目 mrseawave/imgs，域名为 mrseawave.github.io/imgs ，但是我在子项目中单独配置域名 xxx.com，所以不在需要 pathname，直接访问 xxx.com 即可 参考链接 GitHub Pages 绑定个人域名，免 Cloudflare 支持 HTTPS | reuixiy 管理 GitHub Pages 站点的自定义域 - GitHub 文档 多个 Github Pages 项目主页 DNS 配置方式 | Iifa Tree 添加 CNAME 文件到你的存储库中 - GitHub Pages 指南 - UDN 开源文档 多项目部署为同一个 GitHub Pages - 掘金","link":"/articles/2024/03/23/github-bind-domain/"},{"title":"Prettier V3 中英文之间不支持空格","text":"最近在做 blog 依赖升级，使用 pnpm update --latest 升级完所有的依赖后，发现 prettier@3 不再支持盘古之白（分隔中文与英语的空白间隔） 解决办法参考官网，如果需要一个强制间距样式的工具，请考虑 textlint-ja 或 lint-md（规则 space-round-alphabet 和 space-round-number），需要引入额外的插件配置，配不动了，因此我选择降级至 prettier@2.8.8，没啥太大影响，后续可能会再次升级。 额外补充按照w3c标准， In horizontal writing mode, the basic approach uses proportional fonts to represent Western alphas and uses proportional or monospace fonts for European numerals. In principle, there is tracking or spacing between an adjacent Han character and a Western character of up to 1/4 em, except at the line start or end.横排时，西文字母使用比例字体；阿拉伯数字则常用比例字体或等宽字体。原则上，汉字与西文字母、数字间使用不多于四分之一个汉字宽的字距或空白。但西文出现在行首或行尾时，则无须加入空白。 看其意思，应该也是需要空格的（or 间距）。 按照 中华人民共和国新闻出版行业标准 CY/T 154—2017 号《中文出版物夹用英文的编辑规范》第 8.1 节 中文文本中夹用英文时，应根据所选用的中英文字体、字符间距以及排版的视觉效果决定英文词句与中文文字之间是否留有空格间距。如留空格，应保证体例的统一。 借鉴知乎上 - 梁海的回答 我坚持要在混排中加空格，主要是我觉得两种文字的交界处应该是个尽量平滑的过渡，尽量满足双方文字的需求，并且让文本的节奏尽量平稳 混排加空格主要是为了顺滑！视觉美化 另外如果需要加空格，这事也不该由写作者自己输入，工具该自动化执行。 参考链接 Prettier 3.0: Hello, ECMAScript Modules! · Prettier Markdown: Add an option to re-enable Prettier 2.x’s automatic space insertion in CJK · Issue #15015 · prettier/prettier 盘古之白 | M-x Chris-An-Emacser 中西文混排时汉字与拉丁字母之间是否要有空格？ - 知乎 中文文案排版指北 document-style-guide: 中文技术文档的写作规范","link":"/articles/2024/03/30/prettier-lint-space/"}],"tags":[{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"GoodNotes","slug":"GoodNotes","link":"/tags/GoodNotes/"},{"name":"Api","slug":"Api","link":"/tags/Api/"},{"name":"Doc","slug":"Doc","link":"/tags/Doc/"},{"name":"Apple","slug":"Apple","link":"/tags/Apple/"},{"name":"Gift","slug":"Gift","link":"/tags/Gift/"},{"name":"Charles","slug":"Charles","link":"/tags/Charles/"},{"name":"Chrome","slug":"Chrome","link":"/tags/Chrome/"},{"name":"Download","slug":"Download","link":"/tags/Download/"},{"name":"History","slug":"History","link":"/tags/History/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"CI&#x2F;CD","slug":"CI-CD","link":"/tags/CI-CD/"},{"name":"JS","slug":"JS","link":"/tags/JS/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Lint","slug":"Lint","link":"/tags/Lint/"},{"name":"Engineered","slug":"Engineered","link":"/tags/Engineered/"},{"name":"GitHub","slug":"GitHub","link":"/tags/GitHub/"},{"name":"Proxy","slug":"Proxy","link":"/tags/Proxy/"},{"name":"VPN","slug":"VPN","link":"/tags/VPN/"},{"name":"Repository","slug":"Repository","link":"/tags/Repository/"},{"name":"Lerna","slug":"Lerna","link":"/tags/Lerna/"},{"name":"Publish","slug":"Publish","link":"/tags/Publish/"},{"name":"NPM","slug":"NPM","link":"/tags/NPM/"},{"name":"Actions","slug":"Actions","link":"/tags/Actions/"},{"name":"Workflow","slug":"Workflow","link":"/tags/Workflow/"},{"name":"Cache","slug":"Cache","link":"/tags/Cache/"},{"name":"Manual","slug":"Manual","link":"/tags/Manual/"},{"name":"Token","slug":"Token","link":"/tags/Token/"},{"name":"SEO","slug":"SEO","link":"/tags/SEO/"},{"name":"MD","slug":"MD","link":"/tags/MD/"},{"name":"JetBrains","slug":"JetBrains","link":"/tags/JetBrains/"},{"name":"Prettier","slug":"Prettier","link":"/tags/Prettier/"},{"name":"WebStorm","slug":"WebStorm","link":"/tags/WebStorm/"},{"name":"Format","slug":"Format","link":"/tags/Format/"},{"name":"WX","slug":"WX","link":"/tags/WX/"},{"name":"Hooks","slug":"Hooks","link":"/tags/Hooks/"},{"name":"Husky","slug":"Husky","link":"/tags/Husky/"},{"name":"Sourcetree","slug":"Sourcetree","link":"/tags/Sourcetree/"},{"name":"Install","slug":"Install","link":"/tags/Install/"},{"name":"Rust","slug":"Rust","link":"/tags/Rust/"},{"name":"Process","slug":"Process","link":"/tags/Process/"},{"name":"Koa","slug":"Koa","link":"/tags/Koa/"},{"name":"Static","slug":"Static","link":"/tags/Static/"},{"name":"Validator","slug":"Validator","link":"/tags/Validator/"},{"name":"JSON-Schema","slug":"JSON-Schema","link":"/tags/JSON-Schema/"},{"name":"Monorepo","slug":"Monorepo","link":"/tags/Monorepo/"},{"name":"MultiRepo","slug":"MultiRepo","link":"/tags/MultiRepo/"},{"name":"Recommend","slug":"Recommend","link":"/tags/Recommend/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Node","slug":"Node","link":"/tags/Node/"},{"name":"Stream","slug":"Stream","link":"/tags/Stream/"},{"name":"File","slug":"File","link":"/tags/File/"},{"name":"Cron","slug":"Cron","link":"/tags/Cron/"},{"name":"Schedule","slug":"Schedule","link":"/tags/Schedule/"},{"name":"Image","slug":"Image","link":"/tags/Image/"},{"name":"Watermark","slug":"Watermark","link":"/tags/Watermark/"},{"name":"Babel","slug":"Babel","link":"/tags/Babel/"},{"name":"ZSH","slug":"ZSH","link":"/tags/ZSH/"},{"name":"Puppeteer","slug":"Puppeteer","link":"/tags/Puppeteer/"},{"name":"Optimize","slug":"Optimize","link":"/tags/Optimize/"},{"name":"Pkg","slug":"Pkg","link":"/tags/Pkg/"},{"name":"PM2","slug":"PM2","link":"/tags/PM2/"},{"name":"IPC","slug":"IPC","link":"/tags/IPC/"},{"name":"RGB","slug":"RGB","link":"/tags/RGB/"},{"name":"CSS","slug":"CSS","link":"/tags/CSS/"},{"name":"Color","slug":"Color","link":"/tags/Color/"},{"name":"SSH","slug":"SSH","link":"/tags/SSH/"},{"name":"Key","slug":"Key","link":"/tags/Key/"},{"name":"GitLab","slug":"GitLab","link":"/tags/GitLab/"},{"name":"Terminal","slug":"Terminal","link":"/tags/Terminal/"},{"name":"uPic","slug":"uPic","link":"/tags/uPic/"},{"name":"VS Code","slug":"VS-Code","link":"/tags/VS-Code/"},{"name":"Plugins","slug":"Plugins","link":"/tags/Plugins/"},{"name":"Ide","slug":"Ide","link":"/tags/Ide/"},{"name":"Webpack","slug":"Webpack","link":"/tags/Webpack/"},{"name":"Html","slug":"Html","link":"/tags/Html/"},{"name":"Mini-Programs","slug":"Mini-Programs","link":"/tags/Mini-Programs/"},{"name":"Cross","slug":"Cross","link":"/tags/Cross/"},{"name":"Spawn","slug":"Spawn","link":"/tags/Spawn/"},{"name":"Dependencies","slug":"Dependencies","link":"/tags/Dependencies/"},{"name":"Clean","slug":"Clean","link":"/tags/Clean/"},{"name":"G2","slug":"G2","link":"/tags/G2/"},{"name":"Legend","slug":"Legend","link":"/tags/Legend/"},{"name":"Source Code","slug":"Source-Code","link":"/tags/Source-Code/"},{"name":"Analysis","slug":"Analysis","link":"/tags/Analysis/"},{"name":"Script","slug":"Script","link":"/tags/Script/"},{"name":"Monitor","slug":"Monitor","link":"/tags/Monitor/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"Sequelize","slug":"Sequelize","link":"/tags/Sequelize/"},{"name":"ORM","slug":"ORM","link":"/tags/ORM/"},{"name":"analysis","slug":"analysis","link":"/tags/analysis/"},{"name":"Weekly","slug":"Weekly","link":"/tags/Weekly/"},{"name":"Github","slug":"Github","link":"/tags/Github/"}],"categories":[{"name":"Tools","slug":"Tools","link":"/categories/Tools/"},{"name":"技术","slug":"技术","link":"/categories/%E6%8A%80%E6%9C%AF/"},{"name":"Other","slug":"Other","link":"/categories/Other/"},{"name":"analysis","slug":"analysis","link":"/categories/analysis/"},{"name":"Weekly","slug":"Weekly","link":"/categories/Weekly/"}],"pages":[{"title":"About me","text":".heimu { color: #000; background-color: #000; } .heimu:hover { color: #fff; } 95后前端开发一枚，爱好动漫，撸猫， 家有两只猫，一只蒂阿瑞（英短银渐层），一只逢坂大河（狸花猫），旅游，游戏，ps4（Fantasy_FishViy），switch党 独爱魂系游戏，欢迎一起来传火！ 2020年加入 如果青年 和朋友们一起搞事情，哇哈哈哈 博客主要写文章，技术 or 自己还没能解决的坑，但可能因为表述会有点问题，博客更多只是写给自己看的，如果发现不懂之处和可以改进的地方欢迎留言 🙏 本站文章如无特别声明，均为原创，转载请注明来源","link":"/about/index.html"},{"title":"友人帐","text":"function changeFrameHeight(){ const ifm= document.getElementById(\"blogFriend\"); ifm.height=ifm.contentWindow.document.body.scrollHeight; }; window.onresize=function(){ changeFrameHeight(); }","link":"/friends/index.html"},{"title":"留言板","text":"不留下点什么证明你来过吗~","link":"/messages/index.html"}]}